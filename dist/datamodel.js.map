<<<<<<< HEAD
{"version":3,"sources":["webpack://DataModel/webpack/universalModuleDefinition","webpack://DataModel/webpack/bootstrap","webpack://DataModel/./src/index.js","webpack://DataModel/./src/enums/data-format.js","webpack://DataModel/./src/enums/dimension-subtype.js","webpack://DataModel/./src/enums/measure-subtype.js","webpack://DataModel/./src/enums/field-type.js","webpack://DataModel/./src/enums/filtering-mode.js","webpack://DataModel/./src/enums/group-by-functions.js","webpack://DataModel/./src/utils/date-time-formatter.js","webpack://DataModel/./src/utils/column-major.js","webpack://DataModel/./src/utils/extend2.js","webpack://DataModel/./src/utils/helper.js","webpack://DataModel/./src/field-store.js","webpack://DataModel/./src/value.js","webpack://DataModel/./src/operator/row-diffset-iterator.js","webpack://DataModel/./src/invalid-aware-types.js","webpack://DataModel/./src/operator/bucket-creator.js","webpack://DataModel/./src/constants/index.js","webpack://DataModel/./src/operator/compose.js","webpack://DataModel/./src/operator/get-common-schema.js","webpack://DataModel/./src/operator/cross-product.js","webpack://DataModel/./src/operator/merge-sort.js","webpack://DataModel/./src/operator/data-builder.js","webpack://DataModel/./src/operator/difference.js","webpack://DataModel/./src/operator/group-by-function.js","webpack://DataModel/./src/utils/reducer-store.js","webpack://DataModel/./src/operator/group-by.js","webpack://DataModel/./src/operator/natural-join-filter-function.js","webpack://DataModel/./src/operator/union.js","webpack://DataModel/./src/operator/outer-join.js","webpack://DataModel/./src/fields/field/index.js","webpack://DataModel/./src/fields/dimension/index.js","webpack://DataModel/./src/fields/categorical/index.js","webpack://DataModel/./src/fields/temporal/index.js","webpack://DataModel/./src/fields/binned/index.js","webpack://DataModel/./src/fields/measure/index.js","webpack://DataModel/./src/fields/continuous/index.js","webpack://DataModel/./src/fields/parsers/field-parser/index.js","webpack://DataModel/./src/fields/parsers/categorical-parser/index.js","webpack://DataModel/./src/fields/parsers/temporal-parser/index.js","webpack://DataModel/./src/fields/parsers/binned-parser/index.js","webpack://DataModel/./src/fields/parsers/continuous-parser/index.js","webpack://DataModel/./src/fields/partial-field/index.js","webpack://DataModel/./src/field-creator.js","webpack://DataModel/./src/default-config.js","webpack://DataModel/./src/converter/dsv-arr.js","webpack://DataModel/./node_modules/d3-dsv/src/dsv.js","webpack://DataModel/./node_modules/d3-dsv/src/csv.js","webpack://DataModel/./node_modules/d3-dsv/src/tsv.js","webpack://DataModel/./src/converter/dsv-str.js","webpack://DataModel/./src/converter/flat-json.js","webpack://DataModel/./src/converter/auto-resolver.js","webpack://DataModel/./src/helper.js","webpack://DataModel/./src/relation.js","webpack://DataModel/./src/datamodel.js","webpack://DataModel/./src/stats/index.js","webpack://DataModel/./src/export.js","webpack://DataModel/./src/operator/pure-operators.js","webpack://DataModel/./src/operator/natural-join.js"],"names":["root","factory","exports","module","define","amd","window","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","DataModel","require","default","DataFormat","FLAT_JSON","DSV_STR","DSV_ARR","AUTO","DimensionSubtype","CATEGORICAL","TEMPORAL","GEO","BINNED","MeasureSubtype","CONTINUOUS","FieldType","MEASURE","DIMENSION","FilteringMode","NORMAL","INVERSE","ALL","GROUP_BY_FUNCTIONS","SUM","AVG","MIN","MAX","FIRST","LAST","COUNT","STD","convertToNativeDate","date","Date","pad","DateTimeFormatter","format","this","dtParams","undefined","nativeDate","RegExp","escape","text","replace","TOKEN_PREFIX","DATETIME_PARAM_SEQUENCE","YEAR","MONTH","DAY","HOUR","MINUTE","SECOND","MILLISECOND","defaultNumberParser","defVal","val","parsedVal","isFinite","parseInt","defaultRangeParser","range","nVal","toLowerCase","length","getTokenDefinitions","daysDef","short","long","monthsDef","H","index","extract","parser","formatter","getHours","toString","hours","P","M","getMinutes","S","getSeconds","K","getMilliseconds","a","join","day","getDay","A","e","getDate","b","month","getMonth","B","y","result","substring","presentDate","presentYear","Math","trunc","getFullYear","year","Y","getTokenFormalNames","definitions","HOUR_12","AMPM_UPPERCASE","AMPM_LOWERCASE","SHORT_DAY","LONG_DAY","DAY_OF_MONTH","DAY_OF_MONTH_CONSTANT_WIDTH","SHORT_MONTH","LONG_MONTH","MONTH_OF_YEAR","SHORT_YEAR","LONG_YEAR","tokenResolver","defaultResolver","arg","targetParam","arguments","hourFormat24","hourFormat12","ampmLower","ampmUpper","amOrpm","isPM","findTokens","tokenPrefix","tokenLiterals","keys","occurrence","forwardChar","indexOf","push","token","formatAs","nDate","formattedStr","String","formattedVal","parse","dateTimeStamp","options","extractTokenValue","dtParamSeq","noBreak","dtParamArr","args","resolverKey","resolverParams","resolverFn","param","resolvedVal","splice","apply","checkIfOnlyYear","unshift","tokenObj","lastOccurrenceIndex","occObj","occIndex","targetText","regexFormat","tokenArr","map","obj","occurrenceLength","extractValues","match","shift","getNativeDate","Number","Function","concat","_toConsumableArray","len","column_major","store","_len","fields","Array","_key","forEach","fieldIndex","from","OBJECTSTRING","objectToStrFn","objectToStr","arrayToStr","checkCyclicRef","parentArr","bIndex","extend2","obj1","obj2","skipUndef","_typeof","merge","tgtArr","srcArr","item","srcVal","tgtVal","str","cRef","isArray","getUniqueId","getTime","round","random","isArrEqual","arr1","arr2","formatNumber","detectDataFormat","data","isObject","fieldStore","createNamespace","fieldArr","dataId","fieldsObj","_cachedFieldsObj","field","getMeasure","measureFields","_cachedMeasure","schema","type","getDimension","dimensionFields","_cachedDimension","Value","_classCallCheck","defineProperties","_value","configurable","writable","_parsedValue","rowDiffsetIterator","rowDiffset","callback","split","diffStr","diffStsArr","start","end","InvalidAwareTypes","invalid_aware_types_classCallCheck","config","assign","_invalidAwareValsMap","invalidAwareVals","NULL","NA","NIL","invalid","nil","null","generateBuckets","binSize","buckets","next","findBucketRange","bucketRanges","leftIdx","rightIdx","midIdx","floor","DM_DERIVATIVES","SELECT","PROJECT","GROUPBY","COMPOSE","CAL_VAR","BIN","SORT","JOINS","CROSS","LEFTOUTER","RIGHTOUTER","NATURAL","FULLOUTER","LOGICAL_OPERATORS","getCommonSchema","fs1","fs2","retArr","fs1Arr","defaultFilterFn","crossProduct","dm1","dm2","filterFn","replaceCommonSchema","jointype","applicableFilterFn","dm1FieldStore","getFieldspace","dm2FieldStore","dm1FieldStoreName","dm2FieldStoreName","commonSchemaList","Error","tmpSchema","_rowDiffset","rowAdded","rowPosition","ii","tuple","userArg","partialField","dm1Fields","prepareJoinData","dm2Fields","detachedRoot","tupleObj","cellVal","iii","defSortFn","a1","b1","mergeSort","arr","sortFn","sort","lo","hi","mid","mainArr","auxArr","getSortFn","dataType","sortType","retFunc","groupData","hashMap","Map","groupedData","datum","fieldVal","has","set","createSortingFnArg","groupedDatum","targetFields","targetFieldDetails","label","reduce","acc","idx","dataBuilder","colIdentifier","sortingDetails","addUid","columnWise","retObj","uids","reqSorting","tmpDataArr","colName","insertInd","dataObj","fieldName","sortMeta","fDetails","fieldInSchema","sortingFn","slice","f","data_builder_toConsumableArray","pop","sortData","tmpData","difference","hashTable","schemaNameArr","dm1FieldStoreFieldObj","dm2FieldStoreFieldObj","_colIdentifier","prepareDataHelper","dm","addData","hashData","schemaName","getFilteredValues","filter","sum","filteredNumber","curr","avg","totalSum","isNaN","fnList","_defineProperty","_fnList","filteredValues","min","group_by_function_toConsumableArray","max","sqrt","mean","num","pow","variance","defaultReducerName","ReducerStore","_this","reducer_store_classCallCheck","defReducer","entries","reducer","_this2","__unregister","delete","reducerStore","groupBy","dataModel","reducers","existingDataModel","sFieldArr","dimensions","_ref","group_by_slicedToArray","getFieldArr","reducerObj","measures","defaultReducer","measureName","defAggFn","reducerFn","resolve","getReducerObj","fieldStoreObj","dbName","dimensionArr","measureArr","newDataModel","_ref3","_ref4","rowCount","hash","_","cachedStore","cloneProvider","row","__calculateFieldspace","naturalJoinFilter","commonSchemaArr","retainTuple","union","leftOuterJoin","dataModel1","dataModel2","rightOuterJoin","Field","field_classCallCheck","subtype","description","displayName","Dimension","_cachedDomain","calculateDataDomain","Categorical","Set","domain","add","Temporal","temporal_classCallCheck","temporal_possibleConstructorReturn","__proto__","getPrototypeOf","_cachedMinDiff","sortedData","arrLn","minDiff","POSITIVE_INFINITY","prevDatum","nextDatum","processedCount","_this3","Binned","binsArr","bins","Measure","unit","numberFormat","Continuous","NEGATIVE_INFINITY","FieldParser","CategoricalParser","isInvalid","getInvalidType","trim","TemporalParser","temporal_parser_classCallCheck","temporal_parser_possibleConstructorReturn","_dtf","BinnedParser","matched","parseFloat","ContinuousParser","PartialField","partial_field_classCallCheck","_sanitize","createFields","dataColumn","headers","headersObj","header","createUnitField","default_config","dataFormat","DSVArr","firstRowHeader","columns","columnMajor","EOL","EOF","QUOTE","NEWLINE","RETURN","objectConverter","JSON","stringify","src_dsv","delimiter","reFormat","DELIMITER","charCodeAt","parseRows","rows","N","I","eof","eol","j","formatRow","formatValue","test","convert","customConverter","columnSet","column","inferColumns","formatRows","csv","dsv","tsv","DSVStr","fieldSeparator","d3Dsv","FlatJSON","insertionIndex","Auto","converters","resp","updateFields","partialFieldspace","fieldStoreName","helper_slicedToArray","collID","partialFieldMap","newFields","coll","createUnitFieldFromPartial","persistDerivations","sourceDm","model","operation","_model$_derivation","criteriaFn","_derivation","src_helper_toConsumableArray","op","meta","criteria","persistCurrentDerivation","newDm","_newDm$_ancestorDeriv","_ancestorDerivation","persistAncestorDerivation","selectHelper","selectFn","newRowDiffSet","lastInsertedValue","li","rawFieldsData","formattedFieldsData","formattedData","selectorHelperFn","rawData","_iteratorNormalCompletion","_didIteratorError","_iteratorError","_step","_iterator","iterator","done","_ref2","err","return","prepareSelectionData","checker","cloneWithAllFields","clonedDm","clone","getPartialFieldspace","calculateFieldsConfig","filterPropagationModel","propModels","filterByMeasure","fns","propModel","getData","fieldsConfig","getFieldsConfig","fieldsSpace","values","v","def","some","every","propField","valueOf","select","fn","saveChild","cloneWithSelect","selectConfig","cloneConfig","cloned","cloneWithProject","projField","allFields","projectionSet","actualProjField","sanitizeUnitSchema","unitSchema","sanitizeAndValidateSchema","supportedMeasureSubTypes","supportedDimSubTypes","validateUnitSchema","updateData","relation","defaultConfig","converterFn","converter","_converterFn","_converterFn2","dataHeader","fieldNameAs","as","resolveFieldName","nameSpace","_partialFieldspace","_dataFormat","applyExistingOperationOnModel","derivations","getDerivations","selectionModel","rejectionModel","derivation","_selectionModel","_rejectionModel","_getDerivationArgumen","params","groupByString","getDerivationArguments","propagateIdentifiers","propModelInf","nonTraversingModel","excludeModels","handlePropagation","_children","child","_applyExistingOperati","_applyExistingOperati2","getPathToRootModel","path","_parent","propagateToAllDataModels","identifiers","rootModels","propagationInf","propagationNameSpace","propagateToSource","propagationSourceId","sourceId","propagateInterpolatedValues","criterias","persistent","_ref5","actionCriterias","mutableActions","filteredCriteria","entry","action","sourceActionCriterias","actionInf","actionConf","applyOnSource","models","rootModel","propConfig","sourceIdentifiers","rootGroupByModel","groupByModel","inf","propagationModel","filteredModel","getFilteredModel","reverse","Relation","relation_classCallCheck","source","_fieldStoreName","_propagationNameSpace","immutableActions","_fieldspace","joinWith","unionWith","differenceWith","defConfig","oDm","constructor","setParent","fieldConfig","normalizedProjField","relation_toConsumableArray","search","_fieldConfig","fieldObj","removeChild","findIndex","sibling","parent","datamodel_classCallCheck","datamodel_possibleConstructorReturn","_onPropagation","order","withUid","getAllFields","dataGenerated","fieldNames","fmtFieldIdx","elem","fIdx","fmtFn","datumIdx","fieldsArr","dataInCSVArr","sortedDm","colData","rowsCount","serializedData","rowIdx","colIdx","fieldinst","dependency","replaceVar","depVars","retrieveFn","depFieldIndices","fieldSpec","fs","suppliedFields","computedValues","fieldsData","_createFields","datamodel_slicedToArray","addField","addToNameSpace","isMutableAction","payload","getRootDataModel","find","getRootGroupByModel","sourceNamespace","addToPropNamespace","filterImmutableAction","criteriaModel","propagateImmutableActions","eventName","measureFieldName","binFieldName","_createBinnedFieldDat","measureField","binsCount","_measureField$domain","_measureField$domain2","_slicedToArray","dMin","dMax","ceil","abs","binnedData","createBinnedFieldData","binField","serialize","getSchema","first","last","count","sd","std","Operators","compose","_len5","operations","_key5","currentDM","firstChild","compose_toConsumableArray","dispose","bin","_len3","_key3","project","_len2","_key2","_len4","_key4","calculateVariable","naturalJoin","fullOuterJoin","version","Stats","enums"],"mappings":"CAAA,SAAAA,EAAAC,GACA,iBAAAC,SAAA,iBAAAC,OACAA,OAAAD,QAAAD,IACA,mBAAAG,eAAAC,IACAD,OAAA,eAAAH,GACA,iBAAAC,QACAA,QAAA,UAAAD,IAEAD,EAAA,UAAAC,IARA,CASCK,OAAA,WACD,mBCTA,IAAAC,EAAA,GAGA,SAAAC,EAAAC,GAGA,GAAAF,EAAAE,GACA,OAAAF,EAAAE,GAAAP,QAGA,IAAAC,EAAAI,EAAAE,GAAA,CACAC,EAAAD,EACAE,GAAA,EACAT,QAAA,IAUA,OANAU,EAAAH,GAAAI,KAAAV,EAAAD,QAAAC,IAAAD,QAAAM,GAGAL,EAAAQ,GAAA,EAGAR,EAAAD,QA0DA,OArDAM,EAAAM,EAAAF,EAGAJ,EAAAO,EAAAR,EAGAC,EAAAQ,EAAA,SAAAd,EAAAe,EAAAC,GACAV,EAAAW,EAAAjB,EAAAe,IACAG,OAAAC,eAAAnB,EAAAe,EAAA,CAA0CK,YAAA,EAAAC,IAAAL,KAK1CV,EAAAgB,EAAA,SAAAtB,GACA,oBAAAuB,eAAAC,aACAN,OAAAC,eAAAnB,EAAAuB,OAAAC,YAAA,CAAwDC,MAAA,WAExDP,OAAAC,eAAAnB,EAAA,cAAiDyB,OAAA,KAQjDnB,EAAAoB,EAAA,SAAAD,EAAAE,GAEA,GADA,EAAAA,IAAAF,EAAAnB,EAAAmB,IACA,EAAAE,EAAA,OAAAF,EACA,KAAAE,GAAA,iBAAAF,QAAAG,WAAA,OAAAH,EACA,IAAAI,EAAAX,OAAAY,OAAA,MAGA,GAFAxB,EAAAgB,EAAAO,GACAX,OAAAC,eAAAU,EAAA,WAAyCT,YAAA,EAAAK,UACzC,EAAAE,GAAA,iBAAAF,EAAA,QAAAM,KAAAN,EAAAnB,EAAAQ,EAAAe,EAAAE,EAAA,SAAAA,GAAgH,OAAAN,EAAAM,IAAqBC,KAAA,KAAAD,IACrI,OAAAF,GAIAvB,EAAA2B,EAAA,SAAAhC,GACA,IAAAe,EAAAf,KAAA2B,WACA,WAA2B,OAAA3B,EAAA,SAC3B,WAAiC,OAAAA,GAEjC,OADAK,EAAAQ,EAAAE,EAAA,IAAAA,GACAA,GAIAV,EAAAW,EAAA,SAAAiB,EAAAC,GAAsD,OAAAjB,OAAAkB,UAAAC,eAAA1B,KAAAuB,EAAAC,IAGtD7B,EAAAgC,EAAA,GAIAhC,IAAAiC,EAAA,u5DClFA,IAAMC,EAAYC,EAAQ,GAE1BxC,EAAOD,QAAUwC,EAAUE,QAAUF,EAAUE,QAAUF,qxBCKzD,IAOeG,EAPI,CACfC,UAAW,WACXC,QAAS,SACTC,QAAS,SACTC,KAAM,QCEKC,EAPU,CACrBC,YAAa,cACbC,SAAU,WACVC,IAAK,MACLC,OAAQ,UCAGC,EAJQ,CACnBC,WAAY,cCKDC,EALG,CACdC,QAAS,UACTC,UAAW,aCGAC,EANO,CAClBC,OAAQ,SACRC,QAAS,UACTC,IAAK,OCQMC,EAXY,CACvBC,IAAK,MACLC,IAAK,MACLC,IAAK,MACLC,IAAK,MACLC,MAAO,QACPC,KAAM,OACNC,MAAO,QACPC,IAAK,OCRT,SAASC,EAAqBC,GAC1B,OAAIA,aAAgBC,KACTD,EAGJ,IAAIC,KAAKD,GASpB,SAASE,EAAKzC,GACV,OAAQA,EAAI,GAAL,IAAgBA,EAAOA,EA8BP,SAAS0C,EAAmBC,GACnDC,KAAKD,OAASA,EACdC,KAAKC,cAAWC,EAChBF,KAAKG,gBAAaD,EAftBE,OAAOC,OAAS,SAAUC,GACtB,OAAOA,EAAKC,QAAQ,2BAA4B,SAkBpDT,EAAkBU,aAAe,IAIjCV,EAAkBW,wBAA0B,CACxCC,KAAM,EACNC,MAAO,EACPC,IAAK,EACLC,KAAM,EACNC,OAAQ,EACRC,OAAQ,EACRC,YAAa,GAUjBlB,EAAkBmB,oBAAsB,SAAUC,GAC9C,OAAO,SAAUC,GACb,IAAIC,EACJ,OAAIC,SAASD,EAAYE,SAASH,EAAK,KAC5BC,EAGJF,IAYfpB,EAAkByB,mBAAqB,SAAUC,EAAON,GACpD,OAAO,SAACC,GACJ,IACIvF,EADAD,SAGJ,IAAKwF,EAAO,OAAOD,EAEnB,IAAMO,EAAON,EAAIO,cAEjB,IAAK/F,EAAI,EAAGC,EAAI4F,EAAMG,OAAQhG,EAAIC,EAAGD,IACjC,GAAI6F,EAAM7F,GAAG+F,gBAAkBD,EAC3B,OAAO9F,EAIf,YAAUuE,IAANvE,EACOuF,EAEJ,OAqBfpB,EAAkB8B,oBAAsB,WACpC,IAAMC,EAAU,CACZC,MAAO,CACH,MACA,MACA,MACA,MACA,MACA,MACA,OAEJC,KAAM,CACF,SACA,SACA,UACA,YACA,WACA,SACA,aAGFC,EAAY,CACdF,MAAO,CACH,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OAEJC,KAAM,CACF,UACA,WACA,QACA,QACA,MACA,OACA,OACA,SACA,YACA,UACA,WACA,aAsPR,MAlPoB,CAChBE,EAAG,CAEC/F,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAGP,OAFUzB,EAAoByB,GAErBmB,WAAWC,aAG5B3G,EAAG,CAECM,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GACP,IACMqB,EADI9C,EAAoByB,GACdmB,WAAa,GAE7B,OAAkB,IAAVE,EAAc,GAAKA,GAAOD,aAG1C9E,EAAG,CAECvB,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,WACpBC,OAAQ,SAACjB,GACL,OAAIA,EACOA,EAAIO,cAER,MAEXW,UAAW,SAAClB,GAIR,OAHUzB,EAAoByB,GACdmB,WAEA,GAAK,KAAO,OAGpCG,EAAG,CAECvG,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,WACpBC,OAAQ,SAACjB,GACL,OAAIA,EACOA,EAAIO,cAER,MAEXW,UAAW,SAAClB,GAIR,OAHUzB,EAAoByB,GACdmB,WAEA,GAAK,KAAO,OAGpCI,EAAG,CAECxG,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GACfwB,gBAKvBC,EAAG,CAEC1G,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GACZ0B,gBAK1BC,EAAG,CAEC5G,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAHUzB,EAAoByB,GACjB4B,kBAEHR,aAGlBS,EAAG,CAEC9G,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,UAAWN,EAAQC,MAAMmB,KAAK,KAA9B,KACbb,OAAQtC,EAAkByB,mBAAmBM,EAAQC,OACrDO,UAND,SAMYlB,GACP,IACM+B,EADIxD,EAAoByB,GAChBgC,SAEd,OAAQtB,EAAQC,MAAMoB,GAAMX,aAGpCa,EAAG,CAEClH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,UAAWN,EAAQE,KAAKkB,KAAK,KAA7B,KACbb,OAAQtC,EAAkByB,mBAAmBM,EAAQE,MACrDM,UAND,SAMYlB,GACP,IACM+B,EADIxD,EAAoByB,GAChBgC,SAEd,OAAQtB,EAAQE,KAAKmB,GAAMX,aAGnCc,EAAG,CAECnH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAHUzB,EAAoByB,GAChBmC,UAEHf,aAGnBtG,EAAG,CAECC,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GAChBmC,aAKtBC,EAAG,CAECrH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,UAAWH,EAAUF,MAAMmB,KAAK,KAAhC,KACbb,OAAQtC,EAAkByB,mBAAmBS,EAAUF,OACvDO,UAND,SAMYlB,GACP,IACMqC,EADI9D,EAAoByB,GACdsC,WAEhB,OAAQzB,EAAUF,MAAM0B,GAAQjB,aAGxCmB,EAAG,CAECxH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,UAAWH,EAAUD,KAAKkB,KAAK,KAA/B,KACbb,OAAQtC,EAAkByB,mBAAmBS,EAAUD,MACvDM,UAND,SAMYlB,GACP,IACMqC,EADI9D,EAAoByB,GACdsC,WAEhB,OAAQzB,EAAUD,KAAKyB,GAAQjB,aAGvCxG,EAAG,CAECG,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OALD,SAKSjB,GAAO,OAAOrB,EAAkBmB,qBAAlBnB,CAAwCqB,GAAO,GACrEkB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GACdsC,WAEG,KAG3BE,EAAG,CAECzH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,YACpBC,OALD,SAKSjB,GACJ,IAAIyC,SACJ,GAAIzC,EAAK,CACL,IAAMvF,EAAIuF,EAAIQ,OACdR,EAAMA,EAAI0C,UAAUjI,EAAI,EAAGA,GAE/B,IAAIwF,EAAYtB,EAAkBmB,qBAAlBnB,CAAwCqB,GACpD2C,EAAc,IAAIlE,KAClBmE,EAAcC,KAAKC,MAAOH,EAAYI,cAAiB,KAO3D,OAHIxE,EAFJkE,KAAYG,EAAc3C,GAEM8C,cAAgBJ,EAAYI,gBACxDN,MAAYG,EAAc,GAAI3C,GAE3B1B,EAAoBkE,GAAQM,eAEvC7B,UAtBD,SAsBYlB,GACP,IACIgD,EADMzE,EAAoByB,GACjB+C,cAAc3B,WACvB3G,SAOJ,OALIuI,IACAvI,EAAIuI,EAAKxC,OACTwC,EAAOA,EAAKN,UAAUjI,EAAI,EAAGA,IAG1BuI,IAGfC,EAAG,CAEClI,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,YACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAHUzB,EAAoByB,GACf+C,cAAc3B,eAgB7CzC,EAAkBuE,oBAAsB,WACpC,IAAMC,EAAcxE,EAAkB8B,sBAEtC,MAAO,CACHf,KAAMyD,EAAYrC,EAClBsC,QAASD,EAAY1I,EACrB4I,eAAgBF,EAAY7G,EAC5BgH,eAAgBH,EAAY7B,EAC5B3B,OAAQwD,EAAY5B,EACpB3B,OAAQuD,EAAY1B,EACpB8B,UAAWJ,EAAYtB,EACvB2B,SAAUL,EAAYlB,EACtBwB,aAAcN,EAAYjB,EAC1BwB,4BAA6BP,EAAYrI,EACzC6I,YAAaR,EAAYf,EACzBwB,WAAYT,EAAYZ,EACxBsB,cAAeV,EAAYvI,EAC3BkJ,WAAYX,EAAYX,EACxBuB,UAAWZ,EAAYF,IAW/BtE,EAAkBqF,cAAgB,WAC9B,IAAMb,EAAcxE,EAAkB8B,sBAChCwD,EAAkB,WAMpB,IALA,IAAIzJ,EAAI,EACJ0J,SACAC,SACE1J,EAAI2J,UAAK5D,OAERhG,EAAIC,EAAGD,IACV0J,oBAAW1J,OAAXuE,EAAAqF,UAAW5J,IACX4J,UAAA5D,QAAShG,OAATuE,EAAAqF,UAAS5J,MACL2J,EAAcD,GAItB,OAAKC,EAEEA,EAAY,GAAGlD,OAAOkD,EAAY,IAFd,MAK/B,MAAO,CACH5E,KAAM,CAAC4D,EAAYX,EAAGW,EAAYF,EAC9BgB,GAEJzE,MAAO,CAAC2D,EAAYf,EAAGe,EAAYZ,EAAGY,EAAYvI,EAC9CqJ,GAEJxE,IAAK,CAAC0D,EAAYtB,EAAGsB,EAAYlB,EAAGkB,EAAYjB,EAAGiB,EAAYrI,EAC3DmJ,GAEJvE,KAAM,CAACyD,EAAYrC,EAAGqC,EAAY1I,EAAG0I,EAAY7G,EAAG6G,EAAY7B,EAC5D,SAAU+C,EAAcC,EAAcC,EAAWC,GAC7C,IAAIL,SACAM,SACAC,SACA1E,SAcJ,OAZIsE,IAAiBG,EAAUF,GAAaC,IACJ,OAAhCC,EAAO,GAAGxD,OAAOwD,EAAO,MACxBC,GAAO,GAGXP,EAAcG,GAEdH,EADOG,GAGOD,EAGbF,GAELnE,EAAMmE,EAAY,GAAGlD,OAAOkD,EAAY,IACpCO,IACA1E,GAAO,IAEJA,GANoB,OASnCL,OAAQ,CAACwD,EAAY5B,EACjB0C,GAEJrE,OAAQ,CAACuD,EAAY1B,EACjBwC,KAUZtF,EAAkBgG,WAAa,SAAU/F,GAQrC,IAPA,IAAMgG,EAAcjG,EAAkBU,aAChC8D,EAAcxE,EAAkB8B,sBAChCoE,EAAgB3J,OAAO4J,KAAK3B,GAC5B4B,EAAa,GACfvK,SACAwK,UAEIxK,EAAIoE,EAAOqG,QAAQL,EAAapK,EAAI,KAAO,GAC/CwK,EAAcpG,EAAOpE,EAAI,IACmB,IAAxCqK,EAAcI,QAAQD,IAE1BD,EAAWG,KAAK,CACZnE,MAAOvG,EACP2K,MAAOH,IAIf,OAAOD,GASXpG,EAAkByG,SAAW,SAAU5G,EAAMI,GACzC,IAQInE,EARE4K,EAAQ9G,EAAoBC,GAC5BuG,EAAapG,EAAkBgG,WAAW/F,GAC1CuE,EAAcxE,EAAkB8B,sBAClC6E,EAAeC,OAAO3G,GACpBgG,EAAcjG,EAAkBU,aAClC8F,SACAK,SACAhL,SAGJ,IAAKA,EAAI,EAAGC,EAAIsK,EAAWvE,OAAQhG,EAAIC,EAAGD,IAEtCgL,EAAerC,EADfgC,EAAQJ,EAAWvK,GAAG2K,OACYjE,UAAUmE,GAC5CC,EAAeA,EAAalG,QAAQ,IAAIH,OAAO2F,EAAcO,EAAO,KAAMK,GAG9E,OAAOF,GAQX3G,EAAkBvC,UAAUqJ,MAAQ,SAAUC,EAAeC,GACzD,IAAM3B,EAAgBrF,EAAkBqF,gBAClClF,EAAWD,KAAK+G,kBAAkBF,GAClCG,EAAalH,EAAkBW,wBAC/BwG,EAAUH,GAAWA,EAAQG,QAC7BC,EAAa,GACbC,EAAO,GACTC,SACAC,SACAC,SACAnG,SACAxF,SACA4L,SACAC,SACA5L,SACAgI,EAAS,GAEb,IAAKwD,KAAejC,EAChB,GAAK,GAAG3H,eAAe1B,KAAKqJ,EAAeiC,GAA3C,CAMA,IAJAD,EAAKxF,OAAS,EAEd2F,GADAD,EAAiBlC,EAAciC,IACHK,OAAOJ,EAAe1F,OAAS,EAAG,GAAG,GAE5DhG,EAAI,EAAGC,EAAIyL,EAAe1F,OAAQhG,EAAIC,EAAGD,SAI9BuE,KAFZiB,EAAMlB,GADNsH,EAAQF,EAAe1L,IACFO,OAGjBiL,EAAKd,KAAK,MAEVc,EAAKd,KAAK,CAACkB,EAAOpG,IAM1B,GAAI,OAFJqG,EAAcF,EAAWI,MAAM1H,KAAMmH,MAEuBF,EACxD,MAGJC,EAAWF,EAAWI,IAAgBI,EAU1C,OAPIN,EAAWvF,QAAU3B,KAAK2H,gBAAgBT,EAAWvF,QAErDiC,EAAOgE,QAAQV,EAAW,GAAI,EAAG,GAEjCtD,EAAOgE,QAAPF,MAAA9D,EAAkBsD,GAGftD,GAQX9D,EAAkBvC,UAAUwJ,kBAAoB,SAAUF,GACtD,IAYIjL,EAZEmE,EAASC,KAAKD,OACduE,EAAcxE,EAAkB8B,sBAChCmE,EAAcjG,EAAkBU,aAChC0F,EAAapG,EAAkBgG,WAAW/F,GAC1C8H,EAAW,GAEbC,SACAC,SACAC,SACAC,SACAC,SAGAvM,SAEJuM,EAAcxB,OAAO3G,GAErB,IAAMoI,EAAWjC,EAAWkC,IAAI,SAAAC,GAAA,OAAOA,EAAI/B,QACrCgC,EAAmBpC,EAAWvE,OACpC,IAAKhG,EAAI2M,EAAmB,EAAG3M,GAAK,EAAGA,KACnCqM,EAAW9B,EAAWvK,GAAGuG,OAEV,IAAMgG,EAAYvG,OAAS,QAKdzB,IAAxB4H,IACAA,EAAsBI,EAAYvG,QAGtCsG,EAAaC,EAAYrE,UAAUmE,EAAW,EAAGF,GACjDI,EAAcA,EAAYrE,UAAU,EAAGmE,EAAW,GAC9C5H,OAAOC,OAAO4H,GACdC,EAAYrE,UAAUiE,EAAqBI,EAAYvG,QAE3DmG,EAAsBE,GAblBF,EAAsBE,EAgB9B,IAAKrM,EAAI,EAAGA,EAAI2M,EAAkB3M,IAC9BoM,EAAS7B,EAAWvK,GACpBuM,EAAcA,EAAY3H,QAAQwF,EAAcgC,EAAOzB,MAAOhC,EAAYyD,EAAOzB,OAAOnE,WAG5F,IAAMoG,EAAgB1B,EAAc2B,MAAM,IAAIpI,OAAO8H,KAAiB,GAGtE,IAFAK,EAAcE,QAET9M,EAAI,EAAGC,EAAIuM,EAASxG,OAAQhG,EAAIC,EAAGD,IACpCkM,EAASM,EAASxM,IAAM4M,EAAc5M,GAE1C,OAAOkM,GAQX/H,EAAkBvC,UAAUmL,cAAgB,SAAU7B,GAClD,IAAIlH,EAAO,KACX,GAAIgJ,OAAOtH,SAASwF,GAChBlH,EAAO,IAAIC,KAAKiH,QACb,IAAK7G,KAAKD,QAAUH,KAAKgH,MAAMC,GAClClH,EAAO,IAAIC,KAAKiH,OAEf,CACD,IAAM5G,EAAWD,KAAKC,SAAWD,KAAK4G,MAAMC,GACxC5G,EAAS0B,SACT3B,KAAKG,WAAL,IAAAyI,SAAArL,UAAAJ,KAAAuK,MAAsB9H,KAAtB,OAAAiJ,6HAAAC,CAA8B7I,MAC9BN,EAAOK,KAAKG,YAGpB,OAAOR,GAGXG,EAAkBvC,UAAUoK,gBAAkB,SAASoB,GACnD,OAAe,IAARA,GAAa/I,KAAKD,OAAOyI,MAAM,QAAQ7G,QASlD7B,EAAkBvC,UAAUgJ,SAAW,SAAUxG,EAAQ8G,GACrD,IAAI1G,SAQJ,OANI0G,EACA1G,EAAaH,KAAKG,WAAaH,KAAK0I,cAAc7B,IACzC1G,EAAaH,KAAKG,cAC3BA,EAAaH,KAAK0I,cAAc7B,IAG7B/G,EAAkByG,SAASpG,EAAYJ,ICruBnC,IAAAiJ,EAAA,SAACC,GACZ,IAAItN,EAAI,EACR,OAAO,WAAe,QAAAuN,EAAA3D,UAAA5D,OAAXwH,EAAWC,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAXF,EAAWE,GAAA9D,UAAA8D,GAClBF,EAAOG,QAAQ,SAACnI,EAAKoI,GACXN,EAAMM,aAAuBH,QAC/BH,EAAMM,GAAcH,MAAMI,KAAK,CAAE7H,OAAQhG,KAE7CsN,EAAMM,GAAYlD,KAAKlF,KAE3BxF,kNCdF8N,EAAe,SACfC,EAAgBrN,OAAOkB,UAAUgF,SACjCoH,EAAc,kBACdC,EAAa,iBAEnB,SAASC,EAAexB,EAAKyB,GAIzB,IAHA,IAAInO,EAAImO,EAAUnI,OACdoI,GAAU,EAEPpO,GAAG,CACN,GAAI0M,IAAQyB,EAAUnO,GAElB,OADAoO,EAASpO,EAGbA,GAAK,EAGT,OAAOoO,EA2GX,SAASC,EAASC,EAAMC,EAAMC,GAE1B,YAAI,IAAOF,EAAP,YAAAG,EAAOH,MAASR,SAAgB,IAAOS,EAAP,YAAAE,EAAOF,MAAST,EACzC,WAGP,IAAOS,EAAP,YAAAE,EAAOF,MAAST,GAAyB,OAATS,EACzBD,SAGP,IAAOA,EAAP,YAAAG,EAAOH,MAASR,IAChBQ,EAAOC,aAAgBd,MAAQ,GAAK,IAnH5C,SAASiB,EAAMJ,EAAMC,EAAMC,EAAWG,EAAQC,GAC1C,IAAIC,EACAC,EACAC,EACAC,EACAC,EAcJ,GATKL,GAKDD,EAAOjE,KAAK4D,GACZM,EAAOlE,KAAK6D,KALZI,EAAS,CAACL,GACVM,EAAS,CAACL,IAOVA,aAAgBd,MAChB,IAAKoB,EAAO,EAAGA,EAAON,EAAKvI,OAAQ6I,GAAQ,EAAG,CAC1C,IACIC,EAASR,EAAKO,GACdE,EAASR,EAAKM,GAElB,MAAOnH,GACH,eAGA,IAAOqH,EAAP,YAAAN,EAAOM,MAAWjB,EACZU,QAAwBjK,IAAXwK,IACfT,EAAKO,GAAQE,IAIF,OAAXD,SAAmB,IAAOA,EAAP,YAAAL,EAAOK,MAAWhB,IACrCgB,EAASR,EAAKO,GAAQE,aAAkBtB,MAAQ,GAAK,KAG3C,KADdwB,EAAOf,EAAea,EAAQH,IAE1BE,EAASR,EAAKO,GAAQF,EAAOM,GAG7BP,EAAMI,EAAQC,EAAQP,EAAWG,EAAQC,SAMrD,IAAKC,KAAQN,EAAM,CACf,IACIO,EAASR,EAAKO,GACdE,EAASR,EAAKM,GAElB,MAAOnH,GACH,SAGJ,GAAe,OAAXqH,SAAmB,IAAOA,EAAP,YAAAN,EAAOM,MAAWjB,GAKrCkB,EAAMjB,EAAc5N,KAAK4O,MACbf,GACO,OAAXc,SAAmB,IAAOA,EAAP,YAAAL,EAAOK,MAAWhB,IACrCgB,EAASR,EAAKO,GAAQ,KAGZ,KADdI,EAAOf,EAAea,EAAQH,IAE1BE,EAASR,EAAKO,GAAQF,EAAOM,GAG7BP,EAAMI,EAAQC,EAAQP,EAAWG,EAAQC,IAGxCI,IAAQf,GACE,OAAXa,GAAqBA,aAAkBrB,QACvCqB,EAASR,EAAKO,GAAQ,KAGZ,KADdI,EAAOf,EAAea,EAAQH,IAE1BE,EAASR,EAAKO,GAAQF,EAAOM,GAG7BP,EAAMI,EAAQC,EAAQP,EAAWG,EAAQC,IAI7CN,EAAKO,GAAQE,MAGhB,CACD,GAAIP,QAAwBjK,IAAXwK,EACb,SAEJT,EAAKO,GAAQE,GAIzB,OAAOT,EAiBPI,CAAMJ,EAAMC,EAAMC,GACXF,GCnIJ,SAASY,EAAS1J,GACrB,OAAOiI,MAAMyB,QAAQ1J,GA2ClB,IAAM2J,EAAc,wBAAY,IAAIlL,MAAOmL,UAAY/G,KAAKgH,MAAsB,IAAhBhH,KAAKiH,WASvE,SAASC,EAAWC,EAAMC,GAC7B,IAAKP,EAAQM,KAAUN,EAAQO,GAC3B,OAAOD,IAASC,EAGpB,GAAID,EAAKxJ,SAAWyJ,EAAKzJ,OACrB,OAAO,EAGX,IAAK,IAAIhG,EAAI,EAAGA,EAAIwP,EAAKxJ,OAAQhG,IAC7B,GAAIwP,EAAKxP,KAAOyP,EAAKzP,GACjB,OAAO,EAIf,OAAO,EASJ,SAAS0P,EAAalK,GACzB,OAAOA,EASJ,IAAMmK,EAAmB,SAACC,GAC7B,MAnEsB,iBAmETA,EACFzN,EAAWE,QACX6M,EAAQU,IAASV,EAAQU,EAAK,IAC9BzN,EAAWG,QACX4M,EAAQU,KAA0B,IAAhBA,EAAK5J,QAlF/B,SAAmBR,GACtB,OAAOA,IAAQ9E,OAAO8E,GAiF4BqK,CAASD,EAAK,KACrDzN,EAAWC,UAEf,MChDI0N,EApDI,CACfF,KAAM,GAENG,gBAHe,SAGEC,EAAUzP,GACvB,IAAM0P,EAAS1P,GAAQ4O,IA4CvB,OA1CA9K,KAAKuL,KAAKK,GAAU,CAChB1P,KAAM0P,EACNzC,OAAQwC,EAERE,UAJgB,WAKZ,IAAIA,EAAY7L,KAAK8L,iBAQrB,OANKD,IACDA,EAAY7L,KAAK8L,iBAAmB,GACpC9L,KAAKmJ,OAAOG,QAAQ,SAACyC,GACjBF,EAAUE,EAAM7P,QAAU6P,KAG3BF,GAEXG,WAfgB,WAgBZ,IAAIC,EAAgBjM,KAAKkM,eAUzB,OARKD,IACDA,EAAgBjM,KAAKkM,eAAiB,GACtClM,KAAKmJ,OAAOG,QAAQ,SAACyC,GACbA,EAAMI,SAASC,OAAS1N,EAAUC,UAClCsN,EAAcF,EAAM7P,QAAU6P,MAInCE,GAEXI,aA5BgB,WA6BZ,IAAIC,EAAkBtM,KAAKuM,iBAU3B,OARKvM,KAAKuM,mBACND,EAAkBtM,KAAKuM,iBAAmB,GAC1CvM,KAAKmJ,OAAOG,QAAQ,SAACyC,GACbA,EAAMI,SAASC,OAAS1N,EAAUE,YAClC0N,EAAgBP,EAAM7P,QAAU6P,MAIrCO,IAGRtM,KAAKuL,KAAKK,8PCoBVY,aAzDX,SAAAA,EAAapL,EAAWD,EAAK4K,gGAAOU,CAAAzM,KAAAwM,GAChCnQ,OAAOqQ,iBAAiB1M,KAAM,CAC1B2M,OAAQ,CACJpQ,YAAY,EACZqQ,cAAc,EACdC,UAAU,EACVjQ,MAAOuE,GAEX2L,aAAc,CACVvQ,YAAY,EACZqQ,cAAc,EACdC,UAAU,EACVjQ,MAAOwE,KAIfpB,KAAK+L,MAAQA,+CA2Bb,OAAOrF,OAAO1G,KAAKpD,yCAUnB,OAAOoD,KAAKpD,oCA5BZ,OAAOoD,KAAK2M,2CAOZ,OAAO3M,KAAK8M,sBCvCb,SAASC,EAAoBC,EAAYC,GACxCD,EAAWrL,OAAS,GACDqL,EAAWE,MAAM,KACzB5D,QAAQ,SAAC6D,GAChB,IAAMC,EAAaD,EAAQD,MAAM,KAC3BG,GAAUD,EAAW,GACrBE,IAAQF,EAAW,IAAMA,EAAW,IAC1C,GAAIE,GAAOD,EACP,IAAK,IAAI1R,EAAI0R,EAAO1R,GAAK2R,EAAK3R,GAAK,EAC/BsR,EAAStR,kQCVvB4R,aAqBF,SAAAA,EAAa3Q,gGAAO4Q,CAAAxN,KAAAuN,GAChBvN,KAAK2M,OAAS/P,0DAdO6Q,GACrB,OAAKA,EAGEpR,OAAOqR,OAAOH,EAAkBI,qBAAsBF,GAFlDF,EAAkBI,4DAsB7B,OAAO3N,KAAK2M,0CAUZ,OAAOjG,OAAO1G,KAAK2M,4CAGNxL,GACb,OAAQA,aAAeoM,KAAwBA,EAAkBK,mBAAmBzM,0CAGlEA,GAClB,OAAOA,aAAeoM,EAAoBpM,EAAMoM,EAAkBK,mBAAmBzM,YAO7FoM,EAAkBM,KAAO,IAAIN,EAAkB,QAC/CA,EAAkBO,GAAK,IAAIP,EAAkB,MAC7CA,EAAkBQ,IAAM,IAAIR,EAAkB,OAO9CA,EAAkBI,qBAAuB,CACrCK,QAAST,EAAkBO,GAC3BG,IAAKV,EAAkBQ,IACvBG,KAAMX,EAAkBM,KACxB3N,UAAWqN,EAAkBO,IAGlBP,2aC5ETY,EAAkB,SAACC,EAASf,EAAOC,GAIrC,IAHA,IAAMe,EAAU,GACZC,EAAOjB,EAEJiB,EAAOhB,GACVe,EAAQhI,KAAKiI,GACbA,GAAQF,EAIZ,OAFAC,EAAQhI,KAAKiI,GAEND,GAGLE,EAAkB,SAACC,EAAc5R,GAOnC,IANA,IAAI6R,EAAU,EACVC,EAAWF,EAAa7M,OAAS,EACjCgN,SACAnN,SAGGiN,GAAWC,GAAU,CAIxB,GAAI9R,IAFJ4E,EAAQgN,EADRG,EAASF,EAAUzK,KAAK4K,OAAOF,EAAWD,GAAW,KAGlCpB,OAASzQ,EAAQ4E,EAAM8L,IACtC,OAAO9L,EACA5E,GAAS4E,EAAM8L,IACtBmB,EAAUE,EAAS,EACZ/R,EAAQ4E,EAAM6L,QACrBqB,EAAWC,EAAS,GAI5B,OAAO,MChCJ,IAUME,EAAiB,CAC1BC,OAAQ,SACRC,QAAS,UACTC,QAAS,QACTC,QAAS,UACTC,QAAS,qBACTC,IAAK,MACLC,KAAM,QAGGC,EAAQ,CACjBC,MAAO,QACPC,UAAW,YACXC,WAAY,aACZC,QAAS,UACTC,UAAW,aAGFC,EACJ,MC0BF,MCnDA,SAASC,EAAiBC,EAAKC,GAClC,IAAMC,EAAS,GACTC,EAAS,GASf,OARAH,EAAI1G,OAAOG,QAAQ,SAACyC,GAChBiE,EAAO3J,KAAK0F,EAAMI,SAASjQ,QAE/B4T,EAAI3G,OAAOG,QAAQ,SAACyC,IAC6B,IAAzCiE,EAAO5J,QAAQ2F,EAAMI,SAASjQ,OAC9B6T,EAAO1J,KAAK0F,EAAMI,SAASjQ,QAG5B6T,ECRX,SAASE,IAAoB,OAAO,EAY7B,SAASC,EAAcC,EAAKC,EAAKC,GAA+D,IAArDC,EAAqD/K,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,IAAAA,UAAA,GAAxBgL,EAAwBhL,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAb8J,EAAMC,MACtFnD,EAAS,GACTZ,EAAO,GACPiF,EAAqBH,GAAYJ,EACjCQ,EAAgBN,EAAIO,gBACpBC,EAAgBP,EAAIM,gBACpBE,EAAoBH,EAAcvU,KAClC2U,EAAoBF,EAAczU,KAClCA,EAAUuU,EAAcvU,KAAxB,IAAgCyU,EAAczU,KAC9C4U,EAAmBlB,EAAgBa,EAAeE,GAExD,GAAIC,IAAsBC,EACtB,MAAM,IAAIE,MAAM,8CA+EpB,OA5EAN,EAActH,OAAOG,QAAQ,SAACyC,GAC1B,IAAMiF,EAAYhH,EAAQ,GAAI+B,EAAMI,WACc,IAA9C2E,EAAiB1K,QAAQ4K,EAAU9U,OAAiBoU,IACpDU,EAAU9U,KAAUuU,EAAcvU,KAAlC,IAA0C8U,EAAU9U,MAExDiQ,EAAO9F,KAAK2K,KAEhBL,EAAcxH,OAAOG,QAAQ,SAACyC,GAC1B,IAAMiF,EAAYhH,EAAQ,GAAI+B,EAAMI,WACc,IAA9C2E,EAAiB1K,QAAQ4K,EAAU9U,MAC9BoU,IACDU,EAAU9U,KAAUyU,EAAczU,KAAlC,IAA0C8U,EAAU9U,KACpDiQ,EAAO9F,KAAK2K,IAGhB7E,EAAO9F,KAAK2K,KAKpBjE,EAAmBoD,EAAIc,YAAa,SAACtV,GACjC,IAAIuV,GAAW,EACXC,SACJpE,EAAmBqD,EAAIa,YAAa,SAACG,GACjC,IAAMC,EAAQ,GACRC,EAAU,GAChBA,EAAQV,GAAqB,GAC7BU,EAAQT,GAAqB,GAC7BJ,EAActH,OAAOG,QAAQ,SAACyC,GAC1BsF,EAAMhL,KAAK0F,EAAMwF,aAAahG,KAAK5P,IACnC2V,EAAQV,GAAmB7E,EAAM7P,QAAU6P,EAAMwF,aAAahG,KAAK5P,KAEvEgV,EAAcxH,OAAOG,QAAQ,SAACyC,IAC+B,IAAnD+E,EAAiB1K,QAAQ2F,EAAMI,SAASjQ,OAAgBoU,GAC1De,EAAMhL,KAAK0F,EAAMwF,aAAahG,KAAK6F,IAEvCE,EAAQT,GAAmB9E,EAAM7P,QAAU6P,EAAMwF,aAAahG,KAAK6F,KAGvE,IAIMI,EAAYC,GAAgBH,EAAQV,IACpCc,EAAYD,GAAgBH,EAAQT,IAC1C,GAAIL,EAAmBgB,EAAWE,EALb,kBAAMvB,EAAIwB,gBACV,kBAAMvB,EAAIuB,gBAFb,IAMyE,CACvF,IAAMC,EAAW,GACjBP,EAAM/H,QAAQ,SAACuI,EAASC,GACpBF,EAASzF,EAAO2F,GAAK5V,MAAQ2V,IAE7BX,GAAY7B,EAAMC,QAAUiB,EAC5BhF,EAAK4F,GAAeS,GAGpBrG,EAAKlF,KAAKuL,GACVV,GAAW,EACXC,EAAcxV,QAEf,IAAK4U,IAAalB,EAAME,WAAagB,IAAalB,EAAMG,cAAgB0B,EAAU,CACrF,IAAMU,EAAW,GACb7I,EAAM0H,EAActH,OAAOxH,OAAS,EACxC0P,EAAM/H,QAAQ,SAACuI,EAASC,GAEhBF,EAASzF,EAAO2F,GAAK5V,MADrB4V,GAAO/I,EACsB8I,EAGA,OAGrCX,GAAW,EACXC,EAAcxV,EACd4P,EAAKlF,KAAKuL,QAKf,IAAIjU,GAAU4N,EAAMY,EAAQ,CAAEjQ,SC3GzC,SAAS6V,EAAW/O,EAAGO,GACnB,IAAMyO,KAAQhP,EACRiP,KAAQ1O,EACd,OAAIyO,EAAKC,GACG,EAERD,EAAKC,EACE,EAEJ,EAqEJ,SAASC,EAAWC,GAAyB,IAApBC,EAAoB7M,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAXwM,EAIrC,OAHII,EAAIxQ,OAAS,GArBrB,SAAS0Q,EAAMF,EAAKG,EAAIC,EAAIH,GACxB,GAAIG,IAAOD,EAAM,OAAOH,EAExB,IAAMK,EAAMF,EAAKtO,KAAK4K,OAAO2D,EAAKD,GAAM,GAKxC,OAJAD,EAAKF,EAAKG,EAAIE,EAAKJ,GACnBC,EAAKF,EAAKK,EAAM,EAAGD,EAAIH,GAzC3B,SAAgBD,EAAKG,EAAIE,EAAKD,EAAIH,GAG9B,IAFA,IAAMK,EAAUN,EACVO,EAAS,GACN/W,EAAI2W,EAAI3W,GAAK4W,EAAI5W,GAAK,EAC3B+W,EAAO/W,GAAK8W,EAAQ9W,GAKxB,IAHA,IAAIqH,EAAIsP,EACJ/O,EAAIiP,EAAM,EAEL7W,EAAI2W,EAAI3W,GAAK4W,EAAI5W,GAAK,EACvBqH,EAAIwP,GACJC,EAAQ9W,GAAK+W,EAAOnP,GACpBA,GAAK,GACEA,EAAIgP,GACXE,EAAQ9W,GAAK+W,EAAO1P,GACpBA,GAAK,GACEoP,EAAOM,EAAO1P,GAAI0P,EAAOnP,KAAO,GACvCkP,EAAQ9W,GAAK+W,EAAO1P,GACpBA,GAAK,IAELyP,EAAQ9W,GAAK+W,EAAOnP,GACpBA,GAAK,GAqBb8G,CAAM8H,EAAKG,EAAIE,EAAKD,EAAIH,GAEjBD,EAcHE,CAAKF,EAAK,EAAGA,EAAIxQ,OAAS,EAAGyQ,GAE1BD,0HC3EX,SAASQ,EAAWC,EAAUC,EAAU3Q,GACpC,IAAI4Q,SACJ,OAAQF,GACR,KAAKpU,EAAeC,WACpB,KAAKN,EAAiBE,SAEdyU,EADa,SAAbD,EACU,SAAC7P,EAAGO,GAAJ,OAAUA,EAAErB,GAASc,EAAEd,IAEvB,SAACc,EAAGO,GAAJ,OAAUP,EAAEd,GAASqB,EAAErB,IAErC,MACJ,QACI4Q,EAAU,SAAC9P,EAAGO,GACV,IAAMyO,KAAQhP,EAAEd,GACV+P,KAAQ1O,EAAErB,GAChB,OAAI8P,EAAKC,EACe,SAAbY,EAAsB,GAAK,EAElCb,EAAKC,EACe,SAAbY,GAAuB,EAAI,EAE/B,GAGf,OAAOC,EAUX,SAASC,EAAUxH,EAAMhC,GACrB,IAAMyJ,EAAU,IAAIC,IACdC,EAAc,GAYpB,OAVA3H,EAAKjC,QAAQ,SAAC6J,GACV,IAAMC,EAAWD,EAAM5J,GACnByJ,EAAQK,IAAID,GACZF,EAAYF,EAAQxW,IAAI4W,IAAW,GAAG/M,KAAK8M,IAE3CD,EAAY7M,KAAK,CAAC+M,EAAU,CAACD,KAC7BH,EAAQM,IAAIF,EAAUF,EAAYvR,OAAS,MAI5CuR,EAYX,SAASK,EAAmBC,EAAcC,EAAcC,GACpD,IAAMrO,EAAM,CACRsO,MAAOH,EAAa,IAQxB,OALAC,EAAaG,OAAO,SAACC,EAAKvF,EAAMwF,GAE5B,OADAD,EAAIvF,GAAQkF,EAAa,GAAGpL,IAAI,SAAA+K,GAAA,OAASA,EAAMO,EAAmBI,GAAK5R,SAChE2R,GACRxO,GAEIA,EA0EJ,SAAS0O,EAAatI,EAAYuB,EAAYgH,EAAeC,EAAgBnN,GAKhFA,EAAUzK,OAAOqR,OAAO,GAJL,CACfwG,QAAQ,EACRC,YAAY,GAEwBrN,GAExC,IAAMsN,EAAS,CACXjI,OAAQ,GACRZ,KAAM,GACN8I,KAAM,IAEJH,EAASpN,EAAQoN,OACjBI,EAAaL,GAAkBA,EAAetS,OAAS,EAEvD4S,EAAa,GAiDnB,GA/CgBP,EAAc9G,MAAM,KAE5B5D,QAAQ,SAACkL,GACb,IAAK,IAAI7Y,EAAI,EAAGA,EAAI8P,EAAW9J,OAAQhG,GAAK,EACxC,GAAI8P,EAAW9P,GAAGO,SAAWsY,EAAS,CAClCD,EAAWlO,KAAKoF,EAAW9P,IAC3B,SAMZ4Y,EAAWjL,QAAQ,SAACyC,GAEhBqI,EAAOjI,OAAO9F,KAAK0F,EAAMI,YAGzB+H,GACAE,EAAOjI,OAAO9F,KAAK,CACfnK,KAAM,MACNkQ,KAAM,eAIdW,EAAmBC,EAAY,SAACrR,GAC5ByY,EAAO7I,KAAKlF,KAAK,IACjB,IAAMoO,EAAYL,EAAO7I,KAAK5J,OAAS,EAEvC4S,EAAWjL,QAAQ,SAACyC,EAAOqF,GACvBgD,EAAO7I,KAAKkJ,GAAWrD,EAFf,GAE6BrF,EAAMwF,aAAahG,KAAK5P,KAE7DuY,IACAE,EAAO7I,KAAKkJ,GAAWF,EAAW5S,QAAUhG,GAGhDyY,EAAOC,KAAKhO,KAAK1K,GAIb2Y,GAAcF,EAAO7I,KAAKkJ,GAAWpO,KAAK1K,KAI9C2Y,GA7HR,SAAkBI,EAAST,GAOvB,IAPuC,IAC/B1I,EAAiBmJ,EAAjBnJ,KAAMY,EAAWuI,EAAXvI,OACVwI,SACAC,SACAC,SACAlZ,EAAIsY,EAAetS,OAAS,EAEzBhG,GAAK,EAAGA,IACXgZ,EAAYV,EAAetY,GAAG,GAC9BiZ,EAAWX,EAAetY,GAAG,IAC7BkZ,EAAWC,GAAc3I,EAAQwI,MXhEf,mBWuEHC,EAEX1C,EAAU3G,EAAM,SAACvI,EAAGO,GAAJ,OAAUqR,EAAS5R,EAAE6R,EAAS3S,OAAQqB,EAAEsR,EAAS3S,UAC1D2I,EAAQ+J,GAAW,WAC1B,IAAM1B,EAAcH,EAAUxH,EAAMsJ,EAAS3S,OACvC6S,EAAYH,EAASA,EAASjT,OAAS,GACvC8R,EAAemB,EAASI,MAAM,EAAGJ,EAASjT,OAAS,GACnD+R,EAAqBD,EAAarL,IAAI,SAAA6M,GAAA,OAAKH,GAAc3I,EAAQ8I,KAEvE/B,EAAY5J,QAAQ,SAACkK,GACjBA,EAAanN,KAAKkN,EAAmBC,EAAcC,EAAcC,MAGrExB,EAAUgB,EAAa,SAAClQ,EAAGO,GACvB,IAAMxH,EAAIiH,EAAE,GACN5F,EAAImG,EAAE,GACZ,OAAOwR,EAAUhZ,EAAGqB,KAIxBmO,EAAK5J,OAAS,EACduR,EAAY5J,QAAQ,SAAC6J,GACjB5H,EAAKlF,KAALqB,MAAA6D,EAAA2J,EAAa/B,EAAM,OAnBG,IAsB1ByB,EAA8C,SAAnClO,OAAOkO,GAAUlT,cAA2B,OAAS,MAChEwQ,EAAU3G,EAAMoH,EAAUkC,EAASzI,KAAMwI,EAAUC,EAAS3S,UAIpEwS,EAAQL,KAAO,GACf9I,EAAKjC,QAAQ,SAAC1M,GACV8X,EAAQL,KAAKhO,KAAKzJ,EAAMuY,SA6ExBC,CAAShB,EAAQH,GAGjBnN,EAAQqN,WAAY,CACpB,IAAMkB,EAAUjM,qBAASA,MAAMgL,EAAOjI,OAAOxK,UAASyG,IAAI,iBAAM,KAChEgM,EAAO7I,KAAKjC,QAAQ,SAAC+H,GACjBA,EAAM/H,QAAQ,SAACiC,EAAM5P,GACjB0Z,EAAQ1Z,GAAG0K,KAAKkF,OAGxB6I,EAAO7I,KAAO8J,EAGlB,OAAOjB,EC1NJ,SAASkB,EAAYnF,EAAKC,GAC7B,IAAMmF,EAAY,GACZpJ,EAAS,GACTqJ,EAAgB,GAChBjK,EAAO,GACPkF,EAAgBN,EAAIO,gBACpBC,EAAgBP,EAAIM,gBACpB+E,EAAwBhF,EAAc5E,YACtC6J,EAAwB/E,EAAc9E,YACtC3P,EAAUuU,EAAcvU,KAAxB,UAAsCyU,EAAczU,KAG1D,IAAKgP,EAAWiF,EAAIwF,eAAezI,MAAM,KAAKmF,OAAQjC,EAAIuF,eAAezI,MAAM,KAAKmF,QAChF,OAAO,KAiBX,SAASuD,EAAkBC,EAAIhK,EAAWiK,GACtC/I,EAAmB8I,EAAG5E,YAAa,SAACtV,GAChC,IAAM0V,EAAQ,GACV0E,EAAW,GACfP,EAAclM,QAAQ,SAAC0M,GACnB,IAAMpZ,EAAQiP,EAAUmK,GAAYzE,aAAahG,KAAK5P,GACtDoa,OAAgBnZ,EAChByU,EAAM2E,GAAcpZ,IAEnB2Y,EAAUQ,KACPD,GAAWvK,EAAKlF,KAAKgL,GACzBkE,EAAUQ,IAAY,KASlC,OAjCC5F,EAAIwF,eAAezI,MAAM,KAAM5D,QAAQ,SAACqL,GACrC,IAAM5I,EAAQ0J,EAAsBd,GACpCxI,EAAO9F,KAAK2D,EAAQ,GAAI+B,EAAMI,WAC9BqJ,EAAcnP,KAAK0F,EAAMI,SAASjQ,QA2BtC0Z,EAAkBxF,EAAKsF,GAAuB,GAC9CE,EAAkBzF,EAAKsF,GAAuB,GAEvC,IAAI9X,GAAU4N,EAAMY,EAAQ,CAAEjQ,8PC5DjCgD,GAAgDD,EAAhDC,IAAKC,GAA2CF,EAA3CE,IAAKG,GAAsCL,EAAtCK,MAAOC,GAA+BN,EAA/BM,KAAMC,GAAyBP,EAAzBO,MAAOC,GAAkBR,EAAlBQ,IAAKL,GAAaH,EAAbG,IAAKC,GAAQJ,EAARI,IAEhD,SAAS4W,GAAkB9D,GACvB,OAAOA,EAAI+D,OAAO,SAAA1L,GAAA,QAAUA,aAAgB+C,KAShD,SAAS4I,GAAKhE,GACV,GAAItH,EAAQsH,MAAUA,EAAI,aAAc/I,OAAQ,CAC5C,IAAMgN,EAAiBH,GAAkB9D,GAIzC,OAHiBiE,EAAezU,OACZyU,EAAexC,OAAO,SAACC,EAAKwC,GAAN,OAAexC,EAAMwC,GAAM,GAC/C9I,EAAkBM,KAG5C,OAAON,EAAkBM,KAU7B,SAASyI,GAAKnE,GACV,GAAItH,EAAQsH,MAAUA,EAAI,aAAc/I,OAAQ,CAC5C,IAAMmN,EAAWJ,GAAIhE,GACfpJ,EAAMoJ,EAAIxQ,QAAU,EAC1B,OAAQgH,OAAO6N,MAAMD,IAAaA,aAAoBhJ,EAC7CA,EAAkBM,KAAO0I,EAAWxN,EAEjD,OAAOwE,EAAkBM,KAgG7B,IAAM4I,WACDvX,GAAMiX,IADLO,EAAAC,EAEDxX,GAAMmX,IAFLI,EAAAC,EAGDvX,GAzFL,SAAc+S,GACV,GAAItH,EAAQsH,MAAUA,EAAI,aAAc/I,OAAQ,CAE5C,IAAMwN,EAAiBX,GAAkB9D,GAEzC,OAAQyE,EAAejV,OAAUqC,KAAK6S,IAALnP,MAAA1D,KAAA8S,GAAYF,IAAkBrJ,EAAkBM,KAErF,OAAON,EAAkBM,OA+EvB6I,EAAAC,EAIDtX,GAzEL,SAAc8S,GACV,GAAItH,EAAQsH,MAAUA,EAAI,aAAc/I,OAAQ,CAE5C,IAAMwN,EAAiBX,GAAkB9D,GAEzC,OAAQyE,EAAejV,OAAUqC,KAAK+S,IAALrP,MAAA1D,KAAA8S,GAAYF,IAAkBrJ,EAAkBM,KAErF,OAAON,EAAkBM,OA8DvB6I,EAAAC,EAKDrX,GAzDL,SAAgB6S,GACZ,OAAOA,EAAI,KAmDTuE,EAAAC,EAMDpX,GA/CL,SAAe4S,GACX,OAAOA,EAAIA,EAAIxQ,OAAS,KAwCtB+U,EAAAC,EAODnX,GArCL,SAAgB2S,GACZ,OAAItH,EAAQsH,GACDA,EAAIxQ,OAER4L,EAAkBM,OA0BvB6I,EAAAC,EAQDlX,GAbL,SAAc0S,GACV,OAAOnO,KAAKgT,KAbhB,SAAmB7E,GACf,IAAI8E,EAAOX,GAAInE,GACf,OAAOmE,GAAInE,EAAI/J,IAAI,SAAA8O,GAAA,OAAAlT,KAAAmT,IAAQD,EAAMD,EAAS,MAWzBG,CAASjF,MAIxBwE,GAWAU,GAAqBnY,6PC1IrBoY,cACF,SAAAA,IAAe,IAAAC,EAAAvX,kGAAAwX,CAAAxX,KAAAsX,GACXtX,KAAKiJ,MAAQ,IAAIgK,IACjBjT,KAAKiJ,MAAMqK,IAAI,aAAcmE,IAE7Bpb,OAAOqb,QAAQjB,IAAQnN,QAAQ,SAACpM,GAC5Bqa,EAAKtO,MAAMqK,IAAIpW,EAAI,GAAIA,EAAI,0DAc/B,IAAKqI,UAAO5D,OACR,OAAO3B,KAAKiJ,MAAMzM,IAAI,cAG1B,IAAImb,0CAEJ,GAAuB,mBAAZA,EACP3X,KAAKiJ,MAAMqK,IAAI,aAAcqE,OAC1B,CAEH,GADAA,EAAUjR,OAAOiR,IAC6B,IAA1Ctb,OAAO4J,KAAKwQ,IAAQrQ,QAAQuR,GAG5B,MAAM,IAAI5G,MAAJ,WAAqB4G,EAArB,0BAFN3X,KAAKiJ,MAAMqK,IAAI,aAAcmD,GAAOkB,IAK5C,OAAO3X,sCAmCD9D,EAAMyb,GAAS,IAAAC,EAAA5X,KACrB,GAAuB,mBAAZ2X,EACP,MAAM,IAAI5G,MAAM,gCAMpB,OAHA7U,EAAOwK,OAAOxK,GACd8D,KAAKiJ,MAAMqK,IAAIpX,EAAMyb,GAEd,WAAQC,EAAKC,aAAa3b,yCAGvBA,GACN8D,KAAKiJ,MAAMoK,IAAInX,IACf8D,KAAKiJ,MAAM6O,OAAO5b,mCAIjBA,GACL,OAAIA,aAAgB0M,SACT1M,EAEJ8D,KAAKiJ,MAAMzM,IAAIN,YAgBf6b,GAZO,WAClB,IAAI9O,EAAQ,KAQZ,OALkB,OAAVA,IACAA,EAAQ,IAAIqO,IAETrO,EAPO,uaCrCtB,SAAS+O,GAASC,EAAWtM,EAAUuM,EAAUC,GAC7C,IAAMC,EAxDV,SAAsBH,EAAWtM,GAC7B,IAAMoE,EAAS,GAETsI,EADaJ,EAAUvH,gBACCrE,eAY9B,OAVAhQ,OAAOqb,QAAQW,GAAY/O,QAAQ,SAAAgP,GAAW,IAATpb,EAASqb,GAAAD,EAAA,MACtC3M,GAAYA,EAAShK,QACU,IAA3BgK,EAASvF,QAAQlJ,IACjB6S,EAAO1J,KAAKnJ,GAGhB6S,EAAO1J,KAAKnJ,KAIb6S,EAyCWyI,CAAYP,EAAWtM,GACnC8M,EAhCV,SAAwBR,GAA0B,IAAfC,EAAe3S,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAJ,GACpC6O,EAAS,GAETsE,EADaT,EAAUvH,gBACD1E,aACtByL,EAAaM,GAAaY,iBAchC,OAZAtc,OAAO4J,KAAKyS,GAAUpP,QAAQ,SAACsP,GACU,iBAA1BV,EAASU,KAChBV,EAASU,GAAeF,EAASE,GAAaC,YAElD,IAAMC,EAAYf,GAAagB,QAAQb,EAASU,IAC5CE,EACA1E,EAAOwE,GAAeE,GAEtB1E,EAAOwE,GAAenB,EACtBS,EAASU,GAAevB,MAGzBjD,EAcY4E,CAAcf,EAAWC,GACtCzM,EAAawM,EAAUvH,gBACvBuI,EAAgBxN,EAAWI,YAC3BqN,EAASzN,EAAWvP,KACpBid,EAAe,GACfC,EAAa,GACbjN,EAAS,GACT6G,EAAU,GACVzH,EAAO,GACT8N,SAGJhd,OAAOqb,QAAQuB,GAAe3P,QAAQ,SAAAgQ,GAAkB,IAAAC,EAAAhB,GAAAe,EAAA,GAAhBpc,EAAgBqc,EAAA,GAAX3c,EAAW2c,EAAA,GACpD,IAAgC,IAA5BnB,EAAUhS,QAAQlJ,IAAeub,EAAWvb,GAG5C,OAFAiP,EAAO9F,KAAK2D,EAAQ,GAAIpN,EAAMuP,WAEtBvP,EAAMuP,SAASC,MACvB,KAAK1N,EAAUC,QACXya,EAAW/S,KAAKnJ,GAChB,MACJ,QACA,KAAKwB,EAAUE,UACXua,EAAa9S,KAAKnJ,MAK9B,IAAIsc,EAAW,EACfzM,EAAmBkL,EAAUhH,YAAa,SAACtV,GACvC,IAAI8d,EAAO,GACXN,EAAa7P,QAAQ,SAACoQ,GAClBD,EAAUA,EAAV,IAAkBR,EAAcS,GAAGnI,aAAahG,KAAK5P,UAEnCuE,IAAlB8S,EAAQyG,IACRzG,EAAQyG,GAAQD,EAChBjO,EAAKlF,KAAK,IACV8S,EAAa7P,QAAQ,SAACoQ,GAClBnO,EAAKiO,GAAUE,GAAKT,EAAcS,GAAGnI,aAAahG,KAAK5P,KAE3Dyd,EAAW9P,QAAQ,SAACoQ,GAChBnO,EAAKiO,GAAUE,GAAK,CAACT,EAAcS,GAAGnI,aAAahG,KAAK5P,MAE5D6d,GAAY,GAEZJ,EAAW9P,QAAQ,SAACoQ,GAChBnO,EAAKyH,EAAQyG,IAAOC,GAAGrT,KAAK4S,EAAcS,GAAGnI,aAAahG,KAAK5P,QAM3E,IAAIge,EAAc,GACdC,EAAgB,kBAAM3B,EAAUtG,gBAcpC,OAbApG,EAAKjC,QAAQ,SAACuQ,GACV,IAAMxI,EAAQwI,EACdT,EAAW9P,QAAQ,SAACoQ,GAChBrI,EAAMqI,GAAKjB,EAAWiB,GAAGG,EAAIH,GAAIE,EAAeD,OAGpDxB,GACAA,EAAkB2B,wBAClBT,EAAelB,GAGfkB,EAAe,IAAI1b,GAAU4N,EAAMY,EAAQ,CAAEjQ,KAAMgd,IAEhDG,EC9HJ,SAASU,GAAmB5J,EAAKC,GACpC,IAIM4J,EAAkBpK,EAJFO,EAAIO,gBACJN,EAAIM,iBAK1B,OAAO,SAACc,EAAWE,GACf,IAAIuI,GAAc,EASlB,OARAD,EAAgB1Q,QAAQ,SAACqL,GAGjBsF,IAFAzI,EAAUmD,GAAW/X,QACrB8U,EAAUiD,GAAW/X,QAASqd,KAM/BA,GCjBR,SAASC,GAAO/J,EAAKC,GACxB,IAAMmF,EAAY,GACZpJ,EAAS,GACTqJ,EAAgB,GAChBjK,EAAO,GACPkF,EAAgBN,EAAIO,gBACpBC,EAAgBP,EAAIM,gBACpB+E,EAAwBhF,EAAc5E,YACtC6J,EAAwB/E,EAAc9E,YACtC3P,EAAUuU,EAAcvU,KAAxB,UAAsCyU,EAAczU,KAG1D,IAAKgP,EAAWiF,EAAIwF,eAAezI,MAAM,KAAKmF,OAAQjC,EAAIuF,eAAezI,MAAM,KAAKmF,QAChF,OAAO,KAgBX,SAASuD,EAAmBC,EAAIhK,GAC5BkB,EAAmB8I,EAAG5E,YAAa,SAACtV,GAChC,IAAM0V,EAAQ,GACV0E,EAAW,GACfP,EAAclM,QAAQ,SAAC0M,GACnB,IAAMpZ,EAAQiP,EAAUmK,GAAYzE,aAAahG,KAAK5P,GACtDoa,OAAgBnZ,EAChByU,EAAM2E,GAAcpZ,IAEnB2Y,EAAUQ,KACXxK,EAAKlF,KAAKgL,GACVkE,EAAUQ,IAAY,KASlC,OAhCC5F,EAAIwF,eAAezI,MAAM,KAAM5D,QAAQ,SAACqL,GACrC,IAAM5I,EAAQ0J,EAAsBd,GACpCxI,EAAO9F,KAAK2D,EAAQ,GAAI+B,EAAMI,WAC9BqJ,EAAcnP,KAAK0F,EAAMI,SAASjQ,QA0BtC0Z,EAAkBzF,EAAKsF,GACvBG,EAAkBxF,EAAKsF,GAEhB,IAAI/X,GAAU4N,EAAMY,EAAQ,CAAEjQ,SCvDlC,SAASie,GAAeC,EAAYC,EAAYhK,GACnD,OAAOH,EAAakK,EAAYC,EAAYhK,GAAU,EAAOhB,EAAME,WAGhE,SAAS+K,GAAgBF,EAAYC,EAAYhK,GACpD,OAAOH,EAAamK,EAAYD,EAAY/J,GAAU,EAAOhB,EAAMG,0QCWlD+K,cAQjB,SAAAA,EAAahJ,EAAcvE,gGAAYwN,CAAAxa,KAAAua,GACnCva,KAAKuR,aAAeA,EACpBvR,KAAKgN,WAAaA,8CAUlB,MAAM,IAAI+D,MAAM,wDAUhB,OAAO/Q,KAAKuR,aAAapF,sCAUzB,OAAOnM,KAAKuR,aAAarV,oCAUzB,OAAO8D,KAAKuR,aAAapF,OAAOC,uCAUhC,OAAOpM,KAAKuR,aAAapF,OAAOsO,8CAUhC,OAAOza,KAAKuR,aAAapF,OAAOuO,kDAUhC,OAAO1a,KAAKuR,aAAapF,OAAOwO,aAAe3a,KAAKuR,aAAapF,OAAOjQ,oCASpE,IAAAqb,EAAAvX,KACEuL,EAAO,GAIb,OAHAwB,EAAmB/M,KAAKgN,WAAY,SAACrR,GACjC4P,EAAKlF,KAAKkR,EAAKhG,aAAahG,KAAK5P,MAE9B4P,0CAUP,MAAM,IAAIwF,MAAM,0RCpHH6J,irBAAkBL,yCAY/B,OAHKva,KAAK6a,gBACN7a,KAAK6a,cAAgB7a,KAAK8a,uBAEvB9a,KAAK6a,4DAUZ,MAAM,IAAI9J,MAAM,+DAWhB,OAAO/Q,KAAKuL,0QChCCwP,irBAAoBH,0CASjC,OAAOzc,EAAiBC,0DAUL,IAAAwZ,EAAA5X,KACbyZ,EAAO,IAAIuB,IACXC,EAAS,GAUf,OAPAlO,EAAmB/M,KAAKgN,WAAY,SAACrR,GACjC,IAAMwX,EAAQyE,EAAKrG,aAAahG,KAAK5P,GAChC8d,EAAKpG,IAAIF,KACVsG,EAAKyB,IAAI/H,GACT8H,EAAO5U,KAAK8M,MAGb8H,qQC7BME,eAQjB,SAAAA,EAAa5J,EAAcvE,gGAAYoO,CAAApb,KAAAmb,GAAA,IAAA5D,mKAAA8D,CAAArb,MAAAmb,EAAAG,WAAAjf,OAAAkf,eAAAJ,IAAArf,KAAAkE,KAC7BuR,EAAcvE,IADe,OAGnCuK,EAAKiE,eAAiB,KAHajE,qUARLqD,sDAqBX,IAAAhD,EAAA5X,KACbyZ,EAAO,IAAIuB,IACXC,EAAS,GAYf,OARAlO,EAAmB/M,KAAKgN,WAAY,SAACrR,GACjC,IAAMwX,EAAQyE,EAAKrG,aAAahG,KAAK5P,GAChC8d,EAAKpG,IAAIF,KACVsG,EAAKyB,IAAI/H,GACT8H,EAAO5U,KAAK8M,MAIb8H,yDAWP,GAAIjb,KAAKwb,eACL,OAAOxb,KAAKwb,eAUhB,IAPA,IAAMC,EAAazb,KAAKuL,OAAO2K,OAAO,SAAA1L,GAAA,QAAUA,aAAgB+C,KAAoB8E,KAAK,SAACrP,EAAGO,GAAJ,OAAUP,EAAIO,IACjGmY,EAAQD,EAAW9Z,OACrBga,EAAUhT,OAAOiT,kBACjBC,SACAC,SACAC,EAAiB,EAEZpgB,EAAI,EAAGA,EAAI+f,EAAO/f,IACvBkgB,EAAYJ,EAAW9f,EAAI,IAC3BmgB,EAAYL,EAAW9f,MAELkgB,IAIlBF,EAAU3X,KAAK6S,IAAI8E,EAASG,EAAYL,EAAW9f,EAAI,IACvDogB,KAQJ,OALKA,IACDJ,EAAU,MAEd3b,KAAKwb,eAAiBG,EAEf3b,KAAKwb,gDAUZ,OAAOxb,KAAKuR,aAAapF,OAAOpM,+CAUnB,IAAAic,EAAAhc,KACPuL,EAAO,GASb,OARAwB,EAAmB/M,KAAKgN,WAAY,SAACrR,GACjC,IAAMwX,EAAQ6I,EAAKzK,aAAahG,KAAK5P,GACjCwX,aAAiB5F,EACjBhC,EAAKlF,KAAK8M,GAEV5H,EAAKlF,KAAKvG,EAAkByG,SAAS4M,EAAO6I,EAAKjc,aAGlDwL,qQC3GM0Q,irBAAerB,sDAS5B,IAAMsB,EAAUlc,KAAKuR,aAAapF,OAAOgQ,KACzC,MAAO,CAACD,EAAQ,GAAIA,EAAQA,EAAQva,OAAS,mCAU7C,OAAO3B,KAAKuR,aAAapF,OAAOgQ,wQClBnBC,irBAAgB7B,yCAY7B,OAHKva,KAAK6a,gBACN7a,KAAK6a,cAAgB7a,KAAK8a,uBAEvB9a,KAAK6a,6CAUZ,OAAO7a,KAAKuR,aAAapF,OAAOkQ,wCAUhC,OAAOrc,KAAKuR,aAAapF,OAAO0M,UAAYxB,0CAShC,IACJiF,EAAiBtc,KAAKuR,aAAapF,OAAnCmQ,aACR,OAAOA,aAAwB1T,SAAW0T,EAAejR,gDAUzD,MAAM,IAAI0F,MAAM,+DAWhB,OAAO/Q,KAAKuL,0QC/DCgR,irBAAmBH,0CAShC,OAAO5d,EAAeC,yDAUH,IAAAmZ,EAAA5X,KACf6W,EAAMlO,OAAOiT,kBACb7E,EAAMpO,OAAO6T,kBAiBjB,OAdAzP,EAAmB/M,KAAKgN,WAAY,SAACrR,GACjC,IAAMwX,EAAQyE,EAAKrG,aAAahG,KAAK5P,GACjCwX,aAAiB5F,IAIjB4F,EAAQ0D,IACRA,EAAM1D,GAENA,EAAQ4D,IACRA,EAAM5D,MAIP,CAAC0D,EAAKE,sQC5CA0F,4KAQb,MAAM,IAAI1L,MAAM,0RCJH2L,irBAA0BD,sCAQpCtb,GAQH,OALKoM,EAAkBoP,UAAUxb,GAGpBoM,EAAkBqP,eAAezb,GAFjCuF,OAAOvF,GAAK0b,0QCXZC,eAOjB,SAAAA,EAAa3Q,gGAAQ4Q,CAAA/c,KAAA8c,GAAA,IAAAvF,mKAAAyF,CAAAhd,MAAA8c,EAAAxB,WAAAjf,OAAAkf,eAAAuB,IAAAhhB,KAAAkE,OAAA,OAEjBuX,EAAKpL,OAASA,EACdoL,EAAK0F,KAAO,IAAInd,EAAkByX,EAAKpL,OAAOpM,QAH7BwX,qUAPmBkF,sCAoBjCtb,GACH,IAAIyC,SAEJ,GAAK2J,EAAkBoP,UAAUxb,GAI7ByC,EAAS2J,EAAkBqP,eAAezb,OAJP,CACnC,IAAIhB,EAAaH,KAAKid,KAAKvU,cAAcvH,GACzCyC,EAASzD,EAAaA,EAAW4K,UAAYwC,EAAkBO,GAInE,OAAOlK,qQC9BMsZ,irBAAqBT,sCAQ/Btb,GAEHA,EAAMuF,OAAOvF,GACb,IAAIyC,SAEJ,GAAK2J,EAAkBoP,UAAUxb,GAK7ByC,EAAS2J,EAAkBqP,eAAezb,OALP,CACnC,IAAIgc,EAAUhc,EAAIqH,MALR,2DAMV5E,EAASuZ,EAAaxU,OAAOyU,WAAWD,EAAQ,IAAvC,IAA8CxU,OAAOyU,WAAWD,EAAQ,IAC9D5P,EAAkBO,GAIzC,OAAOlK,qQCpBMyZ,irBAAyBZ,sCAQnCtb,GACH,IAAIyC,SAEJ,GAAK2J,EAAkBoP,UAAUxb,GAI7ByC,EAAS2J,EAAkBqP,eAAezb,OAJP,CACnC,IAAIC,EAAYgc,WAAWjc,EAAK,IAChCyC,EAAS+E,OAAO6N,MAAMpV,GAAamM,EAAkBO,GAAK1M,EAI9D,OAAOwC,qQCnBM0Z,cAUjB,SAAAA,EAAaphB,EAAMqP,EAAMY,EAAQ/J,gGAAQmb,CAAAvd,KAAAsd,GACrCtd,KAAK9D,KAAOA,EACZ8D,KAAKmM,OAASA,EACdnM,KAAKoC,OAASA,EACdpC,KAAKuL,KAAOvL,KAAKwd,UAAUjS,gDAUpBA,GAAM,IAAAgM,EAAAvX,KACb,OAAOuL,EAAKnD,IAAI,SAAA+K,GAAA,OAASoE,EAAKnV,OAAOwE,MAAMuM,cCiE5C,SAASsK,GAAaC,EAAYvR,EAAQwR,GAC7C,IAAMC,EAAa,GAUnB,OARMD,GAAWA,EAAQhc,SACrBgc,EAAUxR,EAAO/D,IAAI,SAAAoC,GAAA,OAAQA,EAAKtO,QAGtCyhB,EAAQrU,QAAQ,SAACuU,EAAQliB,GACrBiiB,EAAWC,GAAUliB,IAGlBwQ,EAAO/D,IAAI,SAAAoC,GAAA,OAzFtB,SAAyBe,EAAMY,GAC3BZ,EAAOA,GAAQ,GACf,IAAIgG,SAEJ,OAAQpF,EAAOC,MACf,KAAK1N,EAAUC,QACX,OAAQwN,EAAOsO,SACf,KAAKjc,EAAeC,WAGpB,QAEI,OADA8S,EAAe,IAAI+L,GAAanR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAIkR,IACxD,IAAId,GAAWhL,EAAf,MAAkChG,EAAK5J,OAAS,IAE/D,KAAKjD,EAAUE,UACX,OAAQuN,EAAOsO,SACf,KAAKtc,EAAiBC,YAElB,OADAmT,EAAe,IAAI+L,GAAanR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAIuQ,IACxD,IAAI3B,GAAYxJ,EAAhB,MAAmChG,EAAK5J,OAAS,IAC5D,KAAKxD,EAAiBE,SAElB,OADAkT,EAAe,IAAI+L,GAAanR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAI2Q,GAAe3Q,IACvE,IAAIgP,GAAS5J,EAAb,MAAgChG,EAAK5J,OAAS,IACzD,KAAKxD,EAAiBI,OAElB,OADAgT,EAAe,IAAI+L,GAAanR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAI+Q,IACxD,IAAIjB,GAAO1K,EAAX,MAA8BhG,EAAK5J,OAAS,IACvD,QAEI,OADA4P,EAAe,IAAI+L,GAAanR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAIuQ,IACxD,IAAI3B,GAAYxJ,EAAhB,MAAmChG,EAAK5J,OAAS,IAEhE,QAEI,OADA4P,EAAe,IAAI+L,GAAanR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAIuQ,IACxD,IAAI3B,GAAYxJ,EAAhB,MAAmChG,EAAK5J,OAAS,KA0DlCmc,CAAgBJ,EAAWE,EAAWpT,EAAKtO,OAAQsO,KC3GlE,IAAAuT,GAAA,CACXC,WAAYlgB,EAAWI,MCuCZ+f,OAvBf,SAAiB9L,EAAKrL,GAIlBA,EAAUzK,OAAOqR,OAAO,GAHF,CAClBwQ,gBAAgB,GAEuBpX,GAE3C,IAAI+W,SACEM,EAAU,GACV9X,EAAO+X,EAAYD,GAYzB,OAPIN,EAHA/W,EAAQoX,eAGC/L,EAAI1K,OAAO,EAAG,GAAG,GAEjB,GAGb0K,EAAI7I,QAAQ,SAAAyC,GAAA,OAAS1F,sIAAQ0F,MAEtB,CAAC8R,EAAQM,ICvChBE,GAAM,GACNC,GAAM,GACNC,GAAQ,GACRC,GAAU,GACVC,GAAS,GAEb,SAASC,GAAgBP,GACvB,OAAO,IAAIvV,SAAS,IAAK,WAAauV,EAAQ/V,IAAI,SAASlM,EAAMP,GAC/D,OAAOgjB,KAAKC,UAAU1iB,GAAQ,OAASP,EAAI,MAC1CsH,KAAK,KAAO,KA0BF,IAAA4b,GAAA,SAASC,GACtB,IAAIC,EAAW,IAAI3e,OAAO,KAAQ0e,EAAY,SAC1CE,EAAYF,EAAUG,WAAW,GAWrC,SAASC,EAAU5e,EAAM2U,GACvB,IAIIpY,EAJAsiB,EAAO,GACPC,EAAI9e,EAAKqB,OACT0d,EAAI,EACJjiB,EAAI,EAEJkiB,EAAMF,GAAK,EACXG,GAAM,EAMV,SAASjZ,IACP,GAAIgZ,EAAK,OAAOhB,GAChB,GAAIiB,EAAK,OAAOA,GAAM,EAAOlB,GAG7B,IAAI1iB,EAAUK,EAAPwjB,EAAIH,EACX,GAAI/e,EAAK2e,WAAWO,KAAOjB,GAAO,CAChC,KAAOc,IAAMD,GAAK9e,EAAK2e,WAAWI,KAAOd,IAASje,EAAK2e,aAAaI,KAAOd,KAI3E,OAHK5iB,EAAI0jB,IAAMD,EAAGE,GAAM,GACdtjB,EAAIsE,EAAK2e,WAAWI,QAAUb,GAASe,GAAM,EAC9CvjB,IAAMyiB,KAAUc,GAAM,EAAUjf,EAAK2e,WAAWI,KAAOb,MAAWa,GACpE/e,EAAK0U,MAAMwK,EAAI,EAAG7jB,EAAI,GAAG4E,QAAQ,MAAO,KAIjD,KAAO8e,EAAID,GAAG,CACZ,IAAKpjB,EAAIsE,EAAK2e,WAAWtjB,EAAI0jB,QAAUb,GAASe,GAAM,OACjD,GAAIvjB,IAAMyiB,GAAUc,GAAM,EAAUjf,EAAK2e,WAAWI,KAAOb,MAAWa,OACtE,GAAIrjB,IAAMgjB,EAAW,SAC1B,OAAO1e,EAAK0U,MAAMwK,EAAG7jB,GAIvB,OAAO2jB,GAAM,EAAMhf,EAAK0U,MAAMwK,EAAGJ,GAGnC,IA7BI9e,EAAK2e,WAAWG,EAAI,KAAOZ,MAAWY,EACtC9e,EAAK2e,WAAWG,EAAI,KAAOX,MAAUW,GA4BjCviB,EAAIyJ,OAAagY,IAAK,CAE5B,IADA,IAAIzE,EAAM,GACHhd,IAAMwhB,IAAOxhB,IAAMyhB,IAAKzE,EAAIxT,KAAKxJ,GAAIA,EAAIyJ,IAC5C2O,GAA4B,OAAtB4E,EAAM5E,EAAE4E,EAAKzc,OACvB+hB,EAAK9Y,KAAKwT,GAGZ,OAAOsF,EAgBT,SAASM,EAAU5F,GACjB,OAAOA,EAAIzR,IAAIsX,GAAazc,KAAK6b,GAGnC,SAASY,EAAYpf,GACnB,OAAe,MAARA,EAAe,GAChBye,EAASY,KAAKrf,GAAQ,IAAM,IAAOA,EAAKC,QAAQ,KAAM,MAAU,IAChED,EAGR,MAAO,CACLsG,MAlFF,SAAetG,EAAM2U,GACnB,IAAI2K,EAASzB,EAASgB,EAAOD,EAAU5e,EAAM,SAASuZ,EAAKle,GACzD,GAAIikB,EAAS,OAAOA,EAAQ/F,EAAKle,EAAI,GACrCwiB,EAAUtE,EAAK+F,EAAU3K,EA9B/B,SAAyBkJ,EAASlJ,GAChC,IAAI5X,EAASqhB,GAAgBP,GAC7B,OAAO,SAAStE,EAAKle,GACnB,OAAOsZ,EAAE5X,EAAOwc,GAAMle,EAAGwiB,IA2BM0B,CAAgBhG,EAAK5E,GAAKyJ,GAAgB7E,KAGzE,OADAsF,EAAKhB,QAAUA,GAAW,GACnBgB,GA6EPD,UAAWA,EACXnf,OA1BF,SAAgBof,EAAMhB,GAEpB,OADe,MAAXA,IAAiBA,EA9EzB,SAAsBgB,GACpB,IAAIW,EAAYzjB,OAAOY,OAAO,MAC1BkhB,EAAU,GAUd,OARAgB,EAAK7V,QAAQ,SAASuQ,GACpB,IAAK,IAAIkG,KAAUlG,EACXkG,KAAUD,GACd3B,EAAQ9X,KAAKyZ,EAAUC,GAAUA,KAKhC5B,EAkE0B6B,CAAab,IACrC,CAAChB,EAAQ/V,IAAIsX,GAAazc,KAAK6b,IAAYjW,OAAOsW,EAAK/W,IAAI,SAASyR,GACzE,OAAOsE,EAAQ/V,IAAI,SAAS2X,GAC1B,OAAOL,EAAY7F,EAAIkG,MACtB9c,KAAK6b,MACN7b,KAAK,OAqBTgd,WAlBF,SAAoBd,GAClB,OAAOA,EAAK/W,IAAIqX,GAAWxc,KAAK,SCzGhCid,GAAMC,GAAI,KCAVC,IDEkBF,GAAItZ,MACAsZ,GAAIhB,UACPgB,GAAIngB,OACAmgB,GAAID,WCLrBE,GAAI,OAEQC,GAAIxZ,MACAwZ,GAAIlB,UACPkB,GAAIrgB,OACAqgB,GAAIH,WC4BhBI,OAXf,SAAiB1V,EAAK7D,GAKlBA,EAAUzK,OAAOqR,OAAO,GAJF,CAClBwQ,gBAAgB,EAChBoC,eAAgB,KAEuBxZ,GAE3C,IAAMqZ,EAAMI,GAAMzZ,EAAQwZ,gBAC1B,OAAOrC,GAAOkC,EAAIjB,UAAUvU,GAAM7D,ICoBvB0Z,OAxBf,SAAmBrO,GACf,IAAM0L,EAAS,GACXliB,EAAI,EACJ8kB,SACEtC,EAAU,GACV9X,EAAO+X,EAAYD,GAgBzB,OAdAhM,EAAI7I,QAAQ,SAACkB,GACT,IAAMrB,EAAS,GACf,IAAK,IAAIjM,KAAOsN,EACRtN,KAAO2gB,EACP4C,EAAiB5C,EAAO3gB,IAExB2gB,EAAO3gB,GAAOvB,IACd8kB,EAAiB9kB,EAAI,GAEzBwN,EAAOsX,GAAkBjW,EAAKtN,GAElCmJ,eAAQ8C,KAGL,CAAC9M,OAAO4J,KAAK4X,GAASM,IC1BlBuC,OAXf,SAAenV,EAAMzE,GACjB,IAAM6Z,EAAa,CAAEH,YAAUH,UAAQpC,WACjCD,EAAa1S,EAAiBC,GAEpC,IAAKyS,EACD,MAAM,IAAIjN,MAAM,mCAGpB,OAAO4P,EAAW3C,GAAYzS,EAAMzE,iiBCIjC,SAAS2K,GAAiBtI,GAC7B,IAAMyX,EAAO,GAEb,OADAvkB,OAAO4J,KAAKkD,GAAQG,QAAQ,SAACpM,GAAU0jB,EAAK1jB,GAAO,IAAIsP,EAAMrD,EAAOjM,GAAMA,KACnE0jB,EAGJ,IAAMC,GAAe,SAAAvH,EAA8BwH,EAAmBC,GAAmB,IAAAxH,EAAAyH,GAAA1H,EAAA,GAAlEtM,EAAkEuM,EAAA,GAAtDvF,EAAsDuF,EAAA,GACxF0H,EAASjN,EAAcrS,OAASqS,EAAc9G,MAAM,KAAO,GAC3DgU,EAAkBJ,EAAkBjV,YACpCsV,EAAYF,EAAO7Y,IAAI,SAAAgZ,GAAA,OT8BxB,SAAoC7P,EAAcvE,GAAY,IACzDb,EAAWoF,EAAXpF,OAER,OAAQA,EAAOC,MACf,KAAK1N,EAAUC,QACX,OAAQwN,EAAOsO,SACf,KAAKjc,EAAeC,WAEpB,QACI,OAAO,IAAI8d,GAAWhL,EAAcvE,GAE5C,KAAKtO,EAAUE,UACX,OAAQuN,EAAOsO,SACf,KAAKtc,EAAiBC,YAClB,OAAO,IAAI2c,GAAYxJ,EAAcvE,GACzC,KAAK7O,EAAiBE,SAClB,OAAO,IAAI8c,GAAS5J,EAAcvE,GACtC,KAAK7O,EAAiBI,OAClB,OAAO,IAAI0d,GAAO1K,EAAcvE,GACpC,QACI,OAAO,IAAI+N,GAAYxJ,EAAcvE,GAE7C,QACI,OAAO,IAAI+N,GAAYxJ,EAAcvE,ISrDNqU,CAA2BH,EAAgBE,GAAM7P,aAAcvE,KAClG,OAAOvB,EAAWC,gBAAgByV,EAAWJ,IAoBpCO,GAAqB,SAACC,EAAUC,EAAOC,IAjBZ,SAACD,EAAOC,GAAuC,IACzCC,EADajU,EAA4BlI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAnB,GAAIoc,EAAepc,UAAA,GAC/Ekc,IAAc5S,EAAeI,SAC7BuS,EAAMI,YAAYjgB,OAAS,GAC3B+f,EAAAF,EAAMI,aAAYvb,KAAlBqB,MAAAga,EAAAG,GAA0BF,KAE1BH,EAAMI,YAAYvb,KAAK,CACnByb,GAAIL,EACJM,KAAMtU,EACNuU,SAAUL,IAUlBM,CAAyBT,EAAOC,EADuDlc,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAnB,GAAmBA,UAAA,IAJlD,SAACgc,EAAUW,GAAU,IAAAC,GAC1DA,EAAAD,EAAME,qBAAoB/b,KAA1BqB,MAAAya,EAAAN,GAAkCN,EAASa,qBAA3CvZ,OAAAgZ,GAAmEN,EAASK,eAK5ES,CAA0Bd,EAAUC,IAG3Bc,GAAe,SAACtV,EAAY7D,EAAQoZ,EAAU9U,EAAQ8T,GAC/D,IAAMiB,EAAgB,GAClBC,GAAqB,EACnB3lB,EAAS2Q,EAAT3Q,KACF4lB,SACA/I,EAAc,GACdC,EAAgB,kBAAM2H,EAAS5P,gBAE7BgR,EAAgBxZ,EAAOf,IAAI,SAAA2D,GAAA,OAASA,EAAMR,SAC1CqX,EAAsBzZ,EAAOf,IAAI,SAAA2D,GAAA,OAASA,EAAM8W,kBAChDC,EAAmB,SAAA5gB,GAAA,OAASqgB,EAtDtC,SAA+BpZ,EAAQ0Z,EAAeE,EAASpnB,GAC3D,IAAMilB,EAAO,GADiDoC,GAAA,EAAAC,GAAA,EAAAC,OAAAhjB,EAAA,IAG9D,QAAAijB,EAAAC,EAA2Bja,EAAOuO,UAAlChb,OAAA2mB,cAAAL,GAAAG,EAAAC,EAAA9U,QAAAgV,MAAAN,GAAA,EAA6C,KAAA1K,EAAA6K,EAAAvmB,MAAA2mB,EAAAvC,GAAA1I,EAAA,GAAjCpb,EAAiCqmB,EAAA,GAA5BxX,EAA4BwX,EAAA,GACzC3C,EAAK7U,EAAM7P,QAAU,IAAIsQ,EAAMqW,EAAc3lB,GAAKvB,GAAIonB,EAAQ7lB,GAAKvB,GAAIoQ,IAJb,MAAAyX,GAAAP,GAAA,EAAAC,EAAAM,EAAA,aAAAR,GAAAI,EAAAK,QAAAL,EAAAK,SAAA,WAAAR,EAAA,MAAAC,GAM9D,OAAOtC,EAiDH8C,CAAqBva,EAAQyZ,EAAqBD,EAAezgB,GACjEA,EACA0X,EACAD,IAGAgK,SAkBJ,OAhBIA,EADA7mB,IAAS+B,EAAcE,QACb,SAAAmD,GAAA,OAAU4gB,EAAiB5gB,IAE3B,SAAAA,GAAA,OAAS4gB,EAAiB5gB,IAGxC6K,EAAmBC,EAAY,SAACrR,GACxBgoB,EAAQhoB,MACmB,IAAvB8mB,GAA4B9mB,IAAO8mB,EAAoB,GACvDC,EAAKF,EAAc7gB,OAAS,EAC5B6gB,EAAcE,GAASF,EAAcE,GAAIxV,MAAM,KAAK,GAApD,IAA0DvR,GAE1D6mB,EAAcnc,KAAd,GAAsB1K,GAE1B8mB,EAAoB9mB,KAGrB6mB,EAAcvf,KAAK,MAGjB2gB,GAAqB,SAACpC,GAC/B,IAAMqC,EAAWrC,EAAMsC,OAAM,GACvBhD,EAAoBU,EAAMuC,uBAShC,OARAF,EAASlO,eAAiBmL,EAAkB3X,OAAOf,IAAI,SAAA6M,GAAA,OAAKA,EAAE/Y,SAAQ+G,KAAK,KAG3E6d,EAAkBhV,iBAAmB,KACrCgV,EAAkBvU,iBAAmB,KACrCuU,EAAkB5U,eAAiB,KACnC2X,EAAS/J,wBAAwBkK,wBAE1BH,GAGEI,GAAyB,SAACzC,EAAO0C,GAA4B,IAAhBzW,EAAgBlI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAP,GACzDkc,EAAYhU,EAAOgU,WAAa9R,EAChCwU,EAAkB1W,EAAO0W,kBAAmB,EAC9CC,EAAM,GAINA,EAHCF,EAAWviB,OAGNuiB,EAAW9b,IAAI,SAAAic,GAAA,OACX3P,GAD0BuD,EA6BjCoM,GA5B2BC,UACpBnY,EAASuI,EAAQvI,OACjBoY,EAAetM,EAAUuM,kBACzBC,EAAcxM,EAAUvH,gBAAgB7E,YACxCN,EAAOmJ,EAAQnJ,KACf0P,EAAS5e,OAAOqoB,OAAOH,GAAc3Q,OAAO,SAACC,EAAK8Q,GAEpD,OADA9Q,EAAI8Q,EAAEC,IAAI1oB,MAAQuoB,EAAYE,EAAEC,IAAI1oB,MAAM+e,SACnCpH,GACR,IAEI,SAAC1K,GAgBJ,QAfiBoC,EAAK5J,QAAiB4J,EAAKsZ,KAAK,SAAAhL,GAAA,OAAO1N,EAAO2Y,MAAM,SAACC,GAClE,KAAMA,EAAU7oB,QAAQiN,GACpB,OAAO,EAEX,IAAMvM,EAAQuM,EAAO4b,EAAU7oB,MAAM8oB,UACrC,GAAIb,GAAmBY,EAAU3Y,OAAS1N,EAAUC,QAChD,OAAO/B,GAASqe,EAAO8J,EAAU7oB,MAAM,IAAMU,GAASqe,EAAO8J,EAAU7oB,MAAM,GAGjF,GAAI6oB,EAAU3Y,OAAS1N,EAAUE,UAC7B,OAAO,EAEX,IAAMkV,EAAMyQ,EAAaQ,EAAU7oB,MAAMgG,MACzC,OAAO2X,EAAI/F,KAAS3K,EAAO4b,EAAU7oB,MAAM8oB,eAzBpB,IAAC/M,EAC1BvD,EACAvI,EACAoY,EACAE,EACAlZ,EACA0P,IARJ,CAAC,kBAAM,IA+CjB,OAZIwG,IAAc9R,EACEiU,GAAmBpC,GAAOyD,OAAO,SAAA9b,GAAA,OAAUib,EAAIU,MAAM,SAAAI,GAAA,OAAMA,EAAG/b,MAAU,CACpFgc,WAAW,EACXroB,KAAM+B,EAAcG,MAGR4kB,GAAmBpC,GAAOyD,OAAO,SAAA9b,GAAA,OAAUib,EAAIS,KAAK,SAAAK,GAAA,OAAMA,EAAG/b,MAAU,CACnFrM,KAAM+B,EAAcG,IACpBmmB,WAAW,KAOVC,GAAkB,SAAC7D,EAAUgB,EAAU8C,EAAcC,GAC9D,IAAMC,EAAShE,EAASuC,MAAMwB,EAAYH,WACpCnY,EAAasV,GACfiD,EAAOtU,YACPsU,EAAOxB,uBAAuB5a,OAC9BoZ,EACA8C,EACA9D,GAaJ,OAXAgE,EAAOtU,YAAcjE,EACrBuY,EAAOzL,wBAAwBkK,wBAE/B1C,GACIC,EACAgE,EACA1W,EAAeC,OACd,CAAErB,OAAQ4X,GACT9C,GAGCgD,GAGEC,GAAmB,SAACjE,EAAUkE,EAAWhY,EAAQiY,GAC1D,IAAMH,EAAShE,EAASuC,MAAMrW,EAAO0X,WACjCQ,EAAgBF,EAiBpB,OAhBIhY,EAAO3Q,OAAS+B,EAAcE,UAC9B4mB,EAAgBD,EAAUxP,OAAO,SAAAvB,GAAA,OAA+C,IAAlC8Q,EAAUrf,QAAQuO,MAIpE4Q,EAAO5P,eAAiBgQ,EAAc1iB,KAAK,KAC3CsiB,EAAOzL,wBAAwBkK,wBAE/B1C,GACIC,EACAgE,EACA1W,EAAeE,QACf,CAAE0W,YAAWhY,SAAQmY,gBAAiBD,GACtC,MAGGJ,GAGEM,GAAqB,SAACC,GAO/B,IALAA,EAAa9b,EAAQ,GAAI8b,IACT1Z,OACZ0Z,EAAW1Z,KAAO1N,EAAUE,YAG3BknB,EAAWrL,QACZ,OAAQqL,EAAW1Z,MACnB,KAAK1N,EAAUC,QACXmnB,EAAWrL,QAAUjc,EAAeC,WACpC,MACJ,QACA,KAAKC,EAAUE,UACXknB,EAAWrL,QAAUtc,EAAiBC,YAK9C,OAAO0nB,GA6BEC,GAA4B,SAAA5Z,GAAA,OAAUA,EAAO/D,IAAI,SAAC0d,GAG3D,OA7B8B,SAACA,GAC/B,IAAME,EAA2B,CAACxnB,EAAeC,YAC3CwnB,EAAuB,CACzB9nB,EAAiBC,YACjBD,EAAiBI,OACjBJ,EAAiBE,SACjBF,EAAiBG,KAEb8N,EAAwB0Z,EAAxB1Z,KAAMqO,EAAkBqL,EAAlBrL,QAASve,EAAS4pB,EAAT5pB,KAEvB,OAAQkQ,GACR,KAAK1N,EAAUE,UACX,IAA+C,IAA3CqnB,EAAqB7f,QAAQqU,GAC7B,MAAM,IAAI1J,MAAJ,qDAA+D0J,EAA/D,aAAmFve,EAAnF,UAEV,MACJ,KAAKwC,EAAUC,QACX,IAAmD,IAA/CqnB,EAAyB5f,QAAQqU,GACjC,MAAM,IAAI1J,MAAJ,mDAA6D0J,EAA7D,aAAiFve,EAAjF,UAEV,MACJ,QACI,MAAM,IAAI6U,MAAJ,wCAAkD3E,EAAlD,aAAmElQ,EAAnE,WAMVgqB,CADAJ,EAAaD,GAAmBC,IAEzBA,KAeEK,GAAa,SAACC,EAAU7a,EAAMY,EAAQrF,GAC/CqF,EAAS4Z,GAA0B5Z,GACnCrF,EAAUzK,OAAOqR,OAAOrR,OAAOqR,OAAO,GAAI2Y,IAAgBvf,GAC1D,IAAMwf,EAAcC,EAAUzf,EAAQkX,YAEtC,IAAMsI,GAAsC,mBAAhBA,EACxB,MAAM,IAAIvV,MAAJ,mCAA6CjK,EAAQkX,WAArD,WANiD,IAAAwI,EAS3BF,EAAY/a,EAAMzE,GATS2f,EAAAzF,GAAAwF,EAAA,GASpD3I,EAToD4I,EAAA,GAS5C5D,EAT4C4D,EAAA,IAZ/B,SAACta,EAAQua,GACrCva,EAAO7C,QAAQ,SAACwc,GACZ,IAAMa,EAAcb,EAAWc,GAC/B,GAAKD,EAAL,CAEA,IAAM7S,EAAM4S,EAAWtgB,QAAQ0f,EAAW5pB,MAC1CwqB,EAAW5S,GAAO6S,EAClBb,EAAW5pB,KAAOyqB,SACXb,EAAWc,MActBC,CAAiB1a,EAAQ0R,GACzB,IAAMlS,EAAW8R,GAAaoF,EAAe1W,EAAQ0R,GAG/CiJ,EAAYrb,EAAWC,gBAAgBC,EAAU7E,EAAQ5K,MAM/D,OALAkqB,EAASW,mBAAqBD,EAE9BV,EAASnV,YAAc4R,EAAclhB,QAAUkhB,EAAc,GAAGlhB,OAAzC,MAAuDkhB,EAAc,GAAGlhB,OAAS,GAAM,GAC9GykB,EAASzQ,eAAkBxJ,EAAO/D,IAAI,SAAAsR,GAAA,OAAKA,EAAExd,OAAO+G,OACpDmjB,EAASY,YAAclgB,EAAQkX,aAAelgB,EAAWI,KAAOoN,EAAiBC,GAAQzE,EAAQkX,WAC1FoI,GAGEtR,GAAgB,SAAC3I,EAAQJ,GAGlC,IAFA,IAAIpQ,EAAI,EAEDA,EAAIwQ,EAAOxK,SAAUhG,EACxB,GAAIoQ,IAAUI,EAAOxQ,GAAGO,KACpB,MAAO,CACHkQ,KAAMD,EAAOxQ,GAAG8e,SAAWtO,EAAOxQ,GAAGyQ,KACrClK,MAAOvG,GAInB,OAAO,MA6BLsrB,GAAgC,SAAC5C,EAAWpM,GAC9C,IAAMiP,EAAcjP,EAAUkP,iBAC1BC,EAAiB/C,EAAU,GAC3BgD,EAAiBhD,EAAU,GAkB/B,OAhBA6C,EAAY5d,QAAQ,SAACge,GACjB,GAAKA,EAAL,CADgC,IAMjBC,EAAAC,EANiBC,EA9BF,SAACH,GACnC,IAAII,EAAS,GACTjG,SAEJ,OADAA,EAAY6F,EAAWxF,IAEvB,KAAKjT,EAAeC,OAChB4Y,EAAS,CAACJ,EAAWtF,UACrB,MACJ,KAAKnT,EAAeE,QAChB2Y,EAAS,CAACJ,EAAWvF,KAAK6D,iBAC1B,MACJ,KAAK/W,EAAeG,QAChByS,EAAY,UACZiG,EAAS,CAACJ,EAAWvF,KAAK4F,cAAcza,MAAM,KAAMoa,EAAWtF,UAC/D,MACJ,QACIP,EAAY,KAGhB,MAAO,CACHA,YACAiG,UAc8BE,CAAuBN,GAA7C7F,EALwBgG,EAKxBhG,UAAWiG,EALaD,EAKbC,OACnB,GAAIjG,EACA2F,GAAiBG,EAAAH,GAAe3F,GAAf/Z,MAAA6f,EAAA1F,GAA6B6F,GAA7B7e,OAAA,CAAqC,CAClDsc,WAAW,MAEfkC,GAAiBG,EAAAH,GAAe5F,GAAf/Z,MAAA8f,EAAA3F,GAA6B6F,GAA7B7e,OAAA,CAAqC,CAClDsc,WAAW,SAKhB,CAACiC,EAAgBC,IAWtBQ,GAAuB,SAAvBA,EAAwB5P,EAAWoM,GAA8C,IAAnC5W,EAAmClI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAA1B,GAAIuiB,EAAsBviB,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAP,GACtEwiB,EAAqBD,EAAaC,mBAClCC,EAAgBF,EAAaE,eAAiB,GAEhD/P,IAAc8P,MAIAC,EAAcrmB,SAA+C,IAAtCqmB,EAAc5hB,QAAQ6R,KAElDA,EAAUgQ,kBAAkB5D,EAAW5W,GAEnCwK,EAAUiQ,UAClB5e,QAAQ,SAAC6e,GAAU,IAAAC,EACenB,GAA8B5C,EAAW8D,GADxDE,EAAArH,GAAAoH,EAAA,GACnBhB,EADmBiB,EAAA,GACHhB,EADGgB,EAAA,GAExBR,EAAqBM,EAAO,CAACf,EAAgBC,GAAiB5Z,EAAQqa,OAkBjEQ,GAAqB,SAAC9G,GAC/B,IADoD,IAAd+G,EAAchjB,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAP,GACtCic,EAAMgH,SACTD,EAAKliB,KAAKmb,GACVA,EAAQA,EAAMgH,QAElB,OAAOD,GAGEE,GAA2B,SAACC,EAAaC,EAAYC,EAAgBnb,GAC9E,IAAIuU,SACAqC,SACIwE,EAA4CD,EAA5CC,qBAAsBC,EAAsBF,EAAtBE,kBACxBC,EAAsBH,EAAeI,SACrCC,EAA8Bxb,EAAOwb,4BAMvCC,EAAY,GAEhB,GAAoB,OAAhBR,IAA8C,IAAtBjb,EAAO0b,WAC/BD,EAAY,CAAC,CACTlH,SAAU,SAEX,KAAAoH,EACCC,EAAkBhtB,OAAOqoB,OAAOmE,EAAqBS,iBAC/B,IAAtBR,IACAO,EAAkBA,EAAgBnT,OAAO,SAAAja,GAAA,OAAKA,EAAEwR,OAAOub,WAAaD,KAGxE,IAAMQ,EAAmBF,EAAgBnT,OAjB5B,SAACsT,GAEd,OADe/b,EAAO4C,UAAa,kBAAM,IAC3BmZ,EAAO/b,KAeqCrF,IAAI,SAAAqhB,GAAA,OAAUA,EAAOhc,OAAOuU,WAEhFgG,EAAgB,GAEtB,IAA0B,IAAtBc,EAA6B,CAC7B,IAAMY,EAAwBrtB,OAAOqoB,OAAOmE,EAAqBS,gBAEjEI,EAAsBpgB,QAAQ,SAACqgB,GAC3B,IAAMC,EAAaD,EAAUlc,QACI,IAA7Bmc,EAAWC,eAA2BD,EAAWH,SAAWhc,EAAOgc,QAC/DG,EAAWZ,WAAaD,IAC5Bf,EAAc3hB,KAAKsjB,EAAUnI,QAC7BQ,EAAW0H,EAAsBxT,OAAO,SAAAja,GAAA,OAAKA,IAAM0tB,IAAWvhB,IAAI,SAAAnM,GAAA,OAAKA,EAAEwR,OAAOuU,YACvErgB,QAAUunB,EAAU7iB,KAAK,CAC9B2b,WACA8H,OAAQH,EAAUnI,MAClB+G,KAAMD,GAAmBqB,EAAUnI,YAOnDQ,GAAWoH,EAAA,IAAGvgB,OAAHnB,MAAA0hB,EAAA,GAAAvgB,OAAAgZ,GAAiB0H,GAAjB,CAAmCb,KAAcxS,OAAO,SAAAja,GAAA,OAAW,OAANA,IACxEitB,EAAU7iB,KAAK,CACX2b,WACAgG,wBAAmBA,EAAnBnG,GAAqCpU,EAAOua,eAAiB,OAIrE,IAAM+B,EAAYpB,EAAWnH,MAEvBwI,EAAa3tB,OAAOqR,OAAO,CAC7Buc,kBAAmBvB,EACnBK,uBACDtb,GAEGyc,EAAmBvB,EAAWwB,aAChClB,GAA+BiB,IAC/B7F,EAAYJ,GAAuBiG,EAAkBlI,EAAU,CAC3DmC,gBAAiB8E,IAErBpB,GAAqBqC,EAAkB7F,EAAW2F,IAGtDd,EAAU5f,QAAQ,SAAC8gB,GACf,IAAMC,EAAmBpG,GAAuB8F,EAAWK,EAAIpI,UACzDuG,EAAO6B,EAAI7B,KAEjB,GAAIA,EAAM,CACN,IAAM+B,EA1HO,SAACjG,EAAWkE,GACjC,IAAK,IAAI5sB,EAAI,EAAGoN,EAAMwf,EAAK5mB,OAAQhG,EAAIoN,EAAKpN,IAAK,CAC7C,IAAM6lB,EAAQ+G,EAAK5sB,GACnB0oB,EAAY4C,GAA8B5C,EAAW7C,GAEzD,OAAO6C,EAqHuBkG,CAAiBF,EAAkB9B,EAAKiC,WAC9DJ,EAAIN,OAAO7B,kBAAkBqC,EAAeN,QAE5CnC,GAAqBkC,EAAWM,EAAkBL,EAAY,CAC1DhC,cAAeoC,EAAIpC,cACnBD,mBAAoBkB,GAA+BiB,iQC4GpDO,cA3jBX,SAAAA,iGAAwBC,CAAA1qB,KAAAyqB,GACpB,IAAIE,SAEJ3qB,KAAKwoB,QAAU,KACfxoB,KAAK4hB,YAAc,GACnB5hB,KAAKoiB,oBAAsB,GAC3BpiB,KAAKkoB,UAAY,GANG,QAAAhf,EAAA3D,UAAA5D,OAAR+lB,EAAQte,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAARqe,EAAQre,GAAA9D,UAAA8D,GAQE,IAAlBqe,EAAO/lB,SAAkBgpB,EAASjD,EAAO,cAAe+C,GAExDzqB,KAAK2V,eAAiBgV,EAAOhV,eAC7B3V,KAAKiR,YAAc0Z,EAAO1Z,YAC1BjR,KAAKgnB,YAAc2D,EAAO3D,YAC1BhnB,KAAKwoB,QAAUmC,EACf3qB,KAAK+mB,mBAAqB/mB,KAAKwoB,QAAQzB,mBACvC/mB,KAAK4qB,gBAAkB9f,IACvB9K,KAAK8Z,wBAAwBkK,0BAE7BmC,GAAUA,cAACnmB,MAAX6I,OAAoB6e,IACpB1nB,KAAK4qB,gBAAkB5qB,KAAK+mB,mBAAmB7qB,KAC/C8D,KAAK8Z,wBAAwBkK,wBAC7BhkB,KAAK6qB,sBAAwB,CACzBvB,eAAgB,GAChBwB,iBAAkB,oDA0B1B,OAAO9qB,KAAK0Q,gBAAgBvH,OAAOf,IAAI,SAAAnM,GAAA,OAAKA,EAAEkQ,6CAY9C,OAAOnM,KAAK4qB,wDAIZ,OAAO5qB,KAAK+qB,4DAMZ,OAFA/qB,KAAK+qB,YAAclK,GAAa,CAAC7gB,KAAKiR,YAAajR,KAAK2V,gBACnD3V,KAAK+jB,uBAAwB/jB,KAAK4qB,iBAChC5qB,oDAIP,OAAOA,KAAK+mB,gDAiCViE,EAAU3a,GACZ,OAAOH,EAAalQ,KAAMgrB,EAAU3a,uCAuB3B2a,GACT,OAAO9a,EAAalQ,KAAMgrB,EAAUjR,GAAkB/Z,KAAMgrB,IAAW,iCAqBpEC,GACH,OAAO/Q,GAAMla,KAAMirB,sCAoBXC,GACR,OAAO5V,EAAWtV,KAAMkrB,kCAkDpB3I,EAAU9U,GACd,IAAM0d,EAAY,CACdruB,KAAM+B,EAAcC,OACpBqmB,WAAW,GAITG,EAAc,CAAEH,WAFtB1X,EAASpR,OAAOqR,OAAO,GAAIyd,EAAW1d,IAEE0X,WACpCiG,SAEA3d,EAAO3Q,OAAS+B,EAAcG,IAa9BosB,EAAM,CAZWhG,GACbplB,KACAuiB,EACA,CAAEzlB,KAAM+B,EAAcC,QACtBwmB,GAEaF,GACbplB,KACAuiB,EACA,CAAEzlB,KAAM+B,EAAcE,SACtBumB,IAIJ8F,EAAMhG,GACFplB,KACAuiB,EACA9U,EACA6X,GAIR,OAAO8F,oCAsBP,OAAQprB,KAAKiR,YAAYtP,SAAW3B,KAAK2V,eAAehU,uCAUnC,IAAlBwjB,IAAkB5f,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,KAAAA,UAAA,GACfse,EAAW,IAAI7jB,KAAKqrB,YAAYrrB,MAMtC,OALImlB,EACAtB,EAASyH,UAAUtrB,MAEnB6jB,EAASyH,UAAU,MAEhBzH,kCA8CF4B,EAAWhY,GAChB,IAAM0d,EAAY,CACdruB,KAAM+B,EAAcC,OACpBqmB,WAAW,GAEf1X,EAASpR,OAAOqR,OAAO,GAAIyd,EAAW1d,GACtC,IAAM8d,EAAcvrB,KAAKwkB,kBACnBkB,EAAYrpB,OAAO4J,KAAKslB,GACtBzuB,EAAS2Q,EAAT3Q,KAEJ0uB,EAAsB/F,EAAU7R,OAAO,SAACC,EAAK9H,GAM7C,MAL+B,WAA3BA,EAAMsf,YAAYnvB,KAClB2X,EAAIxN,KAAJqB,MAAAmM,wHAAA4X,CAAY/F,EAAUxP,OAAO,SAAAvB,GAAA,OAA0C,IAA7BA,EAAU+W,OAAO3f,OACpDA,KAASwf,GAChB1X,EAAIxN,KAAK0F,GAEN8H,GACR,IAEH2X,EAAsBpiB,MAAMI,KAAK,IAAIwR,IAAIwQ,IAAsBpjB,IAAI,SAAA2D,GAAA,OAASA,EAAM8Q,SAClF,IAAI5E,SAEAnb,IAAS+B,EAAcG,IASvBiZ,EAAY,CARUuN,GAAiBxlB,KAAMwrB,EAAqB,CAC9D1uB,KAAM+B,EAAcC,OACpBqmB,UAAW1X,EAAO0X,WACnBO,GACkBF,GAAiBxlB,KAAMwrB,EAAqB,CAC7D1uB,KAAM+B,EAAcE,QACpBomB,UAAW1X,EAAO0X,WACnBO,IAIHzN,EADsBuN,GAAiBxlB,KAAMwrB,EAAqB/d,EAAQiY,GAI9E,OAAOzN,4CAIP,OAAOjY,KAAK2rB,6DAWZ,OAPA3rB,KAAK2rB,aAAe3rB,KAAK+qB,YAAY5hB,OAAOyK,OAAO,SAACC,EAAK+X,EAAUjwB,GAK/D,OAJAkY,EAAI+X,EAAS1vB,QAAU,CACnBgG,MAAOvG,EACPipB,IAAKgH,EAASzf,UAEX0H,GACR,IACI7T,uCAWPA,KAAKwoB,SAAWxoB,KAAKwoB,QAAQqD,YAAY7rB,MACzCA,KAAKwoB,QAAU,KACfxoB,KAAKkoB,UAAU5e,QAAQ,SAAC6e,GACpBA,EAAMK,QAAU,OAEpBxoB,KAAKkoB,UAAY,uCA6BRC,GACT,IAAIrU,EAAM9T,KAAKkoB,UAAU4D,UAAU,SAAAC,GAAA,OAAWA,IAAY5D,KACjD,IAATrU,GAAa9T,KAAKkoB,UAAUzgB,OAAOqM,EAAK,qCAQjCkY,GACPhsB,KAAKwoB,SAAWxoB,KAAKwoB,QAAQqD,YAAY7rB,MACzCA,KAAKwoB,QAAUwD,EACfA,GAAUA,EAAO9D,UAAU7hB,KAAKrG,0CA4BhC,OAAOA,KAAKwoB,8CA6BZ,OAAOxoB,KAAKkoB,mDA4BZ,OAAOloB,KAAK4hB,6DA4BZ,OAAO5hB,KAAKoiB,2rBCwGLzkB,eAlnBX,SAAAA,IAAsB,IAAA2a,+FAAA2T,CAAAjsB,KAAArC,GAAA,QAAAuL,EAAA3D,UAAA5D,OAANwF,EAAMiC,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAANlC,EAAMkC,GAAA9D,UAAA8D,GAAA,IAAAkO,mKAAA2U,CAAAlsB,MAAAsY,EAAA3a,EAAA2d,WAAAjf,OAAAkf,eAAA5d,IAAA7B,KAAA4L,MAAA4Q,EAAA,CAAAtY,MAAA6I,OACT1B,KADS,OAGlBoQ,EAAK4U,eAAiB,GAHJ5U,qUArCFkT,wCAuGX3jB,GAQLA,EAAUzK,OAAOqR,OAAO,GAPL,CACf0e,MAAO,MACP/pB,UAAW,KACXgqB,SAAS,EACTC,cAAc,EACdja,KAAM,IAE8BvL,GACxC,IAAMqC,EAASnJ,KAAK+jB,uBAAuB5a,OAErCojB,EAAgBxY,EAAYjY,KAC9BkE,KACAA,KAAK+jB,uBAAuB5a,OAC5BnJ,KAAKiR,YACLnK,EAAQwlB,aAAenjB,EAAOf,IAAI,SAAAnM,GAAA,OAAKA,EAAEC,SAAQ+G,OAASjD,KAAK2V,eAC/D7O,EAAQuL,KACR,CACI8B,WAA8B,WAAlBrN,EAAQslB,MACpBlY,SAAUpN,EAAQulB,UAI1B,IAAKvlB,EAAQzE,UACT,OAAOkqB,EAxBG,IA2BNlqB,EAAcyE,EAAdzE,UACAkJ,EAAuBghB,EAAvBhhB,KAAMY,EAAiBogB,EAAjBpgB,OAAQkI,EAASkY,EAATlY,KAChBmY,EAAargB,EAAO/D,IAAK,SAAA/E,GAAA,OAAKA,EAAEnH,OAEhCuwB,EADgBpwB,OAAO4J,KAAK5D,GACAuR,OAAO,SAACC,EAAKvF,GAC3C,IAAMwF,EAAM0Y,EAAWpmB,QAAQkI,GAI/B,OAHa,IAATwF,GACAD,EAAIxN,KAAK,CAACyN,EAAKzR,EAAUiM,KAEtBuF,GACR,IAgCH,MA9BsB,WAAlB/M,EAAQslB,MACRK,EAAYnjB,QAAQ,SAACojB,GACjB,IAAMC,EAAOD,EAAK,GACZE,EAAQF,EAAK,GAEnBnhB,EAAKohB,GAAMrjB,QAAQ,SAAC6J,EAAO0Z,GACvBthB,EAAKohB,GAAME,GAAYD,EAAM9wB,UACzBoE,EACAiT,EACAkB,EAAKwY,GACL1gB,EAAOwgB,QAKnBphB,EAAKjC,QAAQ,SAAC6J,EAAO0Z,GACjBJ,EAAYnjB,QAAQ,SAACojB,GACjB,IAAMC,EAAOD,EAAK,GACZE,EAAQF,EAAK,GAEnBvZ,EAAMwZ,GAAQC,EAAM9wB,UAChBoE,EACAiT,EAAMwZ,GACNtY,EAAKwY,GACL1gB,EAAOwgB,QAMhBJ,kCA2BFO,GAAwD,IAA7C5U,EAA6C3S,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAlC,GAAIkI,EAA8BlI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAArB,CAAE4f,WAAW,GAC/CwC,KAAmBmF,EAAU7pB,OAC/BykB,EAAS,CAAC1nB,KAAM8sB,EAAW5U,GACzBmB,EAAerB,gBAAW0P,GAgBhC,OAdApG,GACIthB,KACAqZ,EACAxK,EAAeG,QACf,CAAE8d,YAAWnF,gBAAehP,eAAgBZ,GAAaY,kBACzDT,GAGAzK,EAAO0X,UACP9L,EAAaiS,UAAUtrB,MAEvBqZ,EAAaiS,UAAU,MAGpBjS,+BAsDLpF,GAA+C,IAA/BxG,EAA+BlI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAtB,CAAE4f,WAAW,GAClCpC,EAAU/iB,KAAKskB,QAAQ,CACzB8H,MAAO,MACP/Z,KAAM4B,IAGJ8Y,EAAe,CADNhK,EAAQ5W,OAAO/D,IAAI,SAAA2D,GAAA,OAASA,EAAM7P,QACnB2M,OAAOka,EAAQxX,MAEvCyhB,EAAW,IAAIhtB,KAAKqrB,YAAY0B,EAAchK,EAAQ5W,OAAQ,CAAE6R,WAAY,WAgBlF,OAdAsD,GACIthB,KACAgtB,EACAne,EAAeO,KACf3B,EACAwG,GAGAxG,EAAO0X,UACP6H,EAAS1B,UAAUtrB,MAEnBgtB,EAAS1B,UAAU,MAGhB0B,oCAwBA5gB,EAAMtF,GACbsF,EAAOA,GAAQpM,KAAKgnB,YACpBlgB,EAAUzK,OAAOqR,OAAO,GAAI,CAAE4S,eAAgB,KAAOxZ,GAErD,IAAMqC,EAASnJ,KAAK0Q,gBAAgBvH,OAC9B8jB,EAAU9jB,EAAOf,IAAI,SAAA6M,GAAA,OAAKA,EAAE4N,kBAC5BqK,EAAYD,EAAQ,GAAGtrB,OACzBwrB,SACAC,SACAC,SAEJ,GAAIjhB,IAAStO,EAAWC,UAEpB,IADAovB,EAAiB,GACZC,EAAS,EAAGA,EAASF,EAAWE,IAAU,CAC3C,IAAMvT,EAAM,GACZ,IAAKwT,EAAS,EAAGA,EAASlkB,EAAOxH,OAAQ0rB,IACrCxT,EAAI1Q,EAAOkkB,GAAQnxB,QAAU+wB,EAAQI,GAAQD,GAEjDD,EAAe9mB,KAAKwT,QAErB,GAAIzN,IAAStO,EAAWE,QAAS,CAEpC,IADAmvB,EAAiB,CAAChkB,EAAOf,IAAI,SAAA6M,GAAA,OAAKA,EAAE/Y,SAAQ+G,KAAK6D,EAAQwZ,iBACpD8M,EAAS,EAAGA,EAASF,EAAWE,IAAU,CAC3C,IAAMvT,EAAM,GACZ,IAAKwT,EAAS,EAAGA,EAASlkB,EAAOxH,OAAQ0rB,IACrCxT,EAAIxT,KAAK4mB,EAAQI,GAAQD,IAE7BD,EAAe9mB,KAAKwT,EAAI5W,KAAK6D,EAAQwZ,iBAEzC6M,EAAiBA,EAAelqB,KAAK,UAClC,IAAImJ,IAAStO,EAAWG,QAU3B,MAAM,IAAI8S,MAAJ,aAAuB3E,EAAvB,qBARN,IADA+gB,EAAiB,CAAChkB,EAAOf,IAAI,SAAA6M,GAAA,OAAKA,EAAE/Y,UAC/BkxB,EAAS,EAAGA,EAASF,EAAWE,IAAU,CAC3C,IAAMvT,EAAM,GACZ,IAAKwT,EAAS,EAAGA,EAASlkB,EAAOxH,OAAQ0rB,IACrCxT,EAAIxT,KAAK4mB,EAAQI,GAAQD,IAE7BD,EAAe9mB,KAAKwT,IAM5B,OAAOsT,mCAGDphB,GACN,IAAM4I,EAAY5I,EAAM7P,OACxB8D,KAAK2V,gBAAL,IAA2BhB,EAC3B,IAAMmM,EAAoB9gB,KAAK+mB,mBAE/B,GAAKjG,EAAkBjV,YAAYE,EAAM7P,QAElC,CACH,IAAMqN,EAAauX,EAAkB3X,OAAO2iB,UAAU,SAAAwB,GAAA,OAAaA,EAAUpxB,SAAWyY,IACxFpL,GAAc,IAAMuX,EAAkB3X,OAAOI,GAAcwC,QAH3D+U,EAAkB3X,OAAO9C,KAAK0F,GAYlC,OALA+U,EAAkBhV,iBAAmB,KACrCgV,EAAkBvU,iBAAmB,KACrCuU,EAAkB5U,eAAiB,KAEnClM,KAAK8Z,wBAAwBkK,wBACtBhkB,+CAuCQmM,EAAQohB,EAAY9f,GAAQ,IAAAmK,EAAA5X,KAC3CmM,EAAS0Z,GAAmB1Z,GAC5BsB,EAASpR,OAAOqR,OAAO,GAAI,CAAEyX,WAAW,EAAMqI,YAAY,GAAS/f,GAEnE,IAAM8W,EAAevkB,KAAKwkB,kBACpBiJ,EAAUF,EAAWvY,MAAM,EAAGuY,EAAW5rB,OAAS,GAClD+rB,EAAaH,EAAWA,EAAW5rB,OAAS,GAElD,GAAI4iB,EAAapY,EAAOjQ,QAAUuR,EAAO+f,WACrC,MAAM,IAAIzc,MAAS5E,EAAOjQ,KAApB,sCAGV,IAAMyxB,EAAkBF,EAAQrlB,IAAI,SAAC2D,GACjC,IAAM6hB,EAAYrJ,EAAaxY,GAC/B,IAAK6hB,EAED,MAAM,IAAI7c,MAAShF,EAAb,gCAEV,OAAO6hB,EAAU1rB,QAGf4hB,EAAQ9jB,KAAK8jB,MAAMrW,EAAO0X,WAE1B0I,EAAK/J,EAAMpT,gBAAgBvH,OAC3B2kB,EAAiBH,EAAgBvlB,IAAI,SAAA0L,GAAA,OAAO+Z,EAAG/Z,KAEjD6F,EAAc,GACdC,EAAgB,kBAAMhC,EAAKjG,gBAEzBoc,EAAiB,GACvBhhB,EAAmB+W,EAAM7S,YAAa,SAACtV,GACnC,IAAMqyB,EAAaF,EAAe1lB,IAAI,SAAA2D,GAAA,OAASA,EAAMwF,aAAahG,KAAK5P,KACvEoyB,EAAepyB,GAAK+xB,sIAAcM,GAAdnlB,OAAA,CAA0BlN,EAAGie,EAAeD,OAhCzB,IAAAsU,EAkC3BxQ,GAAa,CAACsQ,GAAiB,CAAC5hB,GAAS,CAACA,EAAOjQ,OAA1D6P,EAlCoCmiB,GAAAD,EAAA,MA6C3C,OAVAnK,EAAMqK,SAASpiB,GAEfuV,GACIthB,KACA8jB,EACAjV,EAAeK,QACf,CAAEzB,OAAQtB,EAAQhD,OAAQskB,GAC1BC,GAGG5J,oCAWA4E,GAA2D,IAA9Cjb,EAA8ClI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAArC,GAAI6oB,EAAiC7oB,UAAA,GAAjBykB,EAAiBzkB,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAJ,GACxD8oB,EAAkB5gB,EAAO4gB,gBACzBtF,EAAsBtb,EAAOub,SAC7BsF,EAAU7gB,EAAO6gB,QACjBvE,EFzHkB,SAACvI,GAC7B,KAAOA,EAAMgH,SACThH,EAAQA,EAAMgH,QAElB,OAAOhH,EEqHe+M,CAAiBvuB,MAC7B6oB,EAAuBkB,EAAUc,sBAEjClC,EAAa,CACfwB,aFpIuB,SAAC3I,GAChC,KAAOA,EAAMgH,SAAWhH,EAAMI,YAAY4M,KAAK,SAAAvyB,GAAA,OAAKA,EAAE6lB,KAAOjT,EAAeG,WACxEwS,EAAQA,EAAMgH,QAElB,OAAOhH,EE8HsBiN,CAAoBzuB,MAGzCwhB,MAAOuI,GAgBX,OAbAqE,GFV0B,SAACvF,GAA6C,IAAvBpb,EAAuBlI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAd,GAAIic,EAAUjc,UAAA,GACxEmpB,SACEL,EAAkB5gB,EAAO4gB,gBACzBrM,EAAWvU,EAAOuU,SAClB9kB,EAASuQ,EAAOgc,OAAhB,IAA0Bhc,EAAOub,SAGnC0F,EADAL,EACkBxF,EAAqBS,eAErBT,EAAqBiC,iBAG1B,OAAb9I,SACO0M,EAAgBxxB,GAEvBwxB,EAAgBxxB,GAAO,CACnBskB,QACA/T,UEPckhB,CAAmB9F,EAAsBpb,EAAQzN,MACnEyoB,GAAyBC,EAAaC,EAAY,CAAEE,uBAAsBG,SAAUD,GAChF1sB,OAAOqR,OAAO,CACV4gB,WACD7gB,IAEH4gB,GFpC6B,SAACxF,EAAsBF,EAAYC,GACxE,IAAMkC,EAAmBjC,EAAqBiC,iBAE9C,IAAK,IAAMrB,KAAUqB,EAAkB,CACnC,IACMlB,EADYkB,EAAiBrB,GACNhc,OACvBsb,EAAsBH,EAAenb,OAAOub,SAC5C4F,GAAwBhG,EAAeoB,WAAW4E,uBACpDhG,EAAeoB,WAAW4E,sBAAsBhF,EAAYhB,EAAenb,QAC/E,GAAImc,EAAWZ,WAAaD,GAAuB6F,EAAuB,CACtE,IAAMC,EAAgBjF,EAAW5H,SACjCyG,GAAyBoG,EAAelG,EAAY,CAChDE,uBACAC,mBAAmB,EACnBE,SAAUD,GACXa,KEsBHkF,CAA0BjG,EAAsBF,EAAY,CACxDlb,SACAuc,eAIDhqB,gCAUP+uB,EAAW9hB,GACX,OAAQ8hB,GACR,IrCpiBmB,cqCqiBf/uB,KAAKmsB,eAAe9lB,KAAK4G,GAG7B,OAAOjN,yCASE+uB,GACT,OAAQA,GACR,IrCnjBmB,cqCojBf/uB,KAAKmsB,eAAiB,GAI1B,OAAOnsB,+CAUQqkB,EAAWiK,GAAS,IAAAtS,EAAAhc,KACfA,KAAKmsB,eACX7iB,QAAQ,SAAA4b,GAAA,OAAMA,EAAGppB,KAAKkgB,EAAMqI,EAAWiK,iCA8CpDU,EAAkBvhB,GACnB,IAAM8W,EAAevkB,KAAKwkB,kBAE1B,IAAKD,EAAayK,GACd,MAAM,IAAIje,MAAJ,SAAmBie,EAAnB,kBAGV,IAAMC,EAAexhB,EAAOvR,MAAW8yB,EAAlB,UAErB,GAAIzK,EAAa0K,GACb,MAAM,IAAIle,MAAJ,SAAmBke,EAAnB,mBAGV,IAb2BC,EtCvkB5B,SAAgCC,EAAcniB,EAAYS,GAAQ,IAC/DY,EAA4CZ,EAA5CY,QAAS+gB,EAAmC3hB,EAAnC2hB,UAAWhhB,EAAwBX,EAAxBW,QAASf,EAAeI,EAAfJ,MAAOC,EAAQG,EAARH,IAD2B+hB,EAEhDF,EAAalU,SAFmCqU,EAAAC,EAAAF,EAAA,GAE9DG,EAF8DF,EAAA,GAExDG,EAFwDH,EAAA,GAIhEjhB,IACDhB,EAAmB,IAAVA,KAAiBA,GAASA,EAAQmiB,GAASA,EAAOniB,EAC3DC,EAAe,IAARA,KAAeA,GAAOA,EAAMmiB,GAAUA,EAAO,EAAKniB,EAErD8hB,IACAhhB,EAAUpK,KAAK0rB,KAAK1rB,KAAK2rB,IAAIriB,EAAMD,GAAS+hB,IAGhD/gB,EAAUF,EAAgBC,EAASf,EAAOC,IAG1Ce,EAAQ,GAAKmhB,GACbnhB,EAAQzG,QAAQ4nB,GAEhBnhB,EAAQA,EAAQ1M,OAAS,IAAM8tB,GAC/BphB,EAAQhI,KAAKopB,EAAO,GAIxB,IADA,IAAMjhB,EAAe,GACZ7S,EAAI,EAAGA,EAAI0S,EAAQ1M,OAAS,EAAGhG,IACpC6S,EAAanI,KAAK,CACdgH,MAAOgB,EAAQ1S,GACf2R,IAAKe,EAAQ1S,EAAI,KAIzB,IAAMi0B,EAAa,GAYnB,OAXA7iB,EAAmBC,EAAY,SAACrR,GAC5B,IAAMwX,EAAQgc,EAAa5d,aAAahG,KAAK5P,GAC7C,GAAIwX,aAAiB5F,EACjBqiB,EAAWvpB,KAAK8M,OADpB,CAKA,IAAM3R,EAAQ+M,EAAgBC,EAAc2E,GAC5Cyc,EAAWvpB,KAAQ7E,EAAM6L,MAAzB,IAAkC7L,EAAM8L,QAGrC,CAAEsiB,aAAYzT,KAAM9N,GsC2iBMwhB,CADR7vB,KAAK0Q,gBAAgB7E,YAAYmjB,GACWhvB,KAAKiR,YAAaxD,GAA3EmiB,EAdmBV,EAcnBU,WAAYzT,EAdO+S,EAcP/S,KAEd2T,EAAWrS,GAAa,CAACmS,GAAa,CACxC,CACI1zB,KAAM+yB,EACN7iB,KAAM1N,EAAUE,UAChB6b,QAAStc,EAAiBI,OAC1B4d,SACA,CAAC8S,IAAe,GAElBnL,EAAQ9jB,KAAK8jB,MAAMrW,EAAO0X,WAWhC,OAVArB,EAAMqK,SAAS2B,GAEfxO,GACIthB,KACA8jB,EACAjV,EAAeM,IACd,CAAE6f,mBAAkBvhB,SAAQwhB,gBAC5B,MAGEnL,yCA8BP,OAAO,IAAInmB,EAHEqC,KAAK+vB,UAAUjyB,EAAWC,WACxBiC,KAAKgwB,kEA9kBWviB,GAC/B,OAAOF,EAAkBK,iBAAiBH,oCAf1C,OAAOsK,YCvFA5B,GAAoDM,GAApDN,IAAKG,GAA+CG,GAA/CH,IAAKO,GAA0CJ,GAA1CI,IAAKE,GAAqCN,GAArCM,IAAKkZ,GAAgCxZ,GAAhCwZ,MAAOC,GAAyBzZ,GAAzByZ,KAAMC,GAAmB1Z,GAAnB0Z,MAAYC,GAAO3Z,GAAZ4Z,ICsBjDC,GAAY,CACdC,QtC8LmB,mBAAAC,EAAAjrB,UAAA5D,OAAI8uB,EAAJrnB,MAAAonB,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAID,EAAJC,GAAAnrB,UAAAmrB,GAAA,OACnB,SAAC7a,GAAqC,IAAjCpI,EAAiClI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAxB,CAAE4f,WAAW,GACnBwL,EAAY9a,EACZ+a,SACE1J,EAAc,GA8BpB,OA5BAuJ,EAAWnnB,QAAQ,SAACmY,GAChBkP,EAAYlP,EAAUkP,GACtBzJ,EAAY7gB,KAAZqB,MAAAwf,wHAAA2J,CAAoBF,EAAU/O,cACzBgP,IACDA,EAAaD,KAIjBC,GAAcA,IAAeD,GAC7BC,EAAWE,UAIfH,EAAUvO,oBAAsB,GAChCd,GACIzL,EACA8a,EACA9hB,EAAeI,QACf,KACAiY,GAGAzZ,EAAO0X,UACPwL,EAAUrF,UAAUzV,GAEpB8a,EAAUrF,UAAU,MAGjBqF,IsC/NXI,ItC4He,mBAAAC,EAAAzrB,UAAA5D,OAAIwF,EAAJiC,MAAA4nB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAI9pB,EAAJ8pB,GAAA1rB,UAAA0rB,GAAA,OAAa,SAAApb,GAAA,OAAMA,EAAGkb,IAAHrpB,MAAAmO,EAAU1O,KsC3H5C8d,OtCgCkB,mBAAA/b,EAAA3D,UAAA5D,OAAIwF,EAAJiC,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAIlC,EAAJkC,GAAA9D,UAAA8D,GAAA,OAAa,SAAAwM,GAAA,OAAMA,EAAGoP,OAAHvd,MAAAmO,EAAa1O,KsC/BlD+pB,QtC+DmB,mBAAAC,EAAA5rB,UAAA5D,OAAIwF,EAAJiC,MAAA+nB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAIjqB,EAAJiqB,GAAA7rB,UAAA6rB,GAAA,OAAa,SAAAvb,GAAA,OAAMA,EAAGqb,QAAHxpB,MAAAmO,EAAc1O,KsC9DpD6Q,QtCsJmB,mBAAAqZ,EAAA9rB,UAAA5D,OAAIwF,EAAJiC,MAAAioB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAInqB,EAAJmqB,GAAA/rB,UAAA+rB,GAAA,OAAa,SAAAzb,GAAA,OAAMA,EAAGmC,QAAHtQ,MAAAmO,EAAc1O,KsCrJpDoqB,kBCvB6B,mBAAAroB,EAAA3D,UAAA5D,OAAIwF,EAAJiC,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAIlC,EAAJkC,GAAA9D,UAAA8D,GAAA,OAAa,SAAAwM,GAAA,OAAMA,EAAG0b,kBAAH7pB,MAAAmO,EAAwB1O,KDwBxEkL,KCfgB,mBAAA8e,EAAA5rB,UAAA5D,OAAIwF,EAAJiC,MAAA+nB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAIjqB,EAAJiqB,GAAA7rB,UAAA6rB,GAAA,OAAa,SAAAvb,GAAA,OAAMA,EAAGxD,KAAH3K,MAAAmO,EAAW1O,KDgB9C+I,eACAoF,aACAkc,YE/BG,SAAsBpX,EAAYC,GACrC,OAAOnK,EAAakK,EAAYC,EAAYN,GAAkBK,EAAYC,IAAa,IF+BvFF,iBACAG,kBACAmX,c3BxBG,SAAwBrX,EAAYC,EAAYhK,GACnD,OAAO6J,GAAMC,GAAcC,EAAYC,EAAYhK,GAAWiK,GAAeF,EAAYC,EAAYhK,K2BwBrG6J,UAGEwX,QAAcA,QACpBr1B,OAAOqR,OAAO/P,GAAW,CACrB2yB,aACAqB,QACA9iB,iBACA/O,oBACAhC,aACAe,gBACA0O,oBACAmkB,YACDE,GAEYj0B","file":"datamodel.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"DataModel\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"DataModel\"] = factory();\n\telse\n\t\troot[\"DataModel\"] = factory();\n})(window, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 1);\n","const DataModel = require('./export');\n\nmodule.exports = DataModel.default ? DataModel.default : DataModel;\n","/**\n * DataFormat Enum defines the format of the input data.\n * Based on the format of the data the respective adapter is loaded.\n *\n * @readonly\n * @enum {string}\n */\nconst DataFormat = {\n    FLAT_JSON: 'FlatJSON',\n    DSV_STR: 'DSVStr',\n    DSV_ARR: 'DSVArr',\n    AUTO: 'Auto'\n};\n\nexport default DataFormat;\n","/**\n * DimensionSubtype enum defines the sub types of the Dimensional Field.\n *\n * @readonly\n * @enum {string}\n */\nconst DimensionSubtype = {\n    CATEGORICAL: 'categorical',\n    TEMPORAL: 'temporal',\n    GEO: 'geo',\n    BINNED: 'binned'\n};\n\nexport default DimensionSubtype;\n","/**\n * MeasureSubtype enum defines the sub types of the Measure Field.\n *\n * @readonly\n * @enum {string}\n */\nconst MeasureSubtype = {\n    CONTINUOUS: 'continuous'\n};\n\nexport default MeasureSubtype;\n","/**\n * FieldType enum defines the high level field based on which visuals are controlled.\n * Measure in a high level is numeric field and Dimension in a high level is string field.\n *\n * @readonly\n * @enum {string}\n */\nconst FieldType = {\n    MEASURE: 'measure',\n    DIMENSION: 'dimension'\n};\n\nexport default FieldType;\n","/**\n * Filtering mode enum defines the filering modes of DataModel.\n *\n * @readonly\n * @enum {string}\n */\nconst FilteringMode = {\n    NORMAL: 'normal',\n    INVERSE: 'inverse',\n    ALL: 'all'\n};\n\nexport default FilteringMode;\n","/**\n * Group by function names\n *\n * @readonly\n * @enum {string}\n */\nconst GROUP_BY_FUNCTIONS = {\n    SUM: 'sum',\n    AVG: 'avg',\n    MIN: 'min',\n    MAX: 'max',\n    FIRST: 'first',\n    LAST: 'last',\n    COUNT: 'count',\n    STD: 'std'\n};\n\nexport default GROUP_BY_FUNCTIONS;\n","/**\n * Creates a JS native date object from input\n *\n * @param {string | number | Date} date Input using which date object to be created\n * @return {Date} : JS native date object\n */\nfunction convertToNativeDate (date) {\n    if (date instanceof Date) {\n        return date;\n    }\n\n    return new Date(date);\n}\n/**\n * Apply padding before a number if its less than 1o. This is used when constant digit's number to be returned\n * between 0 - 99\n *\n * @param {number} n Input to be padded\n * @return {string} Padded number\n */\nfunction pad (n) {\n    return (n < 10) ? (`0${n}`) : n;\n}\n/*\n * DateFormatter utility to convert any date format to any other date format\n * DateFormatter parse a date time stamp specified by a user abiding by rules which are defined\n * by user in terms of token. It creates JS native date object from the user specified format.\n * That native date can also be displayed\n * in any specified format.\n * This utility class only takes care of format conversion only\n */\n\n/*\n * Escapes all the special character that are used in regular expression.\n * Like\n * RegExp.escape('sgfd-$') // Output: sgfd\\-\\$\n *\n * @param text {String} : text which is to be escaped\n */\nRegExp.escape = function (text) {\n    return text.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&');\n};\n\n/**\n * DateTimeFormatter class to convert any user format of date time stamp to any other format\n * of date time stamp.\n *\n * @param {string} format Format of the date given. For the above date,\n * 'year: %Y, month: %b, day: %d'.\n * @class\n */\n/* istanbul ignore next */ function DateTimeFormatter (format) {\n    this.format = format;\n    this.dtParams = undefined;\n    this.nativeDate = undefined;\n}\n\n// The identifier of the tokens\nDateTimeFormatter.TOKEN_PREFIX = '%';\n\n// JS native Date constructor takes the date params (year, month, etc) in a certail sequence.\n// This defines the sequence of the date parameters in the constructor.\nDateTimeFormatter.DATETIME_PARAM_SEQUENCE = {\n    YEAR: 0,\n    MONTH: 1,\n    DAY: 2,\n    HOUR: 3,\n    MINUTE: 4,\n    SECOND: 5,\n    MILLISECOND: 6\n};\n\n/*\n * This is a default number parsing utility. It tries to parse a number in integer, if parsing is unsuccessful, it\n * gives back a default value.\n *\n * @param: defVal {Number} : Default no if the parsing to integer is not successful\n * @return {Function} : An closure function which is to be called by passing an the value which needs to be parsed.\n */\nDateTimeFormatter.defaultNumberParser = function (defVal) {\n    return function (val) {\n        let parsedVal;\n        if (isFinite(parsedVal = parseInt(val, 10))) {\n            return parsedVal;\n        }\n\n        return defVal;\n    };\n};\n\n/*\n * This is a default number range utility. It tries to find an element in the range. If not found it returns a\n * default no as an index.\n *\n * @param: range {Array} : The list which is to be serached\n * @param: defVal {Number} : Default no if the serach and find does not return anything\n * @return {Function} : An closure function which is to be called by passing an the value which needs to be found\n */\nDateTimeFormatter.defaultRangeParser = function (range, defVal) {\n    return (val) => {\n        let i;\n        let l;\n\n        if (!val) { return defVal; }\n\n        const nVal = val.toLowerCase();\n\n        for (i = 0, l = range.length; i < l; i++) {\n            if (range[i].toLowerCase() === nVal) {\n                return i;\n            }\n        }\n\n        if (i === undefined) {\n            return defVal;\n        }\n        return null;\n    };\n};\n\n/*\n * Defines the tokens which are supporter by the dateformatter. Using this definitation a value gets extracted from\n * the user specifed date string. This also formats the value for display purpose from native JS date.\n * The definition of each token contains the following named properties\n * {\n *     %token_name% : {\n *         name: name of the token, this is used in reverse lookup,\n *         extract: a function that returns the regular expression to extract that piece of information. All the\n *                  regex should be gouped by using ()\n *         parser: a function which receives value extracted by the above regex and parse it to get the date params\n *         formatter: a formatter function that takes milliseconds or JS Date object and format the param\n *                  represented by the token only.\n *     }\n * }\n *\n * @return {Object} : Definition of the all the supported tokens.\n */\nDateTimeFormatter.getTokenDefinitions = function () {\n    const daysDef = {\n        short: [\n            'Sun',\n            'Mon',\n            'Tue',\n            'Wed',\n            'Thu',\n            'Fri',\n            'Sat'\n        ],\n        long: [\n            'Sunday',\n            'Monday',\n            'Tuesday',\n            'Wednesday',\n            'Thursday',\n            'Friday',\n            'Saturday'\n        ]\n    };\n    const monthsDef = {\n        short: [\n            'Jan',\n            'Feb',\n            'Mar',\n            'Apr',\n            'May',\n            'Jun',\n            'Jul',\n            'Aug',\n            'Sep',\n            'Oct',\n            'Nov',\n            'Dec'\n        ],\n        long: [\n            'January',\n            'February',\n            'March',\n            'April',\n            'May',\n            'June',\n            'July',\n            'August',\n            'September',\n            'October',\n            'November',\n            'December'\n        ]\n    };\n\n    const definitions = {\n        H: {\n            // 24 hours format\n            name: 'H',\n            index: 3,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n\n                return d.getHours().toString();\n            }\n        },\n        l: {\n            // 12 hours format\n            name: 'l',\n            index: 3,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const hours = d.getHours() % 12;\n\n                return (hours === 0 ? 12 : hours).toString();\n            }\n        },\n        p: {\n            // AM or PM\n            name: 'p',\n            index: 3,\n            extract () { return '(AM|PM)'; },\n            parser: (val) => {\n                if (val) {\n                    return val.toLowerCase();\n                }\n                return null;\n            },\n            formatter: (val) => {\n                const d = convertToNativeDate(val);\n                const hours = d.getHours();\n\n                return (hours < 12 ? 'AM' : 'PM');\n            }\n        },\n        P: {\n            // am or pm\n            name: 'P',\n            index: 3,\n            extract () { return '(am|pm)'; },\n            parser: (val) => {\n                if (val) {\n                    return val.toLowerCase();\n                }\n                return null;\n            },\n            formatter: (val) => {\n                const d = convertToNativeDate(val);\n                const hours = d.getHours();\n\n                return (hours < 12 ? 'am' : 'pm');\n            }\n        },\n        M: {\n            // Two digit minutes 00 - 59\n            name: 'M',\n            index: 4,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const mins = d.getMinutes();\n\n                return pad(mins);\n            }\n        },\n        S: {\n            // Two digit seconds 00 - 59\n            name: 'S',\n            index: 5,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const seconds = d.getSeconds();\n\n                return pad(seconds);\n            }\n        },\n        K: {\n            // Milliseconds\n            name: 'K',\n            index: 6,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const ms = d.getMilliseconds();\n\n                return ms.toString();\n            }\n        },\n        a: {\n            // Short name of day, like Mon\n            name: 'a',\n            index: 2,\n            extract () { return `(${daysDef.short.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(daysDef.short),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDay();\n\n                return (daysDef.short[day]).toString();\n            }\n        },\n        A: {\n            // Long name of day, like Monday\n            name: 'A',\n            index: 2,\n            extract () { return `(${daysDef.long.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(daysDef.long),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDay();\n\n                return (daysDef.long[day]).toString();\n            }\n        },\n        e: {\n            // 8 of March, 11 of November\n            name: 'e',\n            index: 2,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDate();\n\n                return day.toString();\n            }\n        },\n        d: {\n            // 08 of March, 11 of November\n            name: 'd',\n            index: 2,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDate();\n\n                return pad(day);\n            }\n        },\n        b: {\n            // Short month, like Jan\n            name: 'b',\n            index: 1,\n            extract () { return `(${monthsDef.short.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(monthsDef.short),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const month = d.getMonth();\n\n                return (monthsDef.short[month]).toString();\n            }\n        },\n        B: {\n            // Long month, like January\n            name: 'B',\n            index: 1,\n            extract () { return `(${monthsDef.long.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(monthsDef.long),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const month = d.getMonth();\n\n                return (monthsDef.long[month]).toString();\n            }\n        },\n        m: {\n            // Two digit month of year like 01 for January\n            name: 'm',\n            index: 1,\n            extract () { return '(\\\\d+)'; },\n            parser (val) { return DateTimeFormatter.defaultNumberParser()(val) - 1; },\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const month = d.getMonth();\n\n                return pad(month + 1);\n            }\n        },\n        y: {\n            // Short year like 90 for 1990\n            name: 'y',\n            index: 0,\n            extract () { return '(\\\\d{2})'; },\n            parser (val) {\n                let result;\n                if (val) {\n                    const l = val.length;\n                    val = val.substring(l - 2, l);\n                }\n                let parsedVal = DateTimeFormatter.defaultNumberParser()(val);\n                let presentDate = new Date();\n                let presentYear = Math.trunc((presentDate.getFullYear()) / 100);\n\n                result = `${presentYear}${parsedVal}`;\n\n                if (convertToNativeDate(result).getFullYear() > presentDate.getFullYear()) {\n                    result = `${presentYear - 1}${parsedVal}`;\n                }\n                return convertToNativeDate(result).getFullYear();\n            },\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                let year = d.getFullYear().toString();\n                let l;\n\n                if (year) {\n                    l = year.length;\n                    year = year.substring(l - 2, l);\n                }\n\n                return year;\n            }\n        },\n        Y: {\n            // Long year like 1990\n            name: 'Y',\n            index: 0,\n            extract () { return '(\\\\d{4})'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const year = d.getFullYear().toString();\n\n                return year;\n            }\n        }\n    };\n\n    return definitions;\n};\n\n/*\n * The tokens which works internally is not user friendly in terms of memorizing the names. This gives a formal\n * definition to the informal notations.\n *\n * @return {Object} : Formal definition of the tokens\n */\nDateTimeFormatter.getTokenFormalNames = function () {\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n\n    return {\n        HOUR: definitions.H,\n        HOUR_12: definitions.l,\n        AMPM_UPPERCASE: definitions.p,\n        AMPM_LOWERCASE: definitions.P,\n        MINUTE: definitions.M,\n        SECOND: definitions.S,\n        SHORT_DAY: definitions.a,\n        LONG_DAY: definitions.A,\n        DAY_OF_MONTH: definitions.e,\n        DAY_OF_MONTH_CONSTANT_WIDTH: definitions.d,\n        SHORT_MONTH: definitions.b,\n        LONG_MONTH: definitions.B,\n        MONTH_OF_YEAR: definitions.m,\n        SHORT_YEAR: definitions.y,\n        LONG_YEAR: definitions.Y\n    };\n};\n\n/*\n * This defines the rules and declares dependencies that resolves a date parameter (year, month etc) from\n * the date time parameter array.\n *\n * @return {Object} : An object that contains dependencies and a resolver function. The dependencies values are fed\n *                  to the resolver function in that particular sequence only.\n */\nDateTimeFormatter.tokenResolver = function () {\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    const defaultResolver = (...args) => { // eslint-disable-line require-jsdoc\n        let i = 0;\n        let arg;\n        let targetParam;\n        const l = args.length;\n\n        for (; i < l; i++) {\n            arg = args[i];\n            if (args[i]) {\n                targetParam = arg;\n            }\n        }\n\n        if (!targetParam) { return null; }\n\n        return targetParam[0].parser(targetParam[1]);\n    };\n\n    return {\n        YEAR: [definitions.y, definitions.Y,\n            defaultResolver\n        ],\n        MONTH: [definitions.b, definitions.B, definitions.m,\n            defaultResolver\n        ],\n        DAY: [definitions.a, definitions.A, definitions.e, definitions.d,\n            defaultResolver\n        ],\n        HOUR: [definitions.H, definitions.l, definitions.p, definitions.P,\n            function (hourFormat24, hourFormat12, ampmLower, ampmUpper) {\n                let targetParam;\n                let amOrpm;\n                let isPM;\n                let val;\n\n                if (hourFormat12 && (amOrpm = (ampmLower || ampmUpper))) {\n                    if (amOrpm[0].parser(amOrpm[1]) === 'pm') {\n                        isPM = true;\n                    }\n\n                    targetParam = hourFormat12;\n                } else if (hourFormat12) {\n                    targetParam = hourFormat12;\n                } else {\n                    targetParam = hourFormat24;\n                }\n\n                if (!targetParam) { return null; }\n\n                val = targetParam[0].parser(targetParam[1]);\n                if (isPM) {\n                    val += 12;\n                }\n                return val;\n            }\n        ],\n        MINUTE: [definitions.M,\n            defaultResolver\n        ],\n        SECOND: [definitions.S,\n            defaultResolver\n        ]\n    };\n};\n\n/*\n * Finds token from the format rule specified by a user.\n * @param format {String} : The format of the input date specified by the user\n * @return {Array} : An array of objects which contains the available token and their occurence index in the format\n */\nDateTimeFormatter.findTokens = function (format) {\n    const tokenPrefix = DateTimeFormatter.TOKEN_PREFIX;\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    const tokenLiterals = Object.keys(definitions);\n    const occurrence = [];\n    let i;\n    let forwardChar;\n\n    while ((i = format.indexOf(tokenPrefix, i + 1)) >= 0) {\n        forwardChar = format[i + 1];\n        if (tokenLiterals.indexOf(forwardChar) === -1) { continue; }\n\n        occurrence.push({\n            index: i,\n            token: forwardChar\n        });\n    }\n\n    return occurrence;\n};\n\n/*\n * Format any JS date to a specified date given by user.\n *\n * @param date {Number | Date} : The date object which is to be formatted\n * @param format {String} : The format using which the date will be formatted for display\n */\nDateTimeFormatter.formatAs = function (date, format) {\n    const nDate = convertToNativeDate(date);\n    const occurrence = DateTimeFormatter.findTokens(format);\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    let formattedStr = String(format);\n    const tokenPrefix = DateTimeFormatter.TOKEN_PREFIX;\n    let token;\n    let formattedVal;\n    let i;\n    let l;\n\n    for (i = 0, l = occurrence.length; i < l; i++) {\n        token = occurrence[i].token;\n        formattedVal = definitions[token].formatter(nDate);\n        formattedStr = formattedStr.replace(new RegExp(tokenPrefix + token, 'g'), formattedVal);\n    }\n\n    return formattedStr;\n};\n\n/*\n * Parses the user specified date string to extract the date time params.\n *\n * @return {Array} : Value of date time params in an array [year, month, day, hour, minutes, seconds, milli]\n */\nDateTimeFormatter.prototype.parse = function (dateTimeStamp, options) {\n    const tokenResolver = DateTimeFormatter.tokenResolver();\n    const dtParams = this.extractTokenValue(dateTimeStamp);\n    const dtParamSeq = DateTimeFormatter.DATETIME_PARAM_SEQUENCE;\n    const noBreak = options && options.noBreak;\n    const dtParamArr = [];\n    const args = [];\n    let resolverKey;\n    let resolverParams;\n    let resolverFn;\n    let val;\n    let i;\n    let param;\n    let resolvedVal;\n    let l;\n    let result = [];\n\n    for (resolverKey in tokenResolver) {\n        if (!{}.hasOwnProperty.call(tokenResolver, resolverKey)) { continue; }\n\n        args.length = 0;\n        resolverParams = tokenResolver[resolverKey];\n        resolverFn = resolverParams.splice(resolverParams.length - 1, 1)[0];\n\n        for (i = 0, l = resolverParams.length; i < l; i++) {\n            param = resolverParams[i];\n            val = dtParams[param.name];\n\n            if (val === undefined) {\n                args.push(null);\n            } else {\n                args.push([param, val]);\n            }\n        }\n\n        resolvedVal = resolverFn.apply(this, args);\n\n        if ((resolvedVal === undefined || resolvedVal === null) && !noBreak) {\n            break;\n        }\n\n        dtParamArr[dtParamSeq[resolverKey]] = resolvedVal;\n    }\n\n    if (dtParamArr.length && this.checkIfOnlyYear(dtParamArr.length))\n     {\n        result.unshift(dtParamArr[0], 0, 1); }\n    else {\n        result.unshift(...dtParamArr);\n    }\n\n    return result;\n};\n\n/*\n * Extract the value of the token from user specified date time string.\n *\n * @return {Object} : An key value pair which contains the tokens as key and value as pair\n */\nDateTimeFormatter.prototype.extractTokenValue = function (dateTimeStamp) {\n    const format = this.format;\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    const tokenPrefix = DateTimeFormatter.TOKEN_PREFIX;\n    const occurrence = DateTimeFormatter.findTokens(format);\n    const tokenObj = {};\n\n    let lastOccurrenceIndex;\n    let occObj;\n    let occIndex;\n    let targetText;\n    let regexFormat;\n\n    let l;\n    let i;\n\n    regexFormat = String(format);\n\n    const tokenArr = occurrence.map(obj => obj.token);\n    const occurrenceLength = occurrence.length;\n    for (i = occurrenceLength - 1; i >= 0; i--) {\n        occIndex = occurrence[i].index;\n\n        if (occIndex + 1 === regexFormat.length - 1) {\n            lastOccurrenceIndex = occIndex;\n            continue;\n        }\n\n        if (lastOccurrenceIndex === undefined) {\n            lastOccurrenceIndex = regexFormat.length;\n        }\n\n        targetText = regexFormat.substring(occIndex + 2, lastOccurrenceIndex);\n        regexFormat = regexFormat.substring(0, occIndex + 2) +\n            RegExp.escape(targetText) +\n            regexFormat.substring(lastOccurrenceIndex, regexFormat.length);\n\n        lastOccurrenceIndex = occIndex;\n    }\n\n    for (i = 0; i < occurrenceLength; i++) {\n        occObj = occurrence[i];\n        regexFormat = regexFormat.replace(tokenPrefix + occObj.token, definitions[occObj.token].extract());\n    }\n\n    const extractValues = dateTimeStamp.match(new RegExp(regexFormat)) || [];\n    extractValues.shift();\n\n    for (i = 0, l = tokenArr.length; i < l; i++) {\n        tokenObj[tokenArr[i]] = extractValues[i];\n    }\n    return tokenObj;\n};\n\n/*\n * Give back the JS native date formed from  user specified date string\n *\n * @return {Date} : Native JS Date\n */\nDateTimeFormatter.prototype.getNativeDate = function (dateTimeStamp) {\n    let date = null;\n    if (Number.isFinite(dateTimeStamp)) {\n        date = new Date(dateTimeStamp);\n    } else if (!this.format && Date.parse(dateTimeStamp)) {\n        date = new Date(dateTimeStamp);\n    }\n    else {\n        const dtParams = this.dtParams = this.parse(dateTimeStamp);\n        if (dtParams.length) {\n            this.nativeDate = new Date(...dtParams);\n            date = this.nativeDate;\n        }\n    }\n    return date;\n};\n\nDateTimeFormatter.prototype.checkIfOnlyYear = function(len) {\n    return len === 1 && this.format.match(/y|Y/g).length;\n};\n\n/*\n * Represents JS native date to a user specified format.\n *\n * @param format {String} : The format according to which the date is to be represented\n * @return {String} : The formatted date string\n */\nDateTimeFormatter.prototype.formatAs = function (format, dateTimeStamp) {\n    let nativeDate;\n\n    if (dateTimeStamp) {\n        nativeDate = this.nativeDate = this.getNativeDate(dateTimeStamp);\n    } else if (!(nativeDate = this.nativeDate)) {\n        nativeDate = this.getNativeDate(dateTimeStamp);\n    }\n\n    return DateTimeFormatter.formatAs(nativeDate, format);\n};\n\nexport { DateTimeFormatter as default };\n","/**\n * The utility function to calculate major column.\n *\n * @param {Object} store - The store object.\n * @return {Function} Returns the push function.\n */\nexport default (store) => {\n    let i = 0;\n    return (...fields) => {\n        fields.forEach((val, fieldIndex) => {\n            if (!(store[fieldIndex] instanceof Array)) {\n                store[fieldIndex] = Array.from({ length: i });\n            }\n            store[fieldIndex].push(val);\n        });\n        i++;\n    };\n};\n","/* eslint-disable */\nconst OBJECTSTRING = 'object';\nconst objectToStrFn = Object.prototype.toString;\nconst objectToStr = '[object Object]';\nconst arrayToStr = '[object Array]';\n\nfunction checkCyclicRef(obj, parentArr) {\n    let i = parentArr.length;\n    let bIndex = -1;\n\n    while (i) {\n        if (obj === parentArr[i]) {\n            bIndex = i;\n            return bIndex;\n        }\n        i -= 1;\n    }\n\n    return bIndex;\n}\n\nfunction merge(obj1, obj2, skipUndef, tgtArr, srcArr) {\n    var item,\n        srcVal,\n        tgtVal,\n        str,\n        cRef;\n    // check whether obj2 is an array\n    // if array then iterate through it's index\n    // **** MOOTOOLS precution\n\n    if (!srcArr) {\n        tgtArr = [obj1];\n        srcArr = [obj2];\n    }\n    else {\n        tgtArr.push(obj1);\n        srcArr.push(obj2);\n    }\n\n    if (obj2 instanceof Array) {\n        for (item = 0; item < obj2.length; item += 1) {\n            try {\n                srcVal = obj1[item];\n                tgtVal = obj2[item];\n            }\n            catch (e) {\n                continue;\n            }\n\n            if (typeof tgtVal !== OBJECTSTRING) {\n                if (!(skipUndef && tgtVal === undefined)) {\n                    obj1[item] = tgtVal;\n                }\n            }\n            else {\n                if (srcVal === null || typeof srcVal !== OBJECTSTRING) {\n                    srcVal = obj1[item] = tgtVal instanceof Array ? [] : {};\n                }\n                cRef = checkCyclicRef(tgtVal, srcArr);\n                if (cRef !== -1) {\n                    srcVal = obj1[item] = tgtArr[cRef];\n                }\n                else {\n                    merge(srcVal, tgtVal, skipUndef, tgtArr, srcArr);\n                }\n            }\n        }\n    }\n    else {\n        for (item in obj2) {\n            try {\n                srcVal = obj1[item];\n                tgtVal = obj2[item];\n            }\n            catch (e) {\n                continue;\n            }\n\n            if (tgtVal !== null && typeof tgtVal === OBJECTSTRING) {\n                // Fix for issue BUG: FWXT-602\n                // IE < 9 Object.prototype.toString.call(null) gives\n                // '[object Object]' instead of '[object Null]'\n                // that's why null value becomes Object in IE < 9\n                str = objectToStrFn.call(tgtVal);\n                if (str === objectToStr) {\n                    if (srcVal === null || typeof srcVal !== OBJECTSTRING) {\n                        srcVal = obj1[item] = {};\n                    }\n                    cRef = checkCyclicRef(tgtVal, srcArr);\n                    if (cRef !== -1) {\n                        srcVal = obj1[item] = tgtArr[cRef];\n                    }\n                    else {\n                        merge(srcVal, tgtVal, skipUndef, tgtArr, srcArr);\n                    }\n                }\n                else if (str === arrayToStr) {\n                    if (srcVal === null || !(srcVal instanceof Array)) {\n                        srcVal = obj1[item] = [];\n                    }\n                    cRef = checkCyclicRef(tgtVal, srcArr);\n                    if (cRef !== -1) {\n                        srcVal = obj1[item] = tgtArr[cRef];\n                    }\n                    else {\n                        merge(srcVal, tgtVal, skipUndef, tgtArr, srcArr);\n                    }\n                }\n                else {\n                    obj1[item] = tgtVal;\n                }\n            }\n            else {\n                if (skipUndef && tgtVal === undefined) {\n                    continue;\n                }\n                obj1[item] = tgtVal;\n            }\n        }\n    }\n    return obj1;\n}\n\n\nfunction extend2 (obj1, obj2, skipUndef) {\n    //if none of the arguments are object then return back\n    if (typeof obj1 !== OBJECTSTRING && typeof obj2 !== OBJECTSTRING) {\n        return null;\n    }\n\n    if (typeof obj2 !== OBJECTSTRING || obj2 === null) {\n        return obj1;\n    }\n\n    if (typeof obj1 !== OBJECTSTRING) {\n        obj1 = obj2 instanceof Array ? [] : {};\n    }\n    merge(obj1, obj2, skipUndef);\n    return obj1;\n}\n\nexport { extend2 as default };\n","import { DataFormat } from '../enums';\n\n/**\n * Checks whether the value is an array.\n *\n * @param  {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is an array otherwise returns false.\n */\nexport function isArray (val) {\n    return Array.isArray(val);\n}\n\n/**\n * Checks whether the value is an object.\n *\n * @param  {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is an object otherwise returns false.\n */\nexport function isObject (val) {\n    return val === Object(val);\n}\n\n/**\n * Checks whether the value is a string value.\n *\n * @param  {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is a string value otherwise returns false.\n */\nexport function isString (val) {\n    return typeof val === 'string';\n}\n\n/**\n * Checks whether the value is callable.\n *\n * @param {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is callable otherwise returns false.\n */\nexport function isCallable (val) {\n    return typeof val === 'function';\n}\n\n/**\n * Returns the unique values from the input array.\n *\n * @param {Array} data - The input array.\n * @return {Array} Returns a new array of unique values.\n */\nexport function uniqueValues (data) {\n    return [...new Set(data)];\n}\n\nexport const getUniqueId = () => `id-${new Date().getTime()}${Math.round(Math.random() * 10000)}`;\n\n/**\n * Checks Whether two arrays have same content.\n *\n * @param {Array} arr1 - The first array.\n * @param {Array} arr2 - The 2nd array.\n * @return {boolean} Returns whether two array have same content.\n */\nexport function isArrEqual(arr1, arr2) {\n    if (!isArray(arr1) || !isArray(arr2)) {\n        return arr1 === arr2;\n    }\n\n    if (arr1.length !== arr2.length) {\n        return false;\n    }\n\n    for (let i = 0; i < arr1.length; i++) {\n        if (arr1[i] !== arr2[i]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n\n/**\n * It is the default number format function for the measure field type.\n *\n * @param {any} val - The input value.\n * @return {number} Returns a number value.\n */\nexport function formatNumber(val) {\n    return val;\n}\n\n/**\n * Returns the detected data format.\n *\n * @param {any} data - The input data to be tested.\n * @return {string} Returns the data format name.\n */\nexport const detectDataFormat = (data) => {\n    if (isString(data)) {\n        return DataFormat.DSV_STR;\n    } else if (isArray(data) && isArray(data[0])) {\n        return DataFormat.DSV_ARR;\n    } else if (isArray(data) && (data.length === 0 || isObject(data[0]))) {\n        return DataFormat.FLAT_JSON;\n    }\n    return null;\n};\n","import { FieldType } from './enums';\nimport { getUniqueId } from './utils';\n\nconst fieldStore = {\n    data: {},\n\n    createNamespace (fieldArr, name) {\n        const dataId = name || getUniqueId();\n\n        this.data[dataId] = {\n            name: dataId,\n            fields: fieldArr,\n\n            fieldsObj () {\n                let fieldsObj = this._cachedFieldsObj;\n\n                if (!fieldsObj) {\n                    fieldsObj = this._cachedFieldsObj = {};\n                    this.fields.forEach((field) => {\n                        fieldsObj[field.name()] = field;\n                    });\n                }\n                return fieldsObj;\n            },\n            getMeasure () {\n                let measureFields = this._cachedMeasure;\n\n                if (!measureFields) {\n                    measureFields = this._cachedMeasure = {};\n                    this.fields.forEach((field) => {\n                        if (field.schema().type === FieldType.MEASURE) {\n                            measureFields[field.name()] = field;\n                        }\n                    });\n                }\n                return measureFields;\n            },\n            getDimension () {\n                let dimensionFields = this._cachedDimension;\n\n                if (!this._cachedDimension) {\n                    dimensionFields = this._cachedDimension = {};\n                    this.fields.forEach((field) => {\n                        if (field.schema().type === FieldType.DIMENSION) {\n                            dimensionFields[field.name()] = field;\n                        }\n                    });\n                }\n                return dimensionFields;\n            },\n        };\n        return this.data[dataId];\n    },\n};\n\nexport default fieldStore;\n","/**\n * The wrapper class on top of the primitive value of a field.\n *\n * @todo Need to have support for StringValue, NumberValue, DateTimeValue\n * and GeoValue. These types should expose predicate API mostly.\n */\nclass Value {\n\n  /**\n   * Creates new Value instance.\n   *\n   * @param {*} val - the primitive value from the field cell.\n   * @param {string | Field} field - The field from which the value belongs.\n   */\n    constructor (parsedVal, val, field) {\n        Object.defineProperties(this, {\n            _value: {\n                enumerable: false,\n                configurable: false,\n                writable: false,\n                value: val\n            },\n            _parsedValue: {\n                enumerable: false,\n                configurable: false,\n                writable: false,\n                value: parsedVal\n            }\n        });\n\n        this.field = field;\n    }\n\n  /**\n   * Returns the field value.\n   *\n   * @return {*} Returns the current value.\n   */\n    get value () {\n        return this._value;\n    }\n\n    /**\n     * Returns the parsed value of field\n     */\n    get parsedValue () {\n        return this._parsedValue;\n    }\n\n  /**\n   * Converts to human readable string.\n   *\n   * @override\n   * @return {string} Returns a human readable string of the field value.\n   *\n   */\n    toString () {\n        return String(this.value);\n    }\n\n  /**\n   * Returns the value of the field.\n   *\n   * @override\n   * @return {*} Returns the field value.\n   */\n    valueOf () {\n        return this.value;\n    }\n}\n\nexport default Value;\n","/**\n * Iterates through the diffSet array and call the callback with the current\n * index.\n *\n * @param {string} rowDiffset - The row diffset string e.g. '0-4,6,10-13'.\n * @param {Function} callback - The callback function to be called with every index.\n */\nexport function rowDiffsetIterator (rowDiffset, callback) {\n    if (rowDiffset.length > 0) {\n        const rowDiffArr = rowDiffset.split(',');\n        rowDiffArr.forEach((diffStr) => {\n            const diffStsArr = diffStr.split('-');\n            const start = +(diffStsArr[0]);\n            const end = +(diffStsArr[1] || diffStsArr[0]);\n            if (end >= start) {\n                for (let i = start; i <= end; i += 1) {\n                    callback(i);\n                }\n            }\n        });\n    }\n}\n","/**\n * A parser to parser null, undefined, invalid and NIL values.\n *\n * @public\n * @class\n */\nclass InvalidAwareTypes {\n    /**\n     * Static method which gets/sets the invalid value registry.\n     *\n     * @public\n     * @param {Object} config - The custom configuration supplied by user.\n     * @return {Object} Returns the invalid values registry.\n     */\n    static invalidAwareVals (config) {\n        if (!config) {\n            return InvalidAwareTypes._invalidAwareValsMap;\n        }\n        return Object.assign(InvalidAwareTypes._invalidAwareValsMap, config);\n    }\n\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {string} value - The value of the invalid data type.\n     */\n    constructor (value) {\n        this._value = value;\n    }\n\n    /**\n     * Returns the current value of the instance.\n     *\n     * @public\n     * @return {string} Returns the value of the invalid data type.\n     */\n    value () {\n        return this._value;\n    }\n\n    /**\n     * Returns the current value of the instance in string format.\n     *\n     * @public\n     * @return {string} Returns the value of the invalid data type.\n     */\n    toString () {\n        return String(this._value);\n    }\n\n    static isInvalid(val) {\n        return (val instanceof InvalidAwareTypes) || !!InvalidAwareTypes.invalidAwareVals()[val];\n    }\n\n    static getInvalidType(val) {\n        return val instanceof InvalidAwareTypes ? val : InvalidAwareTypes.invalidAwareVals()[val];\n    }\n}\n\n/**\n * Enums for Invalid types.\n */\nInvalidAwareTypes.NULL = new InvalidAwareTypes('null');\nInvalidAwareTypes.NA = new InvalidAwareTypes('na');\nInvalidAwareTypes.NIL = new InvalidAwareTypes('nil');\n\n/**\n * Default Registry for mapping the invalid values.\n *\n * @private\n */\nInvalidAwareTypes._invalidAwareValsMap = {\n    invalid: InvalidAwareTypes.NA,\n    nil: InvalidAwareTypes.NIL,\n    null: InvalidAwareTypes.NULL,\n    undefined: InvalidAwareTypes.NA\n};\n\nexport default InvalidAwareTypes;\n","import { rowDiffsetIterator } from './row-diffset-iterator';\nimport InvalidAwareTypes from '../invalid-aware-types';\n\nconst generateBuckets = (binSize, start, end) => {\n    const buckets = [];\n    let next = start;\n\n    while (next < end) {\n        buckets.push(next);\n        next += binSize;\n    }\n    buckets.push(next);\n\n    return buckets;\n};\n\nconst findBucketRange = (bucketRanges, value) => {\n    let leftIdx = 0;\n    let rightIdx = bucketRanges.length - 1;\n    let midIdx;\n    let range;\n\n    // Here use binary search as the bucketRanges is a sorted array\n    while (leftIdx <= rightIdx) {\n        midIdx = leftIdx + Math.floor((rightIdx - leftIdx) / 2);\n        range = bucketRanges[midIdx];\n\n        if (value >= range.start && value < range.end) {\n            return range;\n        } else if (value >= range.end) {\n            leftIdx = midIdx + 1;\n        } else if (value < range.start) {\n            rightIdx = midIdx - 1;\n        }\n    }\n\n    return null;\n};\n\n /**\n  * Creates the bin data from input measure field and supplied configs.\n  *\n  * @param {Measure} measureField - The Measure field instance.\n  * @param {string} rowDiffset - The datamodel rowDiffset values.\n  * @param {Object} config - The config object.\n  * @return {Object} Returns the binned data and the corresponding bins.\n  */\nexport function createBinnedFieldData (measureField, rowDiffset, config) {\n    let { buckets, binsCount, binSize, start, end } = config;\n    const [dMin, dMax] = measureField.domain();\n\n    if (!buckets) {\n        start = (start !== 0 && (!start || start > dMin)) ? dMin : start;\n        end = (end !== 0 && (!end || end < dMax)) ? (dMax + 1) : end;\n\n        if (binsCount) {\n            binSize = Math.ceil(Math.abs(end - start) / binsCount);\n        }\n\n        buckets = generateBuckets(binSize, start, end);\n    }\n\n    if (buckets[0] > dMin) {\n        buckets.unshift(dMin);\n    }\n    if (buckets[buckets.length - 1] <= dMax) {\n        buckets.push(dMax + 1);\n    }\n\n    const bucketRanges = [];\n    for (let i = 0; i < buckets.length - 1; i++) {\n        bucketRanges.push({\n            start: buckets[i],\n            end: buckets[i + 1]\n        });\n    }\n\n    const binnedData = [];\n    rowDiffsetIterator(rowDiffset, (i) => {\n        const datum = measureField.partialField.data[i];\n        if (datum instanceof InvalidAwareTypes) {\n            binnedData.push(datum);\n            return;\n        }\n\n        const range = findBucketRange(bucketRanges, datum);\n        binnedData.push(`${range.start}-${range.end}`);\n    });\n\n    return { binnedData, bins: buckets };\n}\n","export { DataFormat, FilteringMode } from '../enums';\n/**\n * The event name for data propagation.\n */\nexport const PROPAGATION = 'propagation';\n\n/**\n * The name of the unique row id column in DataModel.\n */\nexport const ROW_ID = '__id__';\n\n/**\n * The enums for operation names performed on DataModel.\n */\nexport const DM_DERIVATIVES = {\n    SELECT: 'select',\n    PROJECT: 'project',\n    GROUPBY: 'group',\n    COMPOSE: 'compose',\n    CAL_VAR: 'calculatedVariable',\n    BIN: 'bin',\n    SORT: 'sort'\n};\n\nexport const JOINS = {\n    CROSS: 'cross',\n    LEFTOUTER: 'leftOuter',\n    RIGHTOUTER: 'rightOuter',\n    NATURAL: 'natural',\n    FULLOUTER: 'fullOuter'\n};\n\nexport const LOGICAL_OPERATORS = {\n    AND: 'and',\n    OR: 'or'\n};\n","import { persistDerivations } from '../helper';\nimport { DM_DERIVATIVES } from '../constants';\n\n/**\n * DataModel's opearators are exposed as composable functional operators as well as chainable operators. Chainable\n * operators are called on the instances of {@link Datamodel} and {@link Relation} class.\n *\n * Those same operators can be used as composable operators from `DataModel.Operators` namespace.\n *\n * All these operators have similar behaviour. All these operators when called with the argument returns a function\n * which expects a DataModel instance.\n *\n * @public\n * @module Operators\n * @namespace DataModel\n */\n\n/**\n * This is functional version of selection operator. {@link link_to_selection | Selection} is a row filtering operation.\n * It takes {@link SelectionPredicate | predicate} for filtering criteria and returns a function.\n * The returned function is called with the DataModel instance on which the action needs to be performed.\n *\n * {@link SelectionPredicate} is a function which returns a boolean value. For selection opearation the selection\n * function is called for each row of DataModel instance with the current row passed as argument.\n *\n * After executing {@link SelectionPredicate} the rows are labeled as either an entry of selection set or an entry\n * of rejection set.\n *\n * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n * resulatant datamodel.\n *\n * @warning\n * [Warn] Selection and rejection set is only a logical idea for concept explanation purpose.\n *\n * @error\n * [Error] `FilteringMode.ALL` is not a valid working mode for functional version of `select`. Its only avialable on the\n * chained version.\n *\n * @example\n * const select = DataModel.Operators.select;\n * usaCarsFn = select(fields => fields.Origin.value === 'USA');\n * usaCarsDm = usaCarsFn(dm);\n * console.log(usaCarsDm);\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {SelectionPredicate} selectFn - Predicate funciton which is called for each row with the current row\n *      ```\n *          function (row, i)  { ... }\n *      ```\n * @param {Object} [config] - The configuration object to control the inclusion exclusion of a row in resultant\n *      DataModel instance\n * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - The mode of the selection\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const select = (...args) => dm => dm.select(...args);\n\n/**\n * This is functional version of projection operator. {@link link_to_projection | Projection} is a column filtering\n * operation.It expects list of fields name and either include those or exclude those based on {@link FilteringMode} on\n * the  resultant variable.It returns a function which is called with the DataModel instance on which the action needs\n * to be performed.\n *\n * Projection expects array of fields name based on which it creates the selection and rejection set. All the field\n * whose name is present in array goes in selection set and rest of the fields goes in rejection set.\n *\n * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n * resulatant datamodel.\n *\n * @warning\n * Selection and rejection set is only a logical idea for concept explanation purpose.\n *\n * @error\n * `FilteringMode.ALL` is not a valid working mode for functional version of `select`. Its only avialable on the\n * chained version.\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {Array.<string | Regexp>} projField - An array of column names in string or regular expression.\n * @param {Object} [config] - An optional config to control the creation of new DataModel\n * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - Mode of the projection\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const project = (...args) => dm => dm.project(...args);\n\n/**\n * This is functional version of binnig operator. Binning happens on a measure field based on a binning configuration.\n * Binning in DataModel does not aggregate the number of rows present in DataModel instance after binning, it just adds\n * a new field with the binned value. Refer binning {@link example_of_binning | example} to have a intuition of what\n * binning is and the use case.\n *\n * Binning can be configured by\n * - providing custom bin configuration with non uniform buckets\n * - providing bin count\n * - providing each bin size\n *\n * When custom buckets are provided as part of binning configuration\n * @example\n *  // DataModel already prepared and assigned to dm vairable\n *  const buckets = {\n *      start: 30\n *      stops: [80, 100, 110]\n *  };\n *  const config = { buckets, name: 'binnedHP' }\n *  const binFn = bin('horsepower', config);\n *  const binnedDm = binFn(dm);\n *\n * @text\n * When `binCount` is defined as part of binning configuration\n * @example\n *  // DataModel already prepared and assigned to dm vairable\n *  const config = { binCount: 5, name: 'binnedHP' }\n *  const binFn = bin('horsepower', config);\n *  const binnedDm = binFn(Dm);\n *\n * @text\n * When `binSize` is defined as part of binning configuration\n * @example\n *  // DataModel already prepared and assigned to dm vairable\n *  const config = { binSize: 200, name: 'binnedHorsepower' }\n *  const binnedDm = dataModel.bin('horsepower', config);\n *  const binnedDm = binFn(Dm);\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {String} name Name of measure which will be used to create bin\n * @param {Object} config Config required for bin creation\n * @param {Array.<Number>} config.bucketObj.stops Defination of bucket ranges. Two subsequent number from arrays\n *      are picked and a range is created. The first number from range is inclusive and the second number from range\n *      is exclusive.\n * @param {Number} [config.bucketObj.startAt] Force the start of the bin from a particular number.\n *      If not mentioned, the start of the bin or the lower domain of the data if stops is not mentioned, else its\n *      the first value of the stop.\n * @param {Number} config.binSize Bucket size for each bin\n * @param {Number} config.binCount Number of bins which will be created\n * @param {String} config.name Name of the new binned field to be created\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const bin = (...args) => dm => dm.bin(...args);\n\n/**\n * This is functional version of `groupBy` operator.Groups the data using particular dimensions and by reducing\n * measures. It expects a list of dimensions using which it projects the datamodel and perform aggregations to reduce\n * the duplicate tuples. Refer this {@link link_to_one_example_with_group_by | document} to know the intuition behind\n * groupBy.\n *\n * DataModel by default provides definition of few {@link reducer | Reducers}.\n * {@link ReducerStore | User defined reducers} can also be registered.\n *\n * This is the chained implementation of `groupBy`.\n * `groupBy` also supports {@link link_to_compose_groupBy | composability}\n *\n * @example\n * const groupBy = DataModel.Operators.groupBy;\n * const groupedFn = groupBy(['Year'], { horsepower: 'max' } );\n * groupedDM = groupByFn(dm);\n *\n * @public\n *\n * @param {Array.<string>} fieldsArr - Array containing the name of dimensions\n * @param {Object} [reducers={}] - A map whose key is the variable name and value is the name of the reducer. If its\n *      not passed, or any variable is ommitted from the object, default aggregation function is used from the\n *      schema of the variable.\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const groupBy = (...args) => dm => dm.groupBy(...args);\n\n/**\n * Enables composing operators to run multiple operations and save group of operataion as named opration on a DataModel.\n * The resulting DataModel will be the result of all the operation provided. The operations provided will be executed in\n * a serial manner ie. result of one operation will be the input for the next operations (like pipe operator in unix).\n *\n * Suported operations in compose are\n * - `select`\n * - `project`\n * - `groupBy`\n * - `bin`\n * - `compose`\n *\n * @example\n * const compose = DataModel.Operators.compose;\n * const select = DataModel.Operators.select;\n * const project = DataModel.Operators.project;\n *\n * let composedFn = compose(\n *    select(fields => fields.netprofit.value <= 15),\n *    project(['netprofit', 'netsales']));\n *\n * const dataModel = new DataModel(data1, schema1);\n *\n * let composedDm = composedFn(dataModel);\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {Array.<Operators>} operators: An array of operation that will be applied on the\n * datatable.\n *\n * @returns {DataModel} Instance of resultant DataModel\n */\nexport const compose = (...operations) =>\n    (dm, config = { saveChild: true }) => {\n        let currentDM = dm;\n        let firstChild;\n        const derivations = [];\n\n        operations.forEach((operation) => {\n            currentDM = operation(currentDM);\n            derivations.push(...currentDM._derivation);\n            if (!firstChild) {\n                firstChild = currentDM;\n            }\n        });\n\n        if (firstChild && firstChild !== currentDM) {\n            firstChild.dispose();\n        }\n\n        // reset all ancestorDerivation saved in-between compose\n        currentDM._ancestorDerivation = [];\n        persistDerivations(\n            dm,\n            currentDM,\n            DM_DERIVATIVES.COMPOSE,\n            null,\n            derivations\n        );\n\n        if (config.saveChild) {\n            currentDM.setParent(dm);\n        } else {\n            currentDM.setParent(null);\n        }\n\n        return currentDM;\n    };\n","/**\n * The helper function that returns an array of common schema\n * from two fieldStore instances.\n *\n * @param {FieldStore} fs1 - The first FieldStore instance.\n * @param {FieldStore} fs2 - The second FieldStore instance.\n * @return {Array} An array containing the common schema.\n */\nexport function getCommonSchema (fs1, fs2) {\n    const retArr = [];\n    const fs1Arr = [];\n    fs1.fields.forEach((field) => {\n        fs1Arr.push(field.schema().name);\n    });\n    fs2.fields.forEach((field) => {\n        if (fs1Arr.indexOf(field.schema().name) !== -1) {\n            retArr.push(field.schema().name);\n        }\n    });\n    return retArr;\n}\n","import DataModel from '../datamodel';\nimport { extend2 } from '../utils';\nimport { getCommonSchema } from './get-common-schema';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { JOINS } from '../constants';\nimport { prepareJoinData } from '../helper';\n/**\n * Default filter function for crossProduct.\n *\n * @return {boolean} Always returns true.\n */\nfunction defaultFilterFn() { return true; }\n\n/**\n * Implementation of cross product operation between two DataModel instances.\n * It internally creates the data and schema for the new DataModel.\n *\n * @param {DataModel} dataModel1 - The left DataModel instance.\n * @param {DataModel} dataModel2 - The right DataModel instance.\n * @param {Function} filterFn - The filter function which is used to filter the tuples.\n * @param {boolean} [replaceCommonSchema=false] - The flag if the common name schema should be there.\n * @return {DataModel} Returns The newly created DataModel instance from the crossProduct operation.\n */\nexport function crossProduct (dm1, dm2, filterFn, replaceCommonSchema = false, jointype = JOINS.CROSS) {\n    const schema = [];\n    const data = [];\n    const applicableFilterFn = filterFn || defaultFilterFn;\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    const dm1FieldStoreName = dm1FieldStore.name;\n    const dm2FieldStoreName = dm2FieldStore.name;\n    const name = `${dm1FieldStore.name}.${dm2FieldStore.name}`;\n    const commonSchemaList = getCommonSchema(dm1FieldStore, dm2FieldStore);\n\n    if (dm1FieldStoreName === dm2FieldStoreName) {\n        throw new Error('DataModels must have different alias names');\n    }\n    // Here prepare the schema\n    dm1FieldStore.fields.forEach((field) => {\n        const tmpSchema = extend2({}, field.schema());\n        if (commonSchemaList.indexOf(tmpSchema.name) !== -1 && !replaceCommonSchema) {\n            tmpSchema.name = `${dm1FieldStore.name}.${tmpSchema.name}`;\n        }\n        schema.push(tmpSchema);\n    });\n    dm2FieldStore.fields.forEach((field) => {\n        const tmpSchema = extend2({}, field.schema());\n        if (commonSchemaList.indexOf(tmpSchema.name) !== -1) {\n            if (!replaceCommonSchema) {\n                tmpSchema.name = `${dm2FieldStore.name}.${tmpSchema.name}`;\n                schema.push(tmpSchema);\n            }\n        } else {\n            schema.push(tmpSchema);\n        }\n    });\n\n    // Here prepare Data\n    rowDiffsetIterator(dm1._rowDiffset, (i) => {\n        let rowAdded = false;\n        let rowPosition;\n        rowDiffsetIterator(dm2._rowDiffset, (ii) => {\n            const tuple = [];\n            const userArg = {};\n            userArg[dm1FieldStoreName] = {};\n            userArg[dm2FieldStoreName] = {};\n            dm1FieldStore.fields.forEach((field) => {\n                tuple.push(field.partialField.data[i]);\n                userArg[dm1FieldStoreName][field.name()] = field.partialField.data[i];\n            });\n            dm2FieldStore.fields.forEach((field) => {\n                if (!(commonSchemaList.indexOf(field.schema().name) !== -1 && replaceCommonSchema)) {\n                    tuple.push(field.partialField.data[ii]);\n                }\n                userArg[dm2FieldStoreName][field.name()] = field.partialField.data[ii];\n            });\n\n            let cachedStore = {};\n            let cloneProvider1 = () => dm1.detachedRoot();\n            let cloneProvider2 = () => dm2.detachedRoot();\n\n            const dm1Fields = prepareJoinData(userArg[dm1FieldStoreName]);\n            const dm2Fields = prepareJoinData(userArg[dm2FieldStoreName]);\n            if (applicableFilterFn(dm1Fields, dm2Fields, cloneProvider1, cloneProvider2, cachedStore)) {\n                const tupleObj = {};\n                tuple.forEach((cellVal, iii) => {\n                    tupleObj[schema[iii].name] = cellVal;\n                });\n                if (rowAdded && JOINS.CROSS !== jointype) {\n                    data[rowPosition] = tupleObj;\n                }\n                else {\n                    data.push(tupleObj);\n                    rowAdded = true;\n                    rowPosition = i;\n                }\n            } else if ((jointype === JOINS.LEFTOUTER || jointype === JOINS.RIGHTOUTER) && !rowAdded) {\n                const tupleObj = {};\n                let len = dm1FieldStore.fields.length - 1;\n                tuple.forEach((cellVal, iii) => {\n                    if (iii <= len) {\n                        tupleObj[schema[iii].name] = cellVal;\n                    }\n                    else {\n                        tupleObj[schema[iii].name] = null;\n                    }\n                });\n                rowAdded = true;\n                rowPosition = i;\n                data.push(tupleObj);\n            }\n        });\n    });\n\n    return new DataModel(data, schema, { name });\n}\n","/**\n * The default sort function.\n *\n * @param {*} a - The first value.\n * @param {*} b - The second value.\n * @return {number} Returns the comparison result e.g. 1 or 0 or -1.\n */\nfunction defSortFn (a, b) {\n    const a1 = `${a}`;\n    const b1 = `${b}`;\n    if (a1 < b1) {\n        return -1;\n    }\n    if (a1 > b1) {\n        return 1;\n    }\n    return 0;\n}\n\n/**\n * The helper function for merge sort which creates the sorted array\n * from the two halves of the input array.\n *\n * @param {Array} arr - The target array which needs to be merged.\n * @param {number} lo - The starting index of the first array half.\n * @param {number} mid - The ending index of the first array half.\n * @param {number} hi - The ending index of the second array half.\n * @param {Function} sortFn - The sort function.\n */\nfunction merge (arr, lo, mid, hi, sortFn) {\n    const mainArr = arr;\n    const auxArr = [];\n    for (let i = lo; i <= hi; i += 1) {\n        auxArr[i] = mainArr[i];\n    }\n    let a = lo;\n    let b = mid + 1;\n\n    for (let i = lo; i <= hi; i += 1) {\n        if (a > mid) {\n            mainArr[i] = auxArr[b];\n            b += 1;\n        } else if (b > hi) {\n            mainArr[i] = auxArr[a];\n            a += 1;\n        } else if (sortFn(auxArr[a], auxArr[b]) <= 0) {\n            mainArr[i] = auxArr[a];\n            a += 1;\n        } else {\n            mainArr[i] = auxArr[b];\n            b += 1;\n        }\n    }\n}\n\n/**\n * The helper function for merge sort which would be called\n * recursively for sorting the array halves.\n *\n * @param {Array} arr - The target array which needs to be sorted.\n * @param {number} lo - The starting index of the array half.\n * @param {number} hi - The ending index of the array half.\n * @param {Function} sortFn - The sort function.\n * @return {Array} Returns the target array itself.\n */\nfunction sort (arr, lo, hi, sortFn) {\n    if (hi === lo) { return arr; }\n\n    const mid = lo + Math.floor((hi - lo) / 2);\n    sort(arr, lo, mid, sortFn);\n    sort(arr, mid + 1, hi, sortFn);\n    merge(arr, lo, mid, hi, sortFn);\n\n    return arr;\n}\n\n/**\n * The implementation of merge sort.\n * It is used in DataModel for stable sorting as it is not sure\n * what the sorting algorithm used by browsers is stable or not.\n *\n * @param {Array} arr - The target array which needs to be sorted.\n * @param {Function} [sortFn=defSortFn] - The sort function.\n * @return {Array} Returns the input array itself in sorted order.\n */\nexport function mergeSort (arr, sortFn = defSortFn) {\n    if (arr.length > 1) {\n        sort(arr, 0, arr.length - 1, sortFn);\n    }\n    return arr;\n}\n","import { DimensionSubtype, MeasureSubtype } from '../enums';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { mergeSort } from './merge-sort';\nimport { fieldInSchema } from '../helper';\nimport { isCallable, isArray, } from '../utils';\n/**\n * Generates the sorting functions to sort the data of a DataModel instance\n * according to the input data type.\n *\n * @param {string} dataType - The data type e.g. 'measure', 'datetime' etc.\n * @param {string} sortType - The sorting order i.e. 'asc' or 'desc'.\n * @param {integer} index - The index of the data which will be sorted.\n * @return {Function} Returns the the sorting function.\n */\nfunction getSortFn (dataType, sortType, index) {\n    let retFunc;\n    switch (dataType) {\n    case MeasureSubtype.CONTINUOUS:\n    case DimensionSubtype.TEMPORAL:\n        if (sortType === 'desc') {\n            retFunc = (a, b) => b[index] - a[index];\n        } else {\n            retFunc = (a, b) => a[index] - b[index];\n        }\n        break;\n    default:\n        retFunc = (a, b) => {\n            const a1 = `${a[index]}`;\n            const b1 = `${b[index]}`;\n            if (a1 < b1) {\n                return sortType === 'desc' ? 1 : -1;\n            }\n            if (a1 > b1) {\n                return sortType === 'desc' ? -1 : 1;\n            }\n            return 0;\n        };\n    }\n    return retFunc;\n}\n\n/**\n * Groups the data according to the specified target field.\n *\n * @param {Array} data - The input data array.\n * @param {number} fieldIndex - The target field index within schema array.\n * @return {Array} Returns an array containing the grouped data.\n */\nfunction groupData(data, fieldIndex) {\n    const hashMap = new Map();\n    const groupedData = [];\n\n    data.forEach((datum) => {\n        const fieldVal = datum[fieldIndex];\n        if (hashMap.has(fieldVal)) {\n            groupedData[hashMap.get(fieldVal)][1].push(datum);\n        } else {\n            groupedData.push([fieldVal, [datum]]);\n            hashMap.set(fieldVal, groupedData.length - 1);\n        }\n    });\n\n    return groupedData;\n}\n\n/**\n * Creates the argument value used for sorting function when sort is done\n * with another fields.\n *\n * @param {Array} groupedDatum - The grouped datum for a single dimension field value.\n * @param {Array} targetFields - An array of the sorting fields.\n * @param {Array} targetFieldDetails - An array of the sorting field details in schema.\n * @return {Object} Returns an object containing the value of sorting fields and the target field name.\n */\nfunction createSortingFnArg(groupedDatum, targetFields, targetFieldDetails) {\n    const arg = {\n        label: groupedDatum[0]\n    };\n\n    targetFields.reduce((acc, next, idx) => {\n        acc[next] = groupedDatum[1].map(datum => datum[targetFieldDetails[idx].index]);\n        return acc;\n    }, arg);\n\n    return arg;\n}\n\n/**\n * Sorts the data before return in dataBuilder.\n *\n * @param {Object} dataObj - An object containing the data and schema.\n * @param {Array} sortingDetails - An array containing the sorting configs.\n */\nfunction sortData(dataObj, sortingDetails) {\n    const { data, schema } = dataObj;\n    let fieldName;\n    let sortMeta;\n    let fDetails;\n    let i = sortingDetails.length - 1;\n\n    for (; i >= 0; i--) {\n        fieldName = sortingDetails[i][0];\n        sortMeta = sortingDetails[i][1];\n        fDetails = fieldInSchema(schema, fieldName);\n\n        if (!fDetails) {\n            // eslint-disable-next-line no-continue\n            continue;\n        }\n\n        if (isCallable(sortMeta)) {\n            // eslint-disable-next-line no-loop-func\n            mergeSort(data, (a, b) => sortMeta(a[fDetails.index], b[fDetails.index]));\n        } else if (isArray(sortMeta)) {\n            const groupedData = groupData(data, fDetails.index);\n            const sortingFn = sortMeta[sortMeta.length - 1];\n            const targetFields = sortMeta.slice(0, sortMeta.length - 1);\n            const targetFieldDetails = targetFields.map(f => fieldInSchema(schema, f));\n\n            groupedData.forEach((groupedDatum) => {\n                groupedDatum.push(createSortingFnArg(groupedDatum, targetFields, targetFieldDetails));\n            });\n\n            mergeSort(groupedData, (a, b) => {\n                const m = a[2];\n                const n = b[2];\n                return sortingFn(m, n);\n            });\n\n            // Empty the array\n            data.length = 0;\n            groupedData.forEach((datum) => {\n                data.push(...datum[1]);\n            });\n        } else {\n            sortMeta = String(sortMeta).toLowerCase() === 'desc' ? 'desc' : 'asc';\n            mergeSort(data, getSortFn(fDetails.type, sortMeta, fDetails.index));\n        }\n    }\n\n    dataObj.uids = [];\n    data.forEach((value) => {\n        dataObj.uids.push(value.pop());\n    });\n}\n\n\n/**\n * Builds the actual data array.\n *\n * @param {Array} fieldStore - An array of field.\n * @param {string} rowDiffset - A string consisting of which rows to be included eg. '0-2,4,6';\n * @param {string} colIdentifier - A string consisting of the details of which column\n * to be included eg 'date,sales,profit';\n * @param {Object} sortingDetails - An object containing the sorting details of the DataModel instance.\n * @param {Object} options - The options required to create the type of the data.\n * @return {Object} Returns an object containing the multidimensional array and the relative schema.\n */\nexport function dataBuilder (fieldStore, rowDiffset, colIdentifier, sortingDetails, options) {\n    const defOptions = {\n        addUid: false,\n        columnWise: false\n    };\n    options = Object.assign({}, defOptions, options);\n\n    const retObj = {\n        schema: [],\n        data: [],\n        uids: []\n    };\n    const addUid = options.addUid;\n    const reqSorting = sortingDetails && sortingDetails.length > 0;\n    // It stores the fields according to the colIdentifier argument\n    const tmpDataArr = [];\n    // Stores the fields according to the colIdentifier argument\n    const colIArr = colIdentifier.split(',');\n\n    colIArr.forEach((colName) => {\n        for (let i = 0; i < fieldStore.length; i += 1) {\n            if (fieldStore[i].name() === colName) {\n                tmpDataArr.push(fieldStore[i]);\n                break;\n            }\n        }\n    });\n\n    // Inserts the schema to the schema object\n    tmpDataArr.forEach((field) => {\n        /** @todo Need to use extend2 here otherwise user can overwrite the schema. */\n        retObj.schema.push(field.schema());\n    });\n\n    if (addUid) {\n        retObj.schema.push({\n            name: 'uid',\n            type: 'identifier'\n        });\n    }\n\n    rowDiffsetIterator(rowDiffset, (i) => {\n        retObj.data.push([]);\n        const insertInd = retObj.data.length - 1;\n        let start = 0;\n        tmpDataArr.forEach((field, ii) => {\n            retObj.data[insertInd][ii + start] = field.partialField.data[i];\n        });\n        if (addUid) {\n            retObj.data[insertInd][tmpDataArr.length] = i;\n        }\n        // Creates an array of unique identifiers for each row\n        retObj.uids.push(i);\n\n        // If sorting needed then there is the need to expose the index\n        // mapping from the old index to its new index\n        if (reqSorting) { retObj.data[insertInd].push(i); }\n    });\n\n    // Handles the sort functionality\n    if (reqSorting) {\n        sortData(retObj, sortingDetails);\n    }\n\n    if (options.columnWise) {\n        const tmpData = Array(...Array(retObj.schema.length)).map(() => []);\n        retObj.data.forEach((tuple) => {\n            tuple.forEach((data, i) => {\n                tmpData[i].push(data);\n            });\n        });\n        retObj.data = tmpData;\n    }\n\n    return retObj;\n}\n","import DataModel from '../datamodel';\nimport { extend2 } from '../utils';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { isArrEqual } from '../utils/helper';\n\n/**\n * Performs the union operation between two dm instances.\n *\n * @todo Fix the conflicts between union and difference terminology here.\n *\n * @param {dm} dm1 - The first dm instance.\n * @param {dm} dm2 - The second dm instance.\n * @return {dm} Returns the newly created dm after union operation.\n */\nexport function difference (dm1, dm2) {\n    const hashTable = {};\n    const schema = [];\n    const schemaNameArr = [];\n    const data = [];\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    const dm1FieldStoreFieldObj = dm1FieldStore.fieldsObj();\n    const dm2FieldStoreFieldObj = dm2FieldStore.fieldsObj();\n    const name = `${dm1FieldStore.name} union ${dm2FieldStore.name}`;\n\n   // For union the columns should match otherwise return a clone of the dm1\n    if (!isArrEqual(dm1._colIdentifier.split(',').sort(), dm2._colIdentifier.split(',').sort())) {\n        return null;\n    }\n\n    // Prepare the schema\n    (dm1._colIdentifier.split(',')).forEach((fieldName) => {\n        const field = dm1FieldStoreFieldObj[fieldName];\n        schema.push(extend2({}, field.schema()));\n        schemaNameArr.push(field.schema().name);\n    });\n\n    /**\n     * The helper function to create the data.\n     *\n     * @param {dm} dm - The dm instance for which the data is inserted.\n     * @param {Object} fieldsObj - The fieldStore object format.\n     * @param {boolean} addData - If true only tuple will be added to the data.\n     */\n    function prepareDataHelper(dm, fieldsObj, addData) {\n        rowDiffsetIterator(dm._rowDiffset, (i) => {\n            const tuple = {};\n            let hashData = '';\n            schemaNameArr.forEach((schemaName) => {\n                const value = fieldsObj[schemaName].partialField.data[i];\n                hashData += `-${value}`;\n                tuple[schemaName] = value;\n            });\n            if (!hashTable[hashData]) {\n                if (addData) { data.push(tuple); }\n                hashTable[hashData] = true;\n            }\n        });\n    }\n\n    // Prepare the data\n    prepareDataHelper(dm2, dm2FieldStoreFieldObj, false);\n    prepareDataHelper(dm1, dm1FieldStoreFieldObj, true);\n\n    return new DataModel(data, schema, { name });\n}\n\n","import { isArray } from '../utils';\nimport InvalidAwareTypes from '../invalid-aware-types';\nimport { GROUP_BY_FUNCTIONS } from '../enums';\n\nconst { SUM, AVG, FIRST, LAST, COUNT, STD, MIN, MAX } = GROUP_BY_FUNCTIONS;\n\nfunction getFilteredValues(arr) {\n    return arr.filter(item => !(item instanceof InvalidAwareTypes));\n}\n/**\n * Reducer function that returns the sum of all the values.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the sum of the array.\n */\nfunction sum (arr) {\n    if (isArray(arr) && !(arr[0] instanceof Array)) {\n        const filteredNumber = getFilteredValues(arr);\n        const totalSum = filteredNumber.length ?\n                            filteredNumber.reduce((acc, curr) => acc + curr, 0)\n                            : InvalidAwareTypes.NULL;\n        return totalSum;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Reducer function that returns the average of all the values.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the mean value of the array.\n */\nfunction avg (arr) {\n    if (isArray(arr) && !(arr[0] instanceof Array)) {\n        const totalSum = sum(arr);\n        const len = arr.length || 1;\n        return (Number.isNaN(totalSum) || totalSum instanceof InvalidAwareTypes) ?\n                 InvalidAwareTypes.NULL : totalSum / len;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Reducer function that gives the min value amongst all the values.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the minimum value of the array.\n */\nfunction min (arr) {\n    if (isArray(arr) && !(arr[0] instanceof Array)) {\n        // Filter out undefined, null and NaN values\n        const filteredValues = getFilteredValues(arr);\n\n        return (filteredValues.length) ? Math.min(...filteredValues) : InvalidAwareTypes.NULL;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Reducer function that gives the max value amongst all the values.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the maximum value of the array.\n */\nfunction max (arr) {\n    if (isArray(arr) && !(arr[0] instanceof Array)) {\n        // Filter out undefined, null and NaN values\n        const filteredValues = getFilteredValues(arr);\n\n        return (filteredValues.length) ? Math.max(...filteredValues) : InvalidAwareTypes.NULL;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Reducer function that gives the first value of the array.\n *\n * @public\n * @param  {Array} arr - The input array.\n * @return {number} Returns the first value of the array.\n */\nfunction first (arr) {\n    return arr[0];\n}\n\n/**\n * Reducer function that gives the last value of the array.\n *\n * @public\n * @param  {Array} arr - The input array.\n * @return {number} Returns the last value of the array.\n */\nfunction last (arr) {\n    return arr[arr.length - 1];\n}\n\n/**\n * Reducer function that gives the count value of the array.\n *\n * @public\n * @param  {Array} arr - The input array.\n * @return {number} Returns the length of the array.\n */\nfunction count (arr) {\n    if (isArray(arr)) {\n        return arr.length;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Calculates the variance of the input array.\n *\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the variance of the input array.\n */\nfunction variance (arr) {\n    let mean = avg(arr);\n    return avg(arr.map(num => (num - mean) ** 2));\n}\n\n/**\n * Calculates the square root of the variance of the input array.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the square root of the variance.\n */\nfunction std (arr) {\n    return Math.sqrt(variance(arr));\n}\n\n\nconst fnList = {\n    [SUM]: sum,\n    [AVG]: avg,\n    [MIN]: min,\n    [MAX]: max,\n    [FIRST]: first,\n    [LAST]: last,\n    [COUNT]: count,\n    [STD]: std\n};\n\nconst defaultReducerName = SUM;\n\nexport {\n    defaultReducerName,\n    sum as defReducer,\n    fnList,\n};\n","import { defReducer, fnList } from '../operator';\n\n/**\n * A page level storage which stores, registers, unregisters reducers for all the datamodel instances. There is only one\n * reducer store available in a page. All the datamodel instances receive same instance of reducer store. DataModel\n * out of the box provides handful of {@link reducer | reducers} which can be used as reducer funciton.\n *\n * @public\n * @namespace DataModel\n */\nclass ReducerStore {\n    constructor () {\n        this.store = new Map();\n        this.store.set('defReducer', defReducer);\n\n        Object.entries(fnList).forEach((key) => {\n            this.store.set(key[0], key[1]);\n        });\n    }\n\n    /**\n     * Changes the `defaultReducer` globally. For all the fields which does not have `defAggFn` mentioned in schema, the\n     * value of `defaultReducer` is used for aggregation.\n     *\n     * @public\n     * @param {string} [reducer='sum'] - The name of the default reducer. It picks up the definition from store by doing\n     * name lookup. If no name is found then it takes `sum` as the default reducer.\n     * @return {ReducerStore} Returns instance of the singleton store in page.\n     */\n    defaultReducer (...params) {\n        if (!params.length) {\n            return this.store.get('defReducer');\n        }\n\n        let reducer = params[0];\n\n        if (typeof reducer === 'function') {\n            this.store.set('defReducer', reducer);\n        } else {\n            reducer = String(reducer);\n            if (Object.keys(fnList).indexOf(reducer) !== -1) {\n                this.store.set('defReducer', fnList[reducer]);\n            } else {\n                throw new Error(`Reducer ${reducer} not found in registry`);\n            }\n        }\n        return this;\n    }\n\n    /**\n     *\n     * Registers a {@link reducer | reducer}.\n     * A {@link reducer | reducer} has to be registered before it is used.\n     *\n     * @example\n     *  // find the mean squared value of a given set\n     *  const reducerStore = DataModel.Reducers();\n     *\n     *  reducers.register('meanSquared', (arr) => {\n     *      const squaredVal = arr.map(item => item * item);\n     *      let sum = 0;\n     *      for (let i = 0, l = squaredVal.length; i < l; i++) {\n     *          sum += squaredVal[i++];\n     *      }\n     *\n     *      return sum;\n     *  })\n     *\n     *  // datamodel (dm) is already prepared with cars.json\n     *  const dm1 = dm.groupBy(['origin'], {\n     *      accleration: 'meanSquared'\n     *  });\n     *\n     * @public\n     *\n     * @param {string} name formal name for a reducer. If the given name already exists in store it is overridden by new\n     *      definition.\n     * @param {Function} reducer definition of {@link reducer} function.\n     *\n     * @return {Function} function for unregistering the reducer.\n     */\n    register (name, reducer) {\n        if (typeof reducer !== 'function') {\n            throw new Error('Reducer should be a function');\n        }\n\n        name = String(name);\n        this.store.set(name, reducer);\n\n        return () => { this.__unregister(name); };\n    }\n\n    __unregister (name) {\n        if (this.store.has(name)) {\n            this.store.delete(name);\n        }\n    }\n\n    resolve (name) {\n        if (name instanceof Function) {\n            return name;\n        }\n        return this.store.get(name);\n    }\n}\n\nconst reducerStore = (function () {\n    let store = null;\n\n    function getStore () {\n        if (store === null) {\n            store = new ReducerStore();\n        }\n        return store;\n    }\n    return getStore();\n}());\n\nexport default reducerStore;\n","import { extend2 } from '../utils';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport DataModel from '../export';\nimport reducerStore from '../utils/reducer-store';\nimport { defaultReducerName } from './group-by-function';\nimport { FieldType } from '../enums';\n\n/**\n * This function sanitize the user given field and return a common Array structure field\n * list\n * @param  {DataModel} dataModel the dataModel operating on\n * @param  {Array} fieldArr  user input of field Array\n * @return {Array}           arrays of field name\n */\nfunction getFieldArr (dataModel, fieldArr) {\n    const retArr = [];\n    const fieldStore = dataModel.getFieldspace();\n    const dimensions = fieldStore.getDimension();\n\n    Object.entries(dimensions).forEach(([key]) => {\n        if (fieldArr && fieldArr.length) {\n            if (fieldArr.indexOf(key) !== -1) {\n                retArr.push(key);\n            }\n        } else {\n            retArr.push(key);\n        }\n    });\n\n    return retArr;\n}\n\n/**\n * This sanitize the reducer provide by the user and create a common type of object.\n * user can give function Also\n * @param  {DataModel} dataModel     dataModel to worked on\n * @param  {Object|function} [reducers={}] reducer provided by the users\n * @return {Object}               object containing reducer function for every measure\n */\nfunction getReducerObj (dataModel, reducers = {}) {\n    const retObj = {};\n    const fieldStore = dataModel.getFieldspace();\n    const measures = fieldStore.getMeasure();\n    const defReducer = reducerStore.defaultReducer();\n\n    Object.keys(measures).forEach((measureName) => {\n        if (typeof reducers[measureName] !== 'string') {\n            reducers[measureName] = measures[measureName].defAggFn();\n        }\n        const reducerFn = reducerStore.resolve(reducers[measureName]);\n        if (reducerFn) {\n            retObj[measureName] = reducerFn;\n        } else {\n            retObj[measureName] = defReducer;\n            reducers[measureName] = defaultReducerName;\n        }\n    });\n    return retObj;\n}\n\n/**\n * main function which perform the group-by operations which reduce the measures value is the\n * fields are common according to the reducer function provided\n * @param  {DataModel} dataModel the dataModel to worked\n * @param  {Array} fieldArr  fields according to which the groupby should be worked\n * @param  {Object|Function} reducers  reducers function\n * @param {DataModel} existingDataModel Existing datamodel instance\n * @return {DataModel} new dataModel with the group by\n */\nfunction groupBy (dataModel, fieldArr, reducers, existingDataModel) {\n    const sFieldArr = getFieldArr(dataModel, fieldArr);\n    const reducerObj = getReducerObj(dataModel, reducers);\n    const fieldStore = dataModel.getFieldspace();\n    const fieldStoreObj = fieldStore.fieldsObj();\n    const dbName = fieldStore.name;\n    const dimensionArr = [];\n    const measureArr = [];\n    const schema = [];\n    const hashMap = {};\n    const data = [];\n    let newDataModel;\n\n    // Prepare the schema\n    Object.entries(fieldStoreObj).forEach(([key, value]) => {\n        if (sFieldArr.indexOf(key) !== -1 || reducerObj[key]) {\n            schema.push(extend2({}, value.schema()));\n\n            switch (value.schema().type) {\n            case FieldType.MEASURE:\n                measureArr.push(key);\n                break;\n            default:\n            case FieldType.DIMENSION:\n                dimensionArr.push(key);\n            }\n        }\n    });\n    // Prepare the data\n    let rowCount = 0;\n    rowDiffsetIterator(dataModel._rowDiffset, (i) => {\n        let hash = '';\n        dimensionArr.forEach((_) => {\n            hash = `${hash}-${fieldStoreObj[_].partialField.data[i]}`;\n        });\n        if (hashMap[hash] === undefined) {\n            hashMap[hash] = rowCount;\n            data.push({});\n            dimensionArr.forEach((_) => {\n                data[rowCount][_] = fieldStoreObj[_].partialField.data[i];\n            });\n            measureArr.forEach((_) => {\n                data[rowCount][_] = [fieldStoreObj[_].partialField.data[i]];\n            });\n            rowCount += 1;\n        } else {\n            measureArr.forEach((_) => {\n                data[hashMap[hash]][_].push(fieldStoreObj[_].partialField.data[i]);\n            });\n        }\n    });\n\n    // reduction\n    let cachedStore = {};\n    let cloneProvider = () => dataModel.detachedRoot();\n    data.forEach((row) => {\n        const tuple = row;\n        measureArr.forEach((_) => {\n            tuple[_] = reducerObj[_](row[_], cloneProvider, cachedStore);\n        });\n    });\n    if (existingDataModel) {\n        existingDataModel.__calculateFieldspace();\n        newDataModel = existingDataModel;\n    }\n    else {\n        newDataModel = new DataModel(data, schema, { name: dbName });\n    }\n    return newDataModel;\n}\n\nexport { groupBy, getFieldArr, getReducerObj };\n","import { getCommonSchema } from './get-common-schema';\n\n/**\n * The filter function used in natural join.\n * It generates a function that will have the logic to join two\n * DataModel instances by the process of natural join.\n *\n * @param {DataModel} dm1 - The left DataModel instance.\n * @param {DataModel} dm2 - The right DataModel instance.\n * @return {Function} Returns a function that is used in cross-product operation.\n */\nexport function naturalJoinFilter (dm1, dm2) {\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    // const dm1FieldStoreName = dm1FieldStore.name;\n    // const dm2FieldStoreName = dm2FieldStore.name;\n    const commonSchemaArr = getCommonSchema(dm1FieldStore, dm2FieldStore);\n\n    return (dm1Fields, dm2Fields) => {\n        let retainTuple = true;\n        commonSchemaArr.forEach((fieldName) => {\n            if (dm1Fields[fieldName].value ===\n                dm2Fields[fieldName].value && retainTuple) {\n                retainTuple = true;\n            } else {\n                retainTuple = false;\n            }\n        });\n        return retainTuple;\n    };\n}\n","import DataModel from '../export';\nimport { extend2 } from '../utils';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { isArrEqual } from '../utils/helper';\n/**\n * Performs the union operation between two dm instances.\n *\n * @param {dm} dm1 - The first dm instance.\n * @param {dm} dm2 - The second dm instance.\n * @return {dm} Returns the newly created dm after union operation.\n */\nexport function union (dm1, dm2) {\n    const hashTable = {};\n    const schema = [];\n    const schemaNameArr = [];\n    const data = [];\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    const dm1FieldStoreFieldObj = dm1FieldStore.fieldsObj();\n    const dm2FieldStoreFieldObj = dm2FieldStore.fieldsObj();\n    const name = `${dm1FieldStore.name} union ${dm2FieldStore.name}`;\n\n    // For union the columns should match otherwise return a clone of the dm1\n    if (!isArrEqual(dm1._colIdentifier.split(',').sort(), dm2._colIdentifier.split(',').sort())) {\n        return null;\n    }\n\n    // Prepare the schema\n    (dm1._colIdentifier.split(',')).forEach((fieldName) => {\n        const field = dm1FieldStoreFieldObj[fieldName];\n        schema.push(extend2({}, field.schema()));\n        schemaNameArr.push(field.schema().name);\n    });\n\n    /**\n     * The helper function to create the data.\n     *\n     * @param {dm} dm - The dm instance for which the data is inserted.\n     * @param {Object} fieldsObj - The fieldStore object format.\n     */\n    function prepareDataHelper (dm, fieldsObj) {\n        rowDiffsetIterator(dm._rowDiffset, (i) => {\n            const tuple = {};\n            let hashData = '';\n            schemaNameArr.forEach((schemaName) => {\n                const value = fieldsObj[schemaName].partialField.data[i];\n                hashData += `-${value}`;\n                tuple[schemaName] = value;\n            });\n            if (!hashTable[hashData]) {\n                data.push(tuple);\n                hashTable[hashData] = true;\n            }\n        });\n    }\n\n    // Prepare the data\n    prepareDataHelper(dm1, dm1FieldStoreFieldObj);\n    prepareDataHelper(dm2, dm2FieldStoreFieldObj);\n\n    return new DataModel(data, schema, { name });\n}\n","import { crossProduct } from './cross-product';\nimport { JOINS } from '../constants';\nimport { union } from './union';\n\n\nexport function leftOuterJoin (dataModel1, dataModel2, filterFn) {\n    return crossProduct(dataModel1, dataModel2, filterFn, false, JOINS.LEFTOUTER);\n}\n\nexport function rightOuterJoin (dataModel1, dataModel2, filterFn) {\n    return crossProduct(dataModel2, dataModel1, filterFn, false, JOINS.RIGHTOUTER);\n}\n\nexport function fullOuterJoin (dataModel1, dataModel2, filterFn) {\n    return union(leftOuterJoin(dataModel1, dataModel2, filterFn), rightOuterJoin(dataModel1, dataModel2, filterFn));\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\n\n/**\n * In {@link DataModel}, every tabular data consists of column, a column is stored as field.\n * Field contains all the data for a given column in an array.\n *\n * Each record consists of several fields; the fields of all records form the columns.\n * Examples of fields: name, gender, sex etc.\n *\n * In DataModel, each field can have multiple attributes which describes its data and behaviour.\n * A field can have two types of data: Measure and Dimension.\n *\n * A Dimension Field is the context on which a data is categorized and the measure is the numerical values that\n * quantify the data set.\n * In short a dimension is the lens through which you are looking at your measure data.\n *\n * Refer to {@link Schema} to get info about possible field attributes.\n *\n * @public\n * @class\n */\nexport default class Field {\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {PartialField} partialField - The partialField instance which holds the whole data.\n     * @param {string} rowDiffset - The data subset definition.\n     */\n    constructor (partialField, rowDiffset) {\n        this.partialField = partialField;\n        this.rowDiffset = rowDiffset;\n    }\n\n    /**\n     * Generates the field type specific domain.\n     *\n     * @public\n     * @abstract\n     */\n    domain () {\n        throw new Error('Not yet implemented');\n    }\n\n    /**\n     * Returns the the field schema.\n     *\n     * @public\n     * @return {string} Returns the field schema.\n     */\n    schema () {\n        return this.partialField.schema;\n    }\n\n    /**\n     * Returns the name of the field.\n     *\n     * @public\n     * @return {string} Returns the name of the field.\n     */\n    name () {\n        return this.partialField.name;\n    }\n\n    /**\n     * Returns the type of the field.\n     *\n     * @public\n     * @return {string} Returns the type of the field.\n     */\n    type () {\n        return this.partialField.schema.type;\n    }\n\n    /**\n     * Returns the subtype of the field.\n     *\n     * @public\n     * @return {string} Returns the subtype of the field.\n     */\n    subtype () {\n        return this.partialField.schema.subtype;\n    }\n\n    /**\n     * Returns the description of the field.\n     *\n     * @public\n     * @return {string} Returns the description of the field.\n     */\n    description () {\n        return this.partialField.schema.description;\n    }\n\n    /**\n     * Returns the display name of the field.\n     *\n     * @public\n     * @return {string} Returns the display name of the field.\n     */\n    displayName () {\n        return this.partialField.schema.displayName || this.partialField.schema.name;\n    }\n\n    /**\n     * Returns the data associated with the field.\n     *\n     * @public\n     * @return {Array} Returns the data.\n     */\n    data () {\n        const data = [];\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            data.push(this.partialField.data[i]);\n        });\n        return data;\n    }\n\n    /**\n     * Returns the formatted version of the underlying field data.\n     *\n     * @public\n     * @abstract\n     */\n    formattedData () {\n        throw new Error('Not yet implemented');\n    }\n}\n","import Field from '../field';\n\n/**\n * Represents dimension field type.\n *\n * @public\n * @class\n * @extends Field\n */\nexport default class Dimension extends Field {\n    /**\n     * Returns the domain for the dimension field.\n     *\n     * @override\n     * @public\n     * @return {any} Returns the calculated domain.\n     */\n    domain () {\n        if (!this._cachedDomain) {\n            this._cachedDomain = this.calculateDataDomain();\n        }\n        return this._cachedDomain;\n    }\n\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @abstract\n     */\n    calculateDataDomain () {\n        throw new Error('Not yet implemented');\n    }\n\n     /**\n     * Returns the formatted version of the underlying field data.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the formatted data.\n     */\n    formattedData () {\n        return this.data();\n    }\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\nimport { DimensionSubtype } from '../../enums';\nimport Dimension from '../dimension';\n/**\n * Represents categorical field subtype.\n *\n * @public\n * @class\n * @extends Dimension\n */\nexport default class Categorical extends Dimension {\n    /**\n     * Returns the subtype of the field.\n     *\n     * @public\n     * @override\n     * @return {string} Returns the subtype of the field.\n     */\n    subtype () {\n        return DimensionSubtype.CATEGORICAL;\n    }\n\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the unique values.\n     */\n    calculateDataDomain () {\n        const hash = new Set();\n        const domain = [];\n\n        // here don't use this.data() as the iteration will be occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (!hash.has(datum)) {\n                hash.add(datum);\n                domain.push(datum);\n            }\n        });\n        return domain;\n    }\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\nimport Dimension from '../dimension';\nimport { DateTimeFormatter } from '../../utils';\nimport InvalidAwareTypes from '../../invalid-aware-types';\n\n/**\n * Represents temporal field subtype.\n *\n * @public\n * @class\n * @extends Dimension\n */\nexport default class Temporal extends Dimension {\n     /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {PartialField} partialField - The partialField instance which holds the whole data.\n     * @param {string} rowDiffset - The data subset definition.\n     */\n    constructor (partialField, rowDiffset) {\n        super(partialField, rowDiffset);\n\n        this._cachedMinDiff = null;\n    }\n\n     /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the unique values.\n     */\n    calculateDataDomain () {\n        const hash = new Set();\n        const domain = [];\n\n        // here don't use this.data() as the iteration will be\n        // occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (!hash.has(datum)) {\n                hash.add(datum);\n                domain.push(datum);\n            }\n        });\n\n        return domain;\n    }\n\n\n    /**\n     * Calculates the minimum consecutive difference from the associated field data.\n     *\n     * @public\n     * @return {number} Returns the minimum consecutive diff in milliseconds.\n     */\n    minimumConsecutiveDifference () {\n        if (this._cachedMinDiff) {\n            return this._cachedMinDiff;\n        }\n\n        const sortedData = this.data().filter(item => !(item instanceof InvalidAwareTypes)).sort((a, b) => a - b);\n        const arrLn = sortedData.length;\n        let minDiff = Number.POSITIVE_INFINITY;\n        let prevDatum;\n        let nextDatum;\n        let processedCount = 0;\n\n        for (let i = 1; i < arrLn; i++) {\n            prevDatum = sortedData[i - 1];\n            nextDatum = sortedData[i];\n\n            if (nextDatum === prevDatum) {\n                continue;\n            }\n\n            minDiff = Math.min(minDiff, nextDatum - sortedData[i - 1]);\n            processedCount++;\n        }\n\n        if (!processedCount) {\n            minDiff = null;\n        }\n        this._cachedMinDiff = minDiff;\n\n        return this._cachedMinDiff;\n    }\n\n    /**\n     * Returns the format specified in the input schema while creating field.\n     *\n     * @public\n     * @return {string} Returns the datetime format.\n     */\n    format () {\n        return this.partialField.schema.format;\n    }\n\n    /**\n     * Returns the formatted version of the underlying field data.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the formatted data.\n     */\n    formattedData () {\n        const data = [];\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (datum instanceof InvalidAwareTypes) {\n                data.push(datum);\n            } else {\n                data.push(DateTimeFormatter.formatAs(datum, this.format()));\n            }\n        });\n        return data;\n    }\n}\n\n","import Dimension from '../dimension';\n\n/**\n * Represents binned field subtype.\n *\n * @public\n * @class\n * @extends Dimension\n */\nexport default class Binned extends Dimension {\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the last and first values of bins config array.\n     */\n    calculateDataDomain () {\n        const binsArr = this.partialField.schema.bins;\n        return [binsArr[0], binsArr[binsArr.length - 1]];\n    }\n\n    /**\n     * Returns the bins config provided while creating the field instance.\n     *\n     * @public\n     * @return {Array} Returns the bins array config.\n     */\n    bins () {\n        return this.partialField.schema.bins;\n    }\n}\n","import { formatNumber } from '../../utils';\nimport { defaultReducerName } from '../../operator/group-by-function';\nimport Field from '../field';\n\n/**\n * Represents measure field type.\n *\n * @public\n * @class\n * @extends Field\n */\nexport default class Measure extends Field {\n  /**\n   * Returns the domain for the measure field.\n   *\n   * @override\n   * @public\n   * @return {any} Returns the calculated domain.\n   */\n    domain () {\n        if (!this._cachedDomain) {\n            this._cachedDomain = this.calculateDataDomain();\n        }\n        return this._cachedDomain;\n    }\n\n  /**\n   * Returns the unit of the measure field.\n   *\n   * @public\n   * @return {string} Returns unit of the field.\n   */\n    unit () {\n        return this.partialField.schema.unit;\n    }\n\n  /**\n   * Returns the aggregation function name of the measure field.\n   *\n   * @public\n   * @return {string} Returns aggregation function name of the field.\n   */\n    defAggFn () {\n        return this.partialField.schema.defAggFn || defaultReducerName;\n    }\n\n  /**\n   * Returns the number format of the measure field.\n   *\n   * @public\n   * @return {Function} Returns number format of the field.\n   */\n    numberFormat () {\n        const { numberFormat } = this.partialField.schema;\n        return numberFormat instanceof Function ? numberFormat : formatNumber;\n    }\n\n  /**\n   * Calculates the corresponding field domain.\n   *\n   * @public\n   * @abstract\n   */\n    calculateDataDomain () {\n        throw new Error('Not yet implemented');\n    }\n\n    /**\n     * Returns the formatted version of the underlying field data.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the formatted data.\n     */\n    formattedData () {\n        return this.data();\n    }\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\nimport { MeasureSubtype } from '../../enums';\nimport Measure from '../measure';\nimport InvalidAwareTypes from '../../invalid-aware-types';\n\n/**\n * Represents continuous field subtype.\n *\n * @public\n * @class\n * @extends Measure\n */\nexport default class Continuous extends Measure {\n    /**\n     * Returns the subtype of the field.\n     *\n     * @public\n     * @override\n     * @return {string} Returns the subtype of the field.\n     */\n    subtype () {\n        return MeasureSubtype.CONTINUOUS;\n    }\n\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the min and max values.\n     */\n    calculateDataDomain () {\n        let min = Number.POSITIVE_INFINITY;\n        let max = Number.NEGATIVE_INFINITY;\n\n        // here don't use this.data() as the iteration will be occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (datum instanceof InvalidAwareTypes) {\n                return;\n            }\n\n            if (datum < min) {\n                min = datum;\n            }\n            if (datum > max) {\n                max = datum;\n            }\n        });\n\n        return [min, max];\n    }\n}\n","/**\n * A interface to represent a parser which is responsible to parse the field.\n *\n * @public\n * @interface\n */\nexport default class FieldParser {\n    /**\n     * Parses a single value of a field and return the sanitized form.\n     *\n     * @public\n     * @abstract\n     */\n    parse () {\n        throw new Error('Not yet implemented');\n    }\n}\n","import FieldParser from '../field-parser';\nimport InvalidAwareTypes from '../../../invalid-aware-types';\n\n/**\n * A FieldParser which parses the categorical values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class CategoricalParser extends FieldParser {\n  /**\n   * Parses a single value of a field and returns the stringified form.\n   *\n   * @public\n   * @param {string|number} val - The value of the field.\n   * @return {string} Returns the stringified value.\n   */\n    parse (val) {\n        let result;\n        // check if invalid date value\n        if (!InvalidAwareTypes.isInvalid(val)) {\n            result = String(val).trim();\n        } else {\n            result = InvalidAwareTypes.getInvalidType(val);\n        }\n        return result;\n    }\n}\n","import { DateTimeFormatter } from '../../../utils';\nimport FieldParser from '../field-parser';\nimport InvalidAwareTypes from '../../../invalid-aware-types';\n\n/**\n * A FieldParser which parses the temporal values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class TemporalParser extends FieldParser {\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {Object} schema - The schema object for the corresponding field.\n     */\n    constructor (schema) {\n        super();\n        this.schema = schema;\n        this._dtf = new DateTimeFormatter(this.schema.format);\n    }\n\n    /**\n     * Parses a single value of a field and returns the millisecond value.\n     *\n     * @public\n     * @param {string|number} val - The value of the field.\n     * @return {number} Returns the millisecond value.\n     */\n    parse (val) {\n        let result;\n        // check if invalid date value\n        if (!InvalidAwareTypes.isInvalid(val)) {\n            let nativeDate = this._dtf.getNativeDate(val);\n            result = nativeDate ? nativeDate.getTime() : InvalidAwareTypes.NA;\n        } else {\n            result = InvalidAwareTypes.getInvalidType(val);\n        }\n        return result;\n    }\n}\n","import FieldParser from '../field-parser';\nimport InvalidAwareTypes from '../../../invalid-aware-types';\n\n/**\n * A FieldParser which parses the binned values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class BinnedParser extends FieldParser {\n  /**\n   * Parses a single binned value of a field and returns the sanitized value.\n   *\n   * @public\n   * @param {string} val - The value of the field.\n   * @return {string} Returns the sanitized value.\n   */\n    parse (val) {\n        const regex = /^\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*-\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*$/;\n        val = String(val);\n        let result;\n        // check if invalid date value\n        if (!InvalidAwareTypes.isInvalid(val)) {\n            let matched = val.match(regex);\n            result = matched ? `${Number.parseFloat(matched[1])}-${Number.parseFloat(matched[2])}`\n                             : InvalidAwareTypes.NA;\n        } else {\n            result = InvalidAwareTypes.getInvalidType(val);\n        }\n        return result;\n    }\n}\n","import FieldParser from '../field-parser';\nimport InvalidAwareTypes from '../../../invalid-aware-types';\n\n/**\n * A FieldParser which parses the continuous values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class ContinuousParser extends FieldParser {\n  /**\n   * Parses a single value of a field and returns the number form.\n   *\n   * @public\n   * @param {string|number} val - The value of the field.\n   * @return {string} Returns the number value.\n   */\n    parse (val) {\n        let result;\n        // check if invalid date value\n        if (!InvalidAwareTypes.isInvalid(val)) {\n            let parsedVal = parseFloat(val, 10);\n            result = Number.isNaN(parsedVal) ? InvalidAwareTypes.NA : parsedVal;\n        } else {\n            result = InvalidAwareTypes.getInvalidType(val);\n        }\n        return result;\n    }\n}\n","/**\n * Stores the full data and the metadata of a field. It provides\n * a single source of data from which the future Field\n * instance can get a subset of it with a rowDiffset config.\n *\n * @class\n * @public\n */\nexport default class PartialField {\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {string} name - The name of the field.\n     * @param {Array} data - The data array.\n     * @param {Object} schema - The schema object of the corresponding field.\n     * @param {FieldParser} parser - The parser instance corresponding to that field.\n     */\n    constructor (name, data, schema, parser) {\n        this.name = name;\n        this.schema = schema;\n        this.parser = parser;\n        this.data = this._sanitize(data);\n    }\n\n    /**\n     * Sanitizes the field data.\n     *\n     * @private\n     * @param {Array} data - The actual input data.\n     * @return {Array} Returns the sanitized data.\n     */\n    _sanitize (data) {\n        return data.map(datum => this.parser.parse(datum));\n    }\n}\n","import { FieldType, DimensionSubtype, MeasureSubtype } from './enums';\nimport {\n    Categorical,\n    Temporal,\n    Binned,\n    Continuous,\n    CategoricalParser,\n    TemporalParser,\n    BinnedParser,\n    ContinuousParser,\n    PartialField\n} from './fields';\n\n/**\n * Creates a field instance according to the provided data and schema.\n *\n * @param {Array} data - The field data array.\n * @param {Object} schema - The field schema object.\n * @return {Field} Returns the newly created field instance.\n */\nfunction createUnitField(data, schema) {\n    data = data || [];\n    let partialField;\n\n    switch (schema.type) {\n    case FieldType.MEASURE:\n        switch (schema.subtype) {\n        case MeasureSubtype.CONTINUOUS:\n            partialField = new PartialField(schema.name, data, schema, new ContinuousParser());\n            return new Continuous(partialField, `0-${data.length - 1}`);\n        default:\n            partialField = new PartialField(schema.name, data, schema, new ContinuousParser());\n            return new Continuous(partialField, `0-${data.length - 1}`);\n        }\n    case FieldType.DIMENSION:\n        switch (schema.subtype) {\n        case DimensionSubtype.CATEGORICAL:\n            partialField = new PartialField(schema.name, data, schema, new CategoricalParser());\n            return new Categorical(partialField, `0-${data.length - 1}`);\n        case DimensionSubtype.TEMPORAL:\n            partialField = new PartialField(schema.name, data, schema, new TemporalParser(schema));\n            return new Temporal(partialField, `0-${data.length - 1}`);\n        case DimensionSubtype.BINNED:\n            partialField = new PartialField(schema.name, data, schema, new BinnedParser());\n            return new Binned(partialField, `0-${data.length - 1}`);\n        default:\n            partialField = new PartialField(schema.name, data, schema, new CategoricalParser());\n            return new Categorical(partialField, `0-${data.length - 1}`);\n        }\n    default:\n        partialField = new PartialField(schema.name, data, schema, new CategoricalParser());\n        return new Categorical(partialField, `0-${data.length - 1}`);\n    }\n}\n\n\n/**\n * Creates a field instance from partialField and rowDiffset.\n *\n * @param {PartialField} partialField - The corresponding partial field.\n * @param {string} rowDiffset - The data subset config.\n * @return {Field} Returns the newly created field instance.\n */\nexport function createUnitFieldFromPartial(partialField, rowDiffset) {\n    const { schema } = partialField;\n\n    switch (schema.type) {\n    case FieldType.MEASURE:\n        switch (schema.subtype) {\n        case MeasureSubtype.CONTINUOUS:\n            return new Continuous(partialField, rowDiffset);\n        default:\n            return new Continuous(partialField, rowDiffset);\n        }\n    case FieldType.DIMENSION:\n        switch (schema.subtype) {\n        case DimensionSubtype.CATEGORICAL:\n            return new Categorical(partialField, rowDiffset);\n        case DimensionSubtype.TEMPORAL:\n            return new Temporal(partialField, rowDiffset);\n        case DimensionSubtype.BINNED:\n            return new Binned(partialField, rowDiffset);\n        default:\n            return new Categorical(partialField, rowDiffset);\n        }\n    default:\n        return new Categorical(partialField, rowDiffset);\n    }\n}\n\n/**\n * Creates the field instances with input data and schema.\n *\n * @param {Array} dataColumn - The data array for fields.\n * @param {Array} schema - The schema array for fields.\n * @param {Array} headers - The array of header names.\n * @return {Array.<Field>} Returns an array of newly created field instances.\n */\nexport function createFields(dataColumn, schema, headers) {\n    const headersObj = {};\n\n    if (!(headers && headers.length)) {\n        headers = schema.map(item => item.name);\n    }\n\n    headers.forEach((header, i) => {\n        headersObj[header] = i;\n    });\n\n    return schema.map(item => createUnitField(dataColumn[headersObj[item.name]], item));\n}\n","import { DataFormat } from './enums';\n\nexport default {\n    dataFormat: DataFormat.AUTO\n};\n","import { columnMajor } from '../utils';\n\n/**\n * Parses and converts data formatted in DSV array to a manageable internal format.\n *\n * @param {Array.<Array>} arr - A 2D array containing of the DSV data.\n * @param {Object} options - Option to control the behaviour of the parsing.\n * @param {boolean} [options.firstRowHeader=true] - Whether the first row of the dsv data is header or not.\n * @return {Array} Returns an array of headers and column major data.\n * @example\n *\n * // Sample input data:\n * const data = [\n *    [\"a\", \"b\", \"c\"],\n *    [1, 2, 3],\n *    [4, 5, 6],\n *    [7, 8, 9]\n * ];\n */\nfunction DSVArr (arr, options) {\n    const defaultOption = {\n        firstRowHeader: true,\n    };\n    options = Object.assign({}, defaultOption, options);\n\n    let header;\n    const columns = [];\n    const push = columnMajor(columns);\n\n    if (options.firstRowHeader) {\n        // If header present then mutate the array.\n        // Do in-place mutation to save space.\n        header = arr.splice(0, 1)[0];\n    } else {\n        header = [];\n    }\n\n    arr.forEach(field => push(...field));\n\n    return [header, columns];\n}\n\nexport default DSVArr;\n","var EOL = {},\n    EOF = {},\n    QUOTE = 34,\n    NEWLINE = 10,\n    RETURN = 13;\n\nfunction objectConverter(columns) {\n  return new Function(\"d\", \"return {\" + columns.map(function(name, i) {\n    return JSON.stringify(name) + \": d[\" + i + \"]\";\n  }).join(\",\") + \"}\");\n}\n\nfunction customConverter(columns, f) {\n  var object = objectConverter(columns);\n  return function(row, i) {\n    return f(object(row), i, columns);\n  };\n}\n\n// Compute unique columns in order of discovery.\nfunction inferColumns(rows) {\n  var columnSet = Object.create(null),\n      columns = [];\n\n  rows.forEach(function(row) {\n    for (var column in row) {\n      if (!(column in columnSet)) {\n        columns.push(columnSet[column] = column);\n      }\n    }\n  });\n\n  return columns;\n}\n\nexport default function(delimiter) {\n  var reFormat = new RegExp(\"[\\\"\" + delimiter + \"\\n\\r]\"),\n      DELIMITER = delimiter.charCodeAt(0);\n\n  function parse(text, f) {\n    var convert, columns, rows = parseRows(text, function(row, i) {\n      if (convert) return convert(row, i - 1);\n      columns = row, convert = f ? customConverter(row, f) : objectConverter(row);\n    });\n    rows.columns = columns || [];\n    return rows;\n  }\n\n  function parseRows(text, f) {\n    var rows = [], // output rows\n        N = text.length,\n        I = 0, // current character index\n        n = 0, // current line number\n        t, // current token\n        eof = N <= 0, // current token followed by EOF?\n        eol = false; // current token followed by EOL?\n\n    // Strip the trailing newline.\n    if (text.charCodeAt(N - 1) === NEWLINE) --N;\n    if (text.charCodeAt(N - 1) === RETURN) --N;\n\n    function token() {\n      if (eof) return EOF;\n      if (eol) return eol = false, EOL;\n\n      // Unescape quotes.\n      var i, j = I, c;\n      if (text.charCodeAt(j) === QUOTE) {\n        while (I++ < N && text.charCodeAt(I) !== QUOTE || text.charCodeAt(++I) === QUOTE);\n        if ((i = I) >= N) eof = true;\n        else if ((c = text.charCodeAt(I++)) === NEWLINE) eol = true;\n        else if (c === RETURN) { eol = true; if (text.charCodeAt(I) === NEWLINE) ++I; }\n        return text.slice(j + 1, i - 1).replace(/\"\"/g, \"\\\"\");\n      }\n\n      // Find next delimiter or newline.\n      while (I < N) {\n        if ((c = text.charCodeAt(i = I++)) === NEWLINE) eol = true;\n        else if (c === RETURN) { eol = true; if (text.charCodeAt(I) === NEWLINE) ++I; }\n        else if (c !== DELIMITER) continue;\n        return text.slice(j, i);\n      }\n\n      // Return last token before EOF.\n      return eof = true, text.slice(j, N);\n    }\n\n    while ((t = token()) !== EOF) {\n      var row = [];\n      while (t !== EOL && t !== EOF) row.push(t), t = token();\n      if (f && (row = f(row, n++)) == null) continue;\n      rows.push(row);\n    }\n\n    return rows;\n  }\n\n  function format(rows, columns) {\n    if (columns == null) columns = inferColumns(rows);\n    return [columns.map(formatValue).join(delimiter)].concat(rows.map(function(row) {\n      return columns.map(function(column) {\n        return formatValue(row[column]);\n      }).join(delimiter);\n    })).join(\"\\n\");\n  }\n\n  function formatRows(rows) {\n    return rows.map(formatRow).join(\"\\n\");\n  }\n\n  function formatRow(row) {\n    return row.map(formatValue).join(delimiter);\n  }\n\n  function formatValue(text) {\n    return text == null ? \"\"\n        : reFormat.test(text += \"\") ? \"\\\"\" + text.replace(/\"/g, \"\\\"\\\"\") + \"\\\"\"\n        : text;\n  }\n\n  return {\n    parse: parse,\n    parseRows: parseRows,\n    format: format,\n    formatRows: formatRows\n  };\n}\n","import dsv from \"./dsv\";\n\nvar csv = dsv(\",\");\n\nexport var csvParse = csv.parse;\nexport var csvParseRows = csv.parseRows;\nexport var csvFormat = csv.format;\nexport var csvFormatRows = csv.formatRows;\n","import dsv from \"./dsv\";\n\nvar tsv = dsv(\"\\t\");\n\nexport var tsvParse = tsv.parse;\nexport var tsvParseRows = tsv.parseRows;\nexport var tsvFormat = tsv.format;\nexport var tsvFormatRows = tsv.formatRows;\n","import { dsvFormat as d3Dsv } from 'd3-dsv';\nimport DSVArr from './dsv-arr';\n\n/**\n * Parses and converts data formatted in DSV string to a manageable internal format.\n *\n * @todo Support to be given for https://tools.ietf.org/html/rfc4180.\n * @todo Sample implementation https://github.com/knrz/CSV.js/.\n *\n * @param {string} str - The input DSV string.\n * @param {Object} options - Option to control the behaviour of the parsing.\n * @param {boolean} [options.firstRowHeader=true] - Whether the first row of the dsv string data is header or not.\n * @param {string} [options.fieldSeparator=\",\"] - The separator of two consecutive field.\n * @return {Array} Returns an array of headers and column major data.\n * @example\n *\n * // Sample input data:\n * const data = `\n * a,b,c\n * 1,2,3\n * 4,5,6\n * 7,8,9\n * `\n */\nfunction DSVStr (str, options) {\n    const defaultOption = {\n        firstRowHeader: true,\n        fieldSeparator: ','\n    };\n    options = Object.assign({}, defaultOption, options);\n\n    const dsv = d3Dsv(options.fieldSeparator);\n    return DSVArr(dsv.parseRows(str), options);\n}\n\nexport default DSVStr;\n","import { columnMajor } from '../utils';\n\n/**\n * Parses and converts data formatted in JSON to a manageable internal format.\n *\n * @param {Array.<Object>} arr - The input data formatted in JSON.\n * @return {Array.<Object>} Returns an array of headers and column major data.\n * @example\n *\n * // Sample input data:\n * const data = [\n *    {\n *      \"a\": 1,\n *      \"b\": 2,\n *      \"c\": 3\n *    },\n *    {\n *      \"a\": 4,\n *      \"b\": 5,\n *      \"c\": 6\n *    },\n *    {\n *      \"a\": 7,\n *      \"b\": 8,\n *      \"c\": 9\n *    }\n * ];\n */\nfunction FlatJSON (arr) {\n    const header = {};\n    let i = 0;\n    let insertionIndex;\n    const columns = [];\n    const push = columnMajor(columns);\n\n    arr.forEach((item) => {\n        const fields = [];\n        for (let key in item) {\n            if (key in header) {\n                insertionIndex = header[key];\n            } else {\n                header[key] = i++;\n                insertionIndex = i - 1;\n            }\n            fields[insertionIndex] = item[key];\n        }\n        push(...fields);\n    });\n\n    return [Object.keys(header), columns];\n}\n\nexport default FlatJSON;\n","import FlatJSON from './flat-json';\nimport DSVArr from './dsv-arr';\nimport DSVStr from './dsv-str';\nimport { detectDataFormat } from '../utils';\n\n/**\n * Parses the input data and detect the format automatically.\n *\n * @param {string|Array} data - The input data.\n * @param {Object} options - An optional config specific to data format.\n * @return {Array.<Object>} Returns an array of headers and column major data.\n */\nfunction Auto (data, options) {\n    const converters = { FlatJSON, DSVStr, DSVArr };\n    const dataFormat = detectDataFormat(data);\n\n    if (!dataFormat) {\n        throw new Error('Couldn\\'t detect the data format');\n    }\n\n    return converters[dataFormat](data, options);\n}\n\nexport default Auto;\n","import { FieldType, FilteringMode, DimensionSubtype, MeasureSubtype, DataFormat } from './enums';\nimport fieldStore from './field-store';\nimport Value from './value';\nimport {\n    rowDiffsetIterator\n} from './operator';\nimport { DM_DERIVATIVES, LOGICAL_OPERATORS } from './constants';\nimport { createFields, createUnitFieldFromPartial } from './field-creator';\nimport defaultConfig from './default-config';\nimport * as converter from './converter';\nimport { extend2, detectDataFormat } from './utils';\n\n/**\n * Prepares the selection data.\n */\nfunction prepareSelectionData (fields, formattedData, rawData, i) {\n    const resp = {};\n\n    for (const [key, field] of fields.entries()) {\n        resp[field.name()] = new Value(formattedData[key][i], rawData[key][i], field);\n    }\n    return resp;\n}\n\nexport function prepareJoinData (fields) {\n    const resp = {};\n    Object.keys(fields).forEach((key) => { resp[key] = new Value(fields[key], key); });\n    return resp;\n}\n\nexport const updateFields = ([rowDiffset, colIdentifier], partialFieldspace, fieldStoreName) => {\n    let collID = colIdentifier.length ? colIdentifier.split(',') : [];\n    let partialFieldMap = partialFieldspace.fieldsObj();\n    let newFields = collID.map(coll => createUnitFieldFromPartial(partialFieldMap[coll].partialField, rowDiffset));\n    return fieldStore.createNamespace(newFields, fieldStoreName);\n};\n\nexport const persistCurrentDerivation = (model, operation, config = {}, criteriaFn) => {\n    if (operation === DM_DERIVATIVES.COMPOSE) {\n        model._derivation.length = 0;\n        model._derivation.push(...criteriaFn);\n    } else {\n        model._derivation.push({\n            op: operation,\n            meta: config,\n            criteria: criteriaFn\n        });\n    }\n};\n\nexport const persistAncestorDerivation = (sourceDm, newDm) => {\n    newDm._ancestorDerivation.push(...sourceDm._ancestorDerivation, ...sourceDm._derivation);\n};\n\nexport const persistDerivations = (sourceDm, model, operation, config = {}, criteriaFn) => {\n    persistCurrentDerivation(model, operation, config, criteriaFn);\n    persistAncestorDerivation(sourceDm, model);\n};\n\nexport const selectHelper = (rowDiffset, fields, selectFn, config, sourceDm) => {\n    const newRowDiffSet = [];\n    let lastInsertedValue = -1;\n    let { mode } = config;\n    let li;\n    let cachedStore = {};\n    let cloneProvider = () => sourceDm.detachedRoot();\n\n    const rawFieldsData = fields.map(field => field.data());\n    const formattedFieldsData = fields.map(field => field.formattedData());\n    const selectorHelperFn = index => selectFn(\n        prepareSelectionData(fields, formattedFieldsData, rawFieldsData, index),\n        index,\n        cloneProvider,\n        cachedStore\n    );\n\n    let checker;\n    if (mode === FilteringMode.INVERSE) {\n        checker = index => !selectorHelperFn(index);\n    } else {\n        checker = index => selectorHelperFn(index);\n    }\n\n    rowDiffsetIterator(rowDiffset, (i) => {\n        if (checker(i)) {\n            if (lastInsertedValue !== -1 && i === (lastInsertedValue + 1)) {\n                li = newRowDiffSet.length - 1;\n                newRowDiffSet[li] = `${newRowDiffSet[li].split('-')[0]}-${i}`;\n            } else {\n                newRowDiffSet.push(`${i}`);\n            }\n            lastInsertedValue = i;\n        }\n    });\n    return newRowDiffSet.join(',');\n};\n\nexport const cloneWithAllFields = (model) => {\n    const clonedDm = model.clone(false);\n    const partialFieldspace = model.getPartialFieldspace();\n    clonedDm._colIdentifier = partialFieldspace.fields.map(f => f.name()).join(',');\n\n    // flush out cached namespace values on addition of new fields\n    partialFieldspace._cachedFieldsObj = null;\n    partialFieldspace._cachedDimension = null;\n    partialFieldspace._cachedMeasure = null;\n    clonedDm.__calculateFieldspace().calculateFieldsConfig();\n\n    return clonedDm;\n};\n\nexport const filterPropagationModel = (model, propModels, config = {}) => {\n    const operation = config.operation || LOGICAL_OPERATORS.AND;\n    const filterByMeasure = config.filterByMeasure || false;\n    let fns = [];\n    if (!propModels.length) {\n        fns = [() => false];\n    } else {\n        fns = propModels.map(propModel => ((dataModel) => {\n            const dataObj = dataModel.getData();\n            const schema = dataObj.schema;\n            const fieldsConfig = dataModel.getFieldsConfig();\n            const fieldsSpace = dataModel.getFieldspace().fieldsObj();\n            const data = dataObj.data;\n            const domain = Object.values(fieldsConfig).reduce((acc, v) => {\n                acc[v.def.name] = fieldsSpace[v.def.name].domain();\n                return acc;\n            }, {});\n\n            return (fields) => {\n                const include = !data.length ? false : data.some(row => schema.every((propField) => {\n                    if (!(propField.name in fields)) {\n                        return true;\n                    }\n                    const value = fields[propField.name].valueOf();\n                    if (filterByMeasure && propField.type === FieldType.MEASURE) {\n                        return value >= domain[propField.name][0] && value <= domain[propField.name][1];\n                    }\n\n                    if (propField.type !== FieldType.DIMENSION) {\n                        return true;\n                    }\n                    const idx = fieldsConfig[propField.name].index;\n                    return row[idx] === fields[propField.name].valueOf();\n                }));\n                return include;\n            };\n        })(propModel));\n    }\n\n    let filteredModel;\n    if (operation === LOGICAL_OPERATORS.AND) {\n        filteredModel = cloneWithAllFields(model).select(fields => fns.every(fn => fn(fields)), {\n            saveChild: false,\n            mode: FilteringMode.ALL\n        });\n    } else {\n        filteredModel = cloneWithAllFields(model).select(fields => fns.some(fn => fn(fields)), {\n            mode: FilteringMode.ALL,\n            saveChild: false\n        });\n    }\n\n    return filteredModel;\n};\n\nexport const cloneWithSelect = (sourceDm, selectFn, selectConfig, cloneConfig) => {\n    const cloned = sourceDm.clone(cloneConfig.saveChild);\n    const rowDiffset = selectHelper(\n        cloned._rowDiffset,\n        cloned.getPartialFieldspace().fields,\n        selectFn,\n        selectConfig,\n        sourceDm\n    );\n    cloned._rowDiffset = rowDiffset;\n    cloned.__calculateFieldspace().calculateFieldsConfig();\n\n    persistDerivations(\n        sourceDm,\n        cloned,\n        DM_DERIVATIVES.SELECT,\n         { config: selectConfig },\n          selectFn\n    );\n\n    return cloned;\n};\n\nexport const cloneWithProject = (sourceDm, projField, config, allFields) => {\n    const cloned = sourceDm.clone(config.saveChild);\n    let projectionSet = projField;\n    if (config.mode === FilteringMode.INVERSE) {\n        projectionSet = allFields.filter(fieldName => projField.indexOf(fieldName) === -1);\n    }\n    // cloned._colIdentifier = sourceDm._colIdentifier.split(',')\n    //                         .filter(coll => projectionSet.indexOf(coll) !== -1).join();\n    cloned._colIdentifier = projectionSet.join(',');\n    cloned.__calculateFieldspace().calculateFieldsConfig();\n\n    persistDerivations(\n        sourceDm,\n        cloned,\n        DM_DERIVATIVES.PROJECT,\n        { projField, config, actualProjField: projectionSet },\n        null\n    );\n\n    return cloned;\n};\n\nexport const sanitizeUnitSchema = (unitSchema) => {\n    // Do deep clone of the unit schema as the user might change it later.\n    unitSchema = extend2({}, unitSchema);\n    if (!unitSchema.type) {\n        unitSchema.type = FieldType.DIMENSION;\n    }\n\n    if (!unitSchema.subtype) {\n        switch (unitSchema.type) {\n        case FieldType.MEASURE:\n            unitSchema.subtype = MeasureSubtype.CONTINUOUS;\n            break;\n        default:\n        case FieldType.DIMENSION:\n            unitSchema.subtype = DimensionSubtype.CATEGORICAL;\n            break;\n        }\n    }\n\n    return unitSchema;\n};\n\nexport const validateUnitSchema = (unitSchema) => {\n    const supportedMeasureSubTypes = [MeasureSubtype.CONTINUOUS];\n    const supportedDimSubTypes = [\n        DimensionSubtype.CATEGORICAL,\n        DimensionSubtype.BINNED,\n        DimensionSubtype.TEMPORAL,\n        DimensionSubtype.GEO\n    ];\n    const { type, subtype, name } = unitSchema;\n\n    switch (type) {\n    case FieldType.DIMENSION:\n        if (supportedDimSubTypes.indexOf(subtype) === -1) {\n            throw new Error(`DataModel doesn't support dimension field subtype ${subtype} used for ${name} field`);\n        }\n        break;\n    case FieldType.MEASURE:\n        if (supportedMeasureSubTypes.indexOf(subtype) === -1) {\n            throw new Error(`DataModel doesn't support measure field subtype ${subtype} used for ${name} field`);\n        }\n        break;\n    default:\n        throw new Error(`DataModel doesn't support field type ${type} used for ${name} field`);\n    }\n};\n\nexport const sanitizeAndValidateSchema = schema => schema.map((unitSchema) => {\n    unitSchema = sanitizeUnitSchema(unitSchema);\n    validateUnitSchema(unitSchema);\n    return unitSchema;\n});\n\nexport const resolveFieldName = (schema, dataHeader) => {\n    schema.forEach((unitSchema) => {\n        const fieldNameAs = unitSchema.as;\n        if (!fieldNameAs) { return; }\n\n        const idx = dataHeader.indexOf(unitSchema.name);\n        dataHeader[idx] = fieldNameAs;\n        unitSchema.name = fieldNameAs;\n        delete unitSchema.as;\n    });\n};\n\nexport const updateData = (relation, data, schema, options) => {\n    schema = sanitizeAndValidateSchema(schema);\n    options = Object.assign(Object.assign({}, defaultConfig), options);\n    const converterFn = converter[options.dataFormat];\n\n    if (!(converterFn && typeof converterFn === 'function')) {\n        throw new Error(`No converter function found for ${options.dataFormat} format`);\n    }\n\n    const [header, formattedData] = converterFn(data, options);\n    resolveFieldName(schema, header);\n    const fieldArr = createFields(formattedData, schema, header);\n\n    // This will create a new fieldStore with the fields\n    const nameSpace = fieldStore.createNamespace(fieldArr, options.name);\n    relation._partialFieldspace = nameSpace;\n    // If data is provided create the default colIdentifier and rowDiffset\n    relation._rowDiffset = formattedData.length && formattedData[0].length ? `0-${formattedData[0].length - 1}` : '';\n    relation._colIdentifier = (schema.map(_ => _.name)).join();\n    relation._dataFormat = options.dataFormat === DataFormat.AUTO ? detectDataFormat(data) : options.dataFormat;\n    return relation;\n};\n\nexport const fieldInSchema = (schema, field) => {\n    let i = 0;\n\n    for (; i < schema.length; ++i) {\n        if (field === schema[i].name) {\n            return {\n                type: schema[i].subtype || schema[i].type,\n                index: i\n            };\n        }\n    }\n    return null;\n};\n\n\nexport const getDerivationArguments = (derivation) => {\n    let params = [];\n    let operation;\n    operation = derivation.op;\n    switch (operation) {\n    case DM_DERIVATIVES.SELECT:\n        params = [derivation.criteria];\n        break;\n    case DM_DERIVATIVES.PROJECT:\n        params = [derivation.meta.actualProjField];\n        break;\n    case DM_DERIVATIVES.GROUPBY:\n        operation = 'groupBy';\n        params = [derivation.meta.groupByString.split(','), derivation.criteria];\n        break;\n    default:\n        operation = null;\n    }\n\n    return {\n        operation,\n        params\n    };\n};\n\nconst applyExistingOperationOnModel = (propModel, dataModel) => {\n    const derivations = dataModel.getDerivations();\n    let selectionModel = propModel[0];\n    let rejectionModel = propModel[1];\n\n    derivations.forEach((derivation) => {\n        if (!derivation) {\n            return;\n        }\n\n        const { operation, params } = getDerivationArguments(derivation);\n        if (operation) {\n            selectionModel = selectionModel[operation](...params, {\n                saveChild: false\n            });\n            rejectionModel = rejectionModel[operation](...params, {\n                saveChild: false\n            });\n        }\n    });\n\n    return [selectionModel, rejectionModel];\n};\n\nconst getFilteredModel = (propModel, path) => {\n    for (let i = 0, len = path.length; i < len; i++) {\n        const model = path[i];\n        propModel = applyExistingOperationOnModel(propModel, model);\n    }\n    return propModel;\n};\n\nconst propagateIdentifiers = (dataModel, propModel, config = {}, propModelInf = {}) => {\n    const nonTraversingModel = propModelInf.nonTraversingModel;\n    const excludeModels = propModelInf.excludeModels || [];\n\n    if (dataModel === nonTraversingModel) {\n        return;\n    }\n\n    const propagate = excludeModels.length ? excludeModels.indexOf(dataModel) === -1 : true;\n\n    propagate && dataModel.handlePropagation(propModel, config);\n\n    const children = dataModel._children;\n    children.forEach((child) => {\n        let [selectionModel, rejectionModel] = applyExistingOperationOnModel(propModel, child);\n        propagateIdentifiers(child, [selectionModel, rejectionModel], config, propModelInf);\n    });\n};\n\nexport const getRootGroupByModel = (model) => {\n    while (model._parent && model._derivation.find(d => d.op !== DM_DERIVATIVES.GROUPBY)) {\n        model = model._parent;\n    }\n    return model;\n};\n\nexport const getRootDataModel = (model) => {\n    while (model._parent) {\n        model = model._parent;\n    }\n    return model;\n};\n\nexport const getPathToRootModel = (model, path = []) => {\n    while (model._parent) {\n        path.push(model);\n        model = model._parent;\n    }\n    return path;\n};\n\nexport const propagateToAllDataModels = (identifiers, rootModels, propagationInf, config) => {\n    let criteria;\n    let propModel;\n    const { propagationNameSpace, propagateToSource } = propagationInf;\n    const propagationSourceId = propagationInf.sourceId;\n    const propagateInterpolatedValues = config.propagateInterpolatedValues;\n    const filterFn = (entry) => {\n        const filter = config.filterFn || (() => true);\n        return filter(entry, config);\n    };\n\n    let criterias = [];\n\n    if (identifiers === null && config.persistent !== true) {\n        criterias = [{\n            criteria: []\n        }];\n    } else {\n        let actionCriterias = Object.values(propagationNameSpace.mutableActions);\n        if (propagateToSource !== false) {\n            actionCriterias = actionCriterias.filter(d => d.config.sourceId !== propagationSourceId);\n        }\n\n        const filteredCriteria = actionCriterias.filter(filterFn).map(action => action.config.criteria);\n\n        const excludeModels = [];\n\n        if (propagateToSource !== false) {\n            const sourceActionCriterias = Object.values(propagationNameSpace.mutableActions);\n\n            sourceActionCriterias.forEach((actionInf) => {\n                const actionConf = actionInf.config;\n                if (actionConf.applyOnSource === false && actionConf.action === config.action &&\n                        actionConf.sourceId !== propagationSourceId) {\n                    excludeModels.push(actionInf.model);\n                    criteria = sourceActionCriterias.filter(d => d !== actionInf).map(d => d.config.criteria);\n                    criteria.length && criterias.push({\n                        criteria,\n                        models: actionInf.model,\n                        path: getPathToRootModel(actionInf.model)\n                    });\n                }\n            });\n        }\n\n\n        criteria = [].concat(...[...filteredCriteria, identifiers]).filter(d => d !== null);\n        criterias.push({\n            criteria,\n            excludeModels: [...excludeModels, ...config.excludeModels || []]\n        });\n    }\n\n    const rootModel = rootModels.model;\n\n    const propConfig = Object.assign({\n        sourceIdentifiers: identifiers,\n        propagationSourceId\n    }, config);\n\n    const rootGroupByModel = rootModels.groupByModel;\n    if (propagateInterpolatedValues && rootGroupByModel) {\n        propModel = filterPropagationModel(rootGroupByModel, criteria, {\n            filterByMeasure: propagateInterpolatedValues\n        });\n        propagateIdentifiers(rootGroupByModel, propModel, propConfig);\n    }\n\n    criterias.forEach((inf) => {\n        const propagationModel = filterPropagationModel(rootModel, inf.criteria);\n        const path = inf.path;\n\n        if (path) {\n            const filteredModel = getFilteredModel(propagationModel, path.reverse());\n            inf.models.handlePropagation(filteredModel, propConfig);\n        } else {\n            propagateIdentifiers(rootModel, propagationModel, propConfig, {\n                excludeModels: inf.excludeModels,\n                nonTraversingModel: propagateInterpolatedValues && rootGroupByModel\n            });\n        }\n    });\n};\n\nexport const propagateImmutableActions = (propagationNameSpace, rootModels, propagationInf) => {\n    const immutableActions = propagationNameSpace.immutableActions;\n\n    for (const action in immutableActions) {\n        const actionInf = immutableActions[action];\n        const actionConf = actionInf.config;\n        const propagationSourceId = propagationInf.config.sourceId;\n        const filterImmutableAction = propagationInf.propConfig.filterImmutableAction ?\n            propagationInf.propConfig.filterImmutableAction(actionConf, propagationInf.config) : true;\n        if (actionConf.sourceId !== propagationSourceId && filterImmutableAction) {\n            const criteriaModel = actionConf.criteria;\n            propagateToAllDataModels(criteriaModel, rootModels, {\n                propagationNameSpace,\n                propagateToSource: false,\n                sourceId: propagationSourceId\n            }, actionConf);\n        }\n    }\n};\n\nexport const addToPropNamespace = (propagationNameSpace, config = {}, model) => {\n    let sourceNamespace;\n    const isMutableAction = config.isMutableAction;\n    const criteria = config.criteria;\n    const key = `${config.action}-${config.sourceId}`;\n\n    if (isMutableAction) {\n        sourceNamespace = propagationNameSpace.mutableActions;\n    } else {\n        sourceNamespace = propagationNameSpace.immutableActions;\n    }\n\n    if (criteria === null) {\n        delete sourceNamespace[key];\n    } else {\n        sourceNamespace[key] = {\n            model,\n            config\n        };\n    }\n\n    return this;\n};\n","import { FilteringMode } from './enums';\nimport { getUniqueId } from './utils';\nimport { updateFields, cloneWithSelect, cloneWithProject, updateData } from './helper';\nimport { crossProduct, difference, naturalJoinFilter, union } from './operator';\n\n/**\n * Relation provides the definitions of basic operators of relational algebra like *selection*, *projection*, *union*,\n * *difference* etc.\n *\n * It is extended by {@link DataModel} to inherit the functionalities of relational algebra concept.\n *\n * @class\n * @public\n * @module Relation\n * @namespace DataModel\n */\nclass Relation {\n\n    /**\n     * Creates a new Relation instance by providing underlying data and schema.\n     *\n     * @private\n     *\n     * @param {Object | string | Relation} data - The input tabular data in dsv or json format or\n     * an existing Relation instance object.\n     * @param {Array} schema - An array of data schema.\n     * @param {Object} [options] - The optional options.\n     */\n    constructor (...params) {\n        let source;\n\n        this._parent = null;\n        this._derivation = [];\n        this._ancestorDerivation = [];\n        this._children = [];\n\n        if (params.length === 1 && ((source = params[0]) instanceof Relation)) {\n            // parent datamodel was passed as part of source\n            this._colIdentifier = source._colIdentifier;\n            this._rowDiffset = source._rowDiffset;\n            this._dataFormat = source._dataFormat;\n            this._parent = source;\n            this._partialFieldspace = this._parent._partialFieldspace;\n            this._fieldStoreName = getUniqueId();\n            this.__calculateFieldspace().calculateFieldsConfig();\n        } else {\n            updateData(this, ...params);\n            this._fieldStoreName = this._partialFieldspace.name;\n            this.__calculateFieldspace().calculateFieldsConfig();\n            this._propagationNameSpace = {\n                mutableActions: {},\n                immutableActions: {}\n            };\n        }\n    }\n\n    /**\n     * Retrieves the {@link Schema | schema} details for every {@link Field | field} as an array.\n     *\n     * @public\n     *\n     * @return {Array.<Schema>} Array of fields schema.\n     *      ```\n     *      [\n     *          { name: 'Name', type: 'dimension' },\n     *          { name: 'Miles_per_Gallon', type: 'measure', numberFormat: (val) => `${val} miles / gallon` },\n     *          { name: 'Cylinder', type: 'dimension' },\n     *          { name: 'Displacement', type: 'measure', defAggFn: 'max' },\n     *          { name: 'HorsePower', type: 'measure', defAggFn: 'max' },\n     *          { name: 'Weight_in_lbs', type: 'measure', defAggFn: 'avg',  },\n     *          { name: 'Acceleration', type: 'measure', defAggFn: 'avg' },\n     *          { name: 'Year', type: 'dimension', subtype: 'datetime', format: '%Y' },\n     *          { name: 'Origin' }\n     *      ]\n     *      ```\n     */\n    getSchema () {\n        return this.getFieldspace().fields.map(d => d.schema());\n    }\n\n    /**\n     * Returns the name of the {@link DataModel} instance. If no name was specified during {@link DataModel}\n     * initialization, then it returns a auto-generated name.\n     *\n     * @public\n     *\n     * @return {string} Name of the DataModel instance.\n     */\n    getName() {\n        return this._fieldStoreName;\n    }\n\n    getFieldspace () {\n        return this._fieldspace;\n    }\n\n    __calculateFieldspace () {\n        this._fieldspace = updateFields([this._rowDiffset, this._colIdentifier],\n             this.getPartialFieldspace(), this._fieldStoreName);\n        return this;\n    }\n\n    getPartialFieldspace () {\n        return this._partialFieldspace;\n    }\n\n    /**\n     * Performs {@link link_of_cross_product | cross-product} between two {@link DataModel} instances and returns a\n     * new {@link DataModel} instance containing the results. This operation is also called theta join.\n     *\n     * Cross product takes two set and create one set where each value of one set is paired with each value of another\n     * set.\n     *\n     * This method takes an optional predicate which filters the generated result rows. If the predicate returns true\n     * the combined row is included in the resulatant table.\n     *\n     * @example\n     *  let originDM = dm.project(['Origin','Origin_Formal_Name']);\n     *  let carsDM = dm.project(['Name','Miles_per_Gallon','Origin'])\n     *\n     *  console.log(carsDM.join(originDM)));\n     *\n     *  console.log(carsDM.join(originDM,\n     *      obj => obj.[originDM.getName()].Origin === obj.[carsDM.getName()].Origin));\n     *\n     * @text\n     * This is chained version of `join` operator. `join` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} joinWith - The DataModel to be joined with the current instance DataModel.\n     * @param {SelectionPredicate} filterFn - The predicate function that will filter the result of the crossProduct.\n     *\n     * @return {DataModel} New DataModel instance created after joining.\n     */\n    join (joinWith, filterFn) {\n        return crossProduct(this, joinWith, filterFn);\n    }\n\n    /**\n     * {@link natural_join | Natural join} is a special kind of cross-product join where filtering of rows are performed\n     * internally by resolving common fields are from both table and the rows with common value are included.\n     *\n     * @example\n     *  let originDM = dm.project(['Origin','Origin_Formal_Name']);\n     *  let carsDM = dm.project(['Name','Miles_per_Gallon','Origin'])\n     *\n     *  console.log(carsDM.naturalJoin(originDM));\n     *\n     * @text\n     * This is chained version of `naturalJoin` operator. `naturalJoin` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} joinWith - The DataModel with which the current instance of DataModel on which the method is\n     *      called will be joined.\n     * @return {DataModel} New DataModel instance created after joining.\n     */\n    naturalJoin (joinWith) {\n        return crossProduct(this, joinWith, naturalJoinFilter(this, joinWith), true);\n    }\n\n    /**\n     * {@link link_to_union | Union} operation can be termed as vertical stacking of all rows from both the DataModel\n     * instances, provided that both of the {@link DataModel} instances should have same column names.\n     *\n     * @example\n     * console.log(EuropeanMakerDM.union(USAMakerDM));\n     *\n     * @text\n     * This is chained version of `naturalJoin` operator. `naturalJoin` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} unionWith - DataModel instance for which union has to be applied with the instance on which\n     *      the method is called\n     *\n     * @return {DataModel} New DataModel instance with the result of the operation\n     */\n    union (unionWith) {\n        return union(this, unionWith);\n    }\n\n    /**\n     * {@link link_to_difference | Difference } operation only include rows which are present in the datamodel on which\n     * it was called but not on the one passed as argument.\n     *\n     * @example\n     * console.log(highPowerDM.difference(highExpensiveDM));\n     *\n     * @text\n     * This is chained version of `naturalJoin` operator. `naturalJoin` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} differenceWith - DataModel instance for which difference has to be applied with the instance\n     *      on which the method is called\n     * @return {DataModel} New DataModel instance with the result of the operation\n     */\n    difference (differenceWith) {\n        return difference(this, differenceWith);\n    }\n\n    /**\n     * {@link link_to_selection | Selection} is a row filtering operation. It expects a predicate and an optional mode\n     * which control which all rows should be included in the resultant DataModel instance.\n     *\n     * {@link SelectionPredicate} is a function which returns a boolean value. For selection operation the selection\n     * function is called for each row of DataModel instance with the current row passed as argument.\n     *\n     * After executing {@link SelectionPredicate} the rows are labeled as either an entry of selection set or an entry\n     * of rejection set.\n     *\n     * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n     * resultant datamodel.\n     *\n     * @warning\n     * Selection and rejection set is only a logical idea for concept explanation purpose.\n     *\n     * @example\n     *  // with selection mode NORMAL:\n     *  const normDt = dt.select(fields => fields.Origin.value === \"USA\")\n     *  console.log(normDt));\n     *\n     * // with selection mode INVERSE:\n     * const inverDt = dt.select(fields => fields.Origin.value === \"USA\", { mode: DataModel.FilteringMode.INVERSE })\n     * console.log(inverDt);\n     *\n     * // with selection mode ALL:\n     * const dtArr = dt.select(fields => fields.Origin.value === \"USA\", { mode: DataModel.FilteringMode.ALL })\n     * // print the selected parts\n     * console.log(dtArr[0]);\n     * // print the inverted parts\n     * console.log(dtArr[1]);\n     *\n     * @text\n     * This is chained version of `select` operator. `select` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {Function} selectFn - The predicate function which is called for each row with the current row.\n     * ```\n     *  function (row, i, cloneProvider, store)  { ... }\n     * ```\n     * @param {Object} config - The configuration object to control the inclusion exclusion of a row in resultant\n     * DataModel instance.\n     * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - The mode of the selection.\n     * @return {DataModel} Returns the new DataModel instance(s) after operation.\n     */\n    select (selectFn, config) {\n        const defConfig = {\n            mode: FilteringMode.NORMAL,\n            saveChild: true\n        };\n        config = Object.assign({}, defConfig, config);\n\n        const cloneConfig = { saveChild: config.saveChild };\n        let oDm;\n\n        if (config.mode === FilteringMode.ALL) {\n            const selectDm = cloneWithSelect(\n                this,\n                selectFn,\n                { mode: FilteringMode.NORMAL },\n                cloneConfig\n            );\n            const rejectDm = cloneWithSelect(\n                this,\n                selectFn,\n                { mode: FilteringMode.INVERSE },\n                cloneConfig\n            );\n            oDm = [selectDm, rejectDm];\n        } else {\n            oDm = cloneWithSelect(\n                this,\n                selectFn,\n                config,\n                cloneConfig\n            );\n        }\n\n        return oDm;\n    }\n\n    /**\n     * Retrieves a boolean value if the current {@link DataModel} instance has data.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'CarName', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     * const data = [];\n     *\n     * const dt = new DataModel(data, schema);\n     * console.log(dt.isEmpty());\n     *\n     * @public\n     *\n     * @return {Boolean} True if the datamodel has no data, otherwise false.\n     */\n    isEmpty () {\n        return !this._rowDiffset.length || !this._colIdentifier.length;\n    }\n\n    /**\n     * Creates a clone from the current DataModel instance with child parent relationship.\n     *\n     * @private\n     * @param {boolean} [saveChild=true] - Whether the cloned instance would be recorded in the parent instance.\n     * @return {DataModel} - Returns the newly cloned DataModel instance.\n     */\n    clone (saveChild = true) {\n        const clonedDm = new this.constructor(this);\n        if (saveChild) {\n            clonedDm.setParent(this);\n        } else {\n            clonedDm.setParent(null);\n        }\n        return clonedDm;\n    }\n\n    /**\n     * {@link Projection} is filter column (field) operation. It expects list of fields' name and either include those\n     * or exclude those based on {@link FilteringMode} on the resultant variable.\n     *\n     * Projection expects array of fields name based on which it creates the selection and rejection set. All the field\n     * whose name is present in array goes in selection set and rest of the fields goes in rejection set.\n     *\n     * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n     * resulatant datamodel.\n     *\n     * @warning\n     * Selection and rejection set is only a logical idea for concept explanation purpose.\n     *\n     * @example\n     *  const dm = new DataModel(data, schema);\n     *\n     *  // with projection mode NORMAL:\n     *  const normDt = dt.project([\"Name\", \"HorsePower\"]);\n     *  console.log(normDt.getData());\n     *\n     *  // with projection mode INVERSE:\n     *  const inverDt = dt.project([\"Name\", \"HorsePower\"], { mode: DataModel.FilteringMode.INVERSE })\n     *  console.log(inverDt.getData());\n     *\n     *  // with selection mode ALL:\n     *  const dtArr = dt.project([\"Name\", \"HorsePower\"], { mode: DataModel.FilteringMode.ALL })\n     *  // print the normal parts\n     *  console.log(dtArr[0].getData());\n     *  // print the inverted parts\n     *  console.log(dtArr[1].getData());\n     *\n     * @text\n     * This is chained version of `select` operator. `select` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {Array.<string | Regexp>} projField - An array of column names in string or regular expression.\n     * @param {Object} [config] - An optional config to control the creation of new DataModel\n     * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - Mode of the projection\n     *\n     * @return {DataModel} Returns the new DataModel instance after operation.\n     */\n    project (projField, config) {\n        const defConfig = {\n            mode: FilteringMode.NORMAL,\n            saveChild: true\n        };\n        config = Object.assign({}, defConfig, config);\n        const fieldConfig = this.getFieldsConfig();\n        const allFields = Object.keys(fieldConfig);\n        const { mode } = config;\n\n        let normalizedProjField = projField.reduce((acc, field) => {\n            if (field.constructor.name === 'RegExp') {\n                acc.push(...allFields.filter(fieldName => fieldName.search(field) !== -1));\n            } else if (field in fieldConfig) {\n                acc.push(field);\n            }\n            return acc;\n        }, []);\n\n        normalizedProjField = Array.from(new Set(normalizedProjField)).map(field => field.trim());\n        let dataModel;\n\n        if (mode === FilteringMode.ALL) {\n            let projectionClone = cloneWithProject(this, normalizedProjField, {\n                mode: FilteringMode.NORMAL,\n                saveChild: config.saveChild\n            }, allFields);\n            let rejectionClone = cloneWithProject(this, normalizedProjField, {\n                mode: FilteringMode.INVERSE,\n                saveChild: config.saveChild\n            }, allFields);\n            dataModel = [projectionClone, rejectionClone];\n        } else {\n            let projectionClone = cloneWithProject(this, normalizedProjField, config, allFields);\n            dataModel = projectionClone;\n        }\n\n        return dataModel;\n    }\n\n    getFieldsConfig () {\n        return this._fieldConfig;\n    }\n\n    calculateFieldsConfig () {\n        this._fieldConfig = this._fieldspace.fields.reduce((acc, fieldObj, i) => {\n            acc[fieldObj.name()] = {\n                index: i,\n                def: fieldObj.schema(),\n            };\n            return acc;\n        }, {});\n        return this;\n    }\n\n\n    /**\n     * Frees up the resources associated with the current DataModel instance and breaks all the links instance has in\n     * the DAG.\n     *\n     * @public\n     */\n    dispose () {\n        this._parent && this._parent.removeChild(this);\n        this._parent = null;\n        this._children.forEach((child) => {\n            child._parent = null;\n        });\n        this._children = [];\n    }\n\n    /**\n     * Removes the specified child {@link DataModel} from the child list of the current {@link DataModel} instance.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'Name', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *    { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *    { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *    { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *    { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     *\n     * const dt2 = dt.select(fields => fields.Origin.value === \"USA\")\n     * dt.removeChild(dt2);\n     *\n     * @private\n     *\n     * @param {DataModel} child - Delegates the parent to remove this child.\n     */\n    removeChild (child) {\n        let idx = this._children.findIndex(sibling => sibling === child);\n        idx !== -1 ? this._children.splice(idx, 1) : true;\n    }\n\n    /**\n     * Sets the specified {@link DataModel} as a parent for the current {@link DataModel} instance.\n     *\n     * @param {DataModel} parent - The datamodel instance which will act as parent.\n     */\n    setParent (parent) {\n        this._parent && this._parent.removeChild(this);\n        this._parent = parent;\n        parent && parent._children.push(this);\n    }\n\n    /**\n     * Returns the parent {@link DataModel} instance.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'Name', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *    { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *    { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *    { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *    { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     *\n     * const dt2 = dt.select(fields => fields.Origin.value === \"USA\");\n     * const parentDm = dt2.getParent();\n     *\n     * @return {DataModel} Returns the parent DataModel instance.\n     */\n    getParent () {\n        return this._parent;\n    }\n\n    /**\n     * Returns the immediate child {@link DataModel} instances.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'Name', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *    { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *    { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *    { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *    { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     *\n     * const childDm1 = dt.select(fields => fields.Origin.value === \"USA\");\n     * const childDm2 = dt.select(fields => fields.Origin.value === \"Japan\");\n     * const childDm3 = dt.groupBy([\"Origin\"]);\n     *\n     * @return {DataModel[]} Returns the immediate child DataModel instances.\n     */\n    getChildren () {\n        return this._children;\n    }\n\n    /**\n     * Returns the in-between operation meta data while creating the current {@link DataModel} instance.\n     *\n     * @example\n     * const schema = [\n     *   { name: 'Name', type: 'dimension' },\n     *   { name: 'HorsePower', type: 'measure' },\n     *   { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *   { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *   { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *   { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *   { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     * const dt2 = dt.select(fields => fields.Origin.value === \"USA\");\n     * const dt3 = dt2.groupBy([\"Origin\"]);\n     * const derivations = dt3.getDerivations();\n     *\n     * @return {Any[]} Returns the derivation meta data.\n     */\n    getDerivations () {\n        return this._derivation;\n    }\n\n    /**\n     * Returns the in-between operation meta data happened from root {@link DataModel} to current instance.\n     *\n     * @example\n     * const schema = [\n     *   { name: 'Name', type: 'dimension' },\n     *   { name: 'HorsePower', type: 'measure' },\n     *   { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *   { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *   { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *   { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *   { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     * const dt2 = dt.select(fields => fields.Origin.value === \"USA\");\n     * const dt3 = dt2.groupBy([\"Origin\"]);\n     * const ancDerivations = dt3.getAncestorDerivations();\n     *\n     * @return {Any[]} Returns the previous derivation meta data.\n     */\n    getAncestorDerivations () {\n        return this._ancestorDerivation;\n    }\n}\n\nexport default Relation;\n","/* eslint-disable default-case */\n\nimport { FieldType, DimensionSubtype, DataFormat } from './enums';\nimport {\n    persistDerivations,\n    getRootGroupByModel,\n    propagateToAllDataModels,\n    getRootDataModel,\n    propagateImmutableActions,\n    addToPropNamespace,\n    sanitizeUnitSchema\n} from './helper';\nimport { DM_DERIVATIVES, PROPAGATION } from './constants';\nimport {\n    dataBuilder,\n    rowDiffsetIterator,\n    groupBy\n} from './operator';\nimport { createBinnedFieldData } from './operator/bucket-creator';\nimport Relation from './relation';\nimport reducerStore from './utils/reducer-store';\nimport { createFields } from './field-creator';\nimport InvalidAwareTypes from './invalid-aware-types';\n\n/**\n * DataModel is an in-browser representation of tabular data. It supports\n * {@link https://en.wikipedia.org/wiki/Relational_algebra | relational algebra} operators as well as generic data\n * processing opearators.\n * DataModel extends {@link Relation} class which defines all the relational algebra opreators. DataModel gives\n * definition of generic data processing operators which are not relational algebra complient.\n *\n * @public\n * @class\n * @extends Relation\n * @memberof Datamodel\n */\nclass DataModel extends Relation {\n    /**\n     * Creates a new DataModel instance by providing data and schema. Data could be in the form of\n     * - Flat JSON\n     * - DSV String\n     * - 2D Array\n     *\n     * By default DataModel finds suitable adapter to serialize the data. DataModel also expects a\n     * {@link Schema | schema} for identifying the variables present in data.\n     *\n     * @constructor\n     * @example\n     * const data = loadData('cars.csv');\n     * const schema = [\n     *      { name: 'Name', type: 'dimension' },\n     *      { name: 'Miles_per_Gallon', type: 'measure', unit : 'cm', scale: '1000', numberformat: val => `${val}G`},\n     *      { name: 'Cylinders', type: 'dimension' },\n     *      { name: 'Displacement', type: 'measure' },\n     *      { name: 'Horsepower', type: 'measure' },\n     *      { name: 'Weight_in_lbs', type: 'measure' },\n     *      { name: 'Acceleration', type: 'measure' },\n     *      { name: 'Year', type: 'dimension', subtype: 'datetime', format: '%Y' },\n     *      { name: 'Origin', type: 'dimension' }\n     * ];\n     * const dm = new DataModel(data, schema, { name: 'Cars' });\n     * table(dm);\n     *\n     * @public\n     *\n     * @param {Array.<Object> | string | Array.<Array>} data Input data in any of the mentioned formats\n     * @param {Array.<Schema>} schema Defination of the variables. Order of the variables in data and order of the\n     *      variables in schema has to be same.\n     * @param {object} [options] Optional arguments to specify more settings regarding the creation part\n     * @param {string} [options.name] Name of the datamodel instance. If no name is given an auto generated name is\n     *      assigned to the instance.\n     * @param {string} [options.fieldSeparator=','] specify field separator type if the data is of type dsv string.\n     */\n    constructor (...args) {\n        super(...args);\n\n        this._onPropagation = [];\n    }\n\n    /**\n     * Reducers are simple functions which reduces an array of numbers to a representative number of the set.\n     * Like an array of numbers `[10, 20, 5, 15]` can be reduced to `12.5` if average / mean reducer function is\n     * applied. All the measure fields in datamodel (variables in data) needs a reducer to handle aggregation.\n     *\n     * @public\n     *\n     * @return {ReducerStore} Singleton instance of {@link ReducerStore}.\n     */\n    static get Reducers () {\n        return reducerStore;\n    }\n\n    /**\n     * Configure null, undefined, invalid values in the source data\n     *\n     * @public\n     *\n     * @param {Object} [config] - Configuration to control how null, undefined and non-parsable values are\n     * represented in DataModel.\n     * @param {string} [config.undefined] - Define how an undefined value will be represented.\n     * @param {string} [config.null] - Define how a null value will be represented.\n     * @param {string} [config.invalid] - Define how a non-parsable value will be represented.\n     */\n    static configureInvalidAwareTypes (config) {\n        return InvalidAwareTypes.invalidAwareVals(config);\n    }\n\n    /**\n     * Retrieve the data attached to an instance in JSON format.\n     *\n     * @example\n     * // DataModel instance is already prepared and assigned to dm variable\n     *  const data = dm.getData({\n     *      order: 'column',\n     *      formatter: {\n     *          origin: (val) => val === 'European Union' ? 'EU' : val;\n     *      }\n     *  });\n     *  console.log(data);\n     *\n     * @public\n     *\n     * @param {Object} [options] Options to control how the raw data is to be returned.\n     * @param {string} [options.order='row'] Defines if data is retieved in row order or column order. Possible values\n     *      are `'rows'` and `'columns'`\n     * @param {Function} [options.formatter=null] Formats the output data. This expects an object, where the keys are\n     *      the name of the variable needs to be formatted. The formatter function is called for each row passing the\n     *      value of the cell for a particular row as arguments. The formatter is a function in the form of\n     *      `function (value, rowId, schema) => { ... }`\n     *      Know more about {@link Fomatter}.\n     *\n     * @return {Array} Returns a multidimensional array of the data with schema. The return format looks like\n     *      ```\n     *          {\n     *              data,\n     *              schema\n     *          }\n     *      ```\n     */\n    getData (options) {\n        const defOptions = {\n            order: 'row',\n            formatter: null,\n            withUid: false,\n            getAllFields: false,\n            sort: []\n        };\n        options = Object.assign({}, defOptions, options);\n        const fields = this.getPartialFieldspace().fields;\n\n        const dataGenerated = dataBuilder.call(\n            this,\n            this.getPartialFieldspace().fields,\n            this._rowDiffset,\n            options.getAllFields ? fields.map(d => d.name()).join() : this._colIdentifier,\n            options.sort,\n            {\n                columnWise: options.order === 'column',\n                addUid: !!options.withUid\n            }\n        );\n\n        if (!options.formatter) {\n            return dataGenerated;\n        }\n\n        const { formatter } = options;\n        const { data, schema, uids } = dataGenerated;\n        const fieldNames = schema.map((e => e.name));\n        const fmtFieldNames = Object.keys(formatter);\n        const fmtFieldIdx = fmtFieldNames.reduce((acc, next) => {\n            const idx = fieldNames.indexOf(next);\n            if (idx !== -1) {\n                acc.push([idx, formatter[next]]);\n            }\n            return acc;\n        }, []);\n\n        if (options.order === 'column') {\n            fmtFieldIdx.forEach((elem) => {\n                const fIdx = elem[0];\n                const fmtFn = elem[1];\n\n                data[fIdx].forEach((datum, datumIdx) => {\n                    data[fIdx][datumIdx] = fmtFn.call(\n                        undefined,\n                        datum,\n                        uids[datumIdx],\n                        schema[fIdx]\n                    );\n                });\n            });\n        } else {\n            data.forEach((datum, datumIdx) => {\n                fmtFieldIdx.forEach((elem) => {\n                    const fIdx = elem[0];\n                    const fmtFn = elem[1];\n\n                    datum[fIdx] = fmtFn.call(\n                        undefined,\n                        datum[fIdx],\n                        uids[datumIdx],\n                        schema[fIdx]\n                    );\n                });\n            });\n        }\n\n        return dataGenerated;\n    }\n\n    /**\n     * Groups the data using particular dimensions and by reducing measures. It expects a list of dimensions using which\n     * it projects the datamodel and perform aggregations to reduce the duplicate tuples. Refer this\n     * {@link link_to_one_example_with_group_by | document} to know the intuition behind groupBy.\n     *\n     * DataModel by default provides definition of few {@link reducer | Reducers}.\n     * {@link ReducerStore | User defined reducers} can also be registered.\n     *\n     * This is the chained implementation of `groupBy`.\n     * `groupBy` also supports {@link link_to_compose_groupBy | composability}\n     *\n     * @example\n     * const groupedDM = dm.groupBy(['Year'], { horsepower: 'max' } );\n     * console.log(groupedDm);\n     *\n     * @public\n     *\n     * @param {Array.<string>} fieldsArr - Array containing the name of dimensions\n     * @param {Object} [reducers={}] - A map whose key is the variable name and value is the name of the reducer. If its\n     *      not passed, or any variable is ommitted from the object, default aggregation function is used from the\n     *      schema of the variable.\n     *\n     * @return {DataModel} Returns a new DataModel instance after performing the groupby.\n     */\n    groupBy (fieldsArr, reducers = {}, config = { saveChild: true }) {\n        const groupByString = `${fieldsArr.join()}`;\n        let params = [this, fieldsArr, reducers];\n        const newDataModel = groupBy(...params);\n\n        persistDerivations(\n            this,\n            newDataModel,\n            DM_DERIVATIVES.GROUPBY,\n            { fieldsArr, groupByString, defaultReducer: reducerStore.defaultReducer() },\n            reducers\n        );\n\n        if (config.saveChild) {\n            newDataModel.setParent(this);\n        } else {\n            newDataModel.setParent(null);\n        }\n\n        return newDataModel;\n    }\n\n    /**\n     * Performs sorting operation on the current {@link DataModel} instance according to the specified sorting details.\n     * Like every other operator it doesn't mutate the current DataModel instance on which it was called, instead\n     * returns a new DataModel instance containing the sorted data.\n     *\n     * DataModel support multi level sorting by listing the variables using which sorting needs to be performed and\n     * the type of sorting `ASC` or `DESC`.\n     *\n     * In the following example, data is sorted by `Origin` field in `DESC` order in first level followed by another\n     * level of sorting by `Acceleration` in `ASC` order.\n     *\n     * @example\n     * // here dm is the pre-declared DataModel instance containing the data of 'cars.json' file\n     * let sortedDm = dm.sort([\n     *    [\"Origin\", \"DESC\"]\n     *    [\"Acceleration\"] // Default value is ASC\n     * ]);\n     *\n     * console.log(dm.getData());\n     * console.log(sortedDm.getData());\n     *\n     * // Sort with a custom sorting function\n     * sortedDm = dm.sort([\n     *    [\"Origin\", \"DESC\"]\n     *    [\"Acceleration\", (a, b) => a - b] // Custom sorting function\n     * ]);\n     *\n     * console.log(dm.getData());\n     * console.log(sortedDm.getData());\n     *\n     * @text\n     * DataModel also provides another sorting mechanism out of the box where sort is applied to a variable using\n     * another variable which determines the order.\n     * Like the above DataModel contains three fields `Origin`, `Name` and `Acceleration`. Now, the data in this\n     * model can be sorted by `Origin` field according to the average value of all `Acceleration` for a\n     * particular `Origin` value.\n     *\n     * @example\n     * // here dm is the pre-declared DataModel instance containing the data of 'cars.json' file\n     * const sortedDm = dm.sort([\n     *     ['Origin', ['Acceleration', (a, b) => avg(...a.Acceleration) - avg(...b.Acceleration)]]\n     * ]);\n     *\n     * console.log(dm.getData());\n     * console.log(sortedDm.getData());\n     *\n     * @public\n     *\n     * @param {Array.<Array>} sortingDetails - Sorting details based on which the sorting will be performed.\n     * @return {DataModel} Returns a new instance of DataModel with sorted data.\n     */\n    sort (sortingDetails, config = { saveChild: false }) {\n        const rawData = this.getData({\n            order: 'row',\n            sort: sortingDetails\n        });\n        const header = rawData.schema.map(field => field.name);\n        const dataInCSVArr = [header].concat(rawData.data);\n\n        const sortedDm = new this.constructor(dataInCSVArr, rawData.schema, { dataFormat: 'DSVArr' });\n\n        persistDerivations(\n            this,\n            sortedDm,\n            DM_DERIVATIVES.SORT,\n            config,\n            sortingDetails\n        );\n\n        if (config.saveChild) {\n            sortedDm.setParent(this);\n        } else {\n            sortedDm.setParent(null);\n        }\n\n        return sortedDm;\n    }\n\n    /**\n     * Performs the serialization operation on the current {@link DataModel} instance according to the specified data\n     * type. When an {@link DataModel} instance is created, it de-serializes the input data into its internal format,\n     * and during its serialization process, it converts its internal data format to the specified data type and returns\n     * that data regardless what type of data is used during the {@link DataModel} initialization.\n     *\n     * @example\n     * // here dm is the pre-declared DataModel instance.\n     * const csvData = dm.serialize(DataModel.DataFormat.DSV_STR, { fieldSeparator: \",\" });\n     * console.log(csvData); // The csv formatted data.\n     *\n     * const jsonData = dm.serialize(DataModel.DataFormat.FLAT_JSON);\n     * console.log(jsonData); // The json data.\n     *\n     * @public\n     *\n     * @param {string} type - The data type name for serialization.\n     * @param {Object} options - The optional option object.\n     * @param {string} options.fieldSeparator - The field separator character for DSV data type.\n     * @return {Array|string} Returns the serialized data.\n     */\n    serialize (type, options) {\n        type = type || this._dataFormat;\n        options = Object.assign({}, { fieldSeparator: ',' }, options);\n\n        const fields = this.getFieldspace().fields;\n        const colData = fields.map(f => f.formattedData());\n        const rowsCount = colData[0].length;\n        let serializedData;\n        let rowIdx;\n        let colIdx;\n\n        if (type === DataFormat.FLAT_JSON) {\n            serializedData = [];\n            for (rowIdx = 0; rowIdx < rowsCount; rowIdx++) {\n                const row = {};\n                for (colIdx = 0; colIdx < fields.length; colIdx++) {\n                    row[fields[colIdx].name()] = colData[colIdx][rowIdx];\n                }\n                serializedData.push(row);\n            }\n        } else if (type === DataFormat.DSV_STR) {\n            serializedData = [fields.map(f => f.name()).join(options.fieldSeparator)];\n            for (rowIdx = 0; rowIdx < rowsCount; rowIdx++) {\n                const row = [];\n                for (colIdx = 0; colIdx < fields.length; colIdx++) {\n                    row.push(colData[colIdx][rowIdx]);\n                }\n                serializedData.push(row.join(options.fieldSeparator));\n            }\n            serializedData = serializedData.join('\\n');\n        } else if (type === DataFormat.DSV_ARR) {\n            serializedData = [fields.map(f => f.name())];\n            for (rowIdx = 0; rowIdx < rowsCount; rowIdx++) {\n                const row = [];\n                for (colIdx = 0; colIdx < fields.length; colIdx++) {\n                    row.push(colData[colIdx][rowIdx]);\n                }\n                serializedData.push(row);\n            }\n        } else {\n            throw new Error(`Data type ${type} is not supported`);\n        }\n\n        return serializedData;\n    }\n\n    addField (field) {\n        const fieldName = field.name();\n        this._colIdentifier += `,${fieldName}`;\n        const partialFieldspace = this._partialFieldspace;\n\n        if (!partialFieldspace.fieldsObj()[field.name()]) {\n            partialFieldspace.fields.push(field);\n        } else {\n            const fieldIndex = partialFieldspace.fields.findIndex(fieldinst => fieldinst.name() === fieldName);\n            fieldIndex >= 0 && (partialFieldspace.fields[fieldIndex] = field);\n        }\n\n        // flush out cached namespace values on addition of new fields\n        partialFieldspace._cachedFieldsObj = null;\n        partialFieldspace._cachedDimension = null;\n        partialFieldspace._cachedMeasure = null;\n\n        this.__calculateFieldspace().calculateFieldsConfig();\n        return this;\n    }\n\n    /**\n    * Creates a new variable calculated from existing variables. This method expects the definition of the newly created\n    * variable and a function which resolves the value of the new variable from existing variables.\n    *\n    * Can create a new measure based on existing variables:\n    * @example\n    *  // DataModel already prepared and assigned to dm variable;\n    *  const newDm = dataModel.calculateVariable({\n    *      name: 'powerToWeight',\n    *      type: 'measure'\n    *  }, ['horsepower', 'weight_in_lbs', (hp, weight) => hp / weight ]);\n    *\n    *\n    * Can create a new dimension based on existing variables:\n    * @example\n    *  // DataModel already prepared and assigned to dm variable;\n    *  const child = dataModel.calculateVariable(\n    *     {\n    *       name: 'Efficiency',\n    *       type: 'dimension'\n    *     }, ['horsepower', (hp) => {\n    *      if (hp < 80) { return 'low'; },\n    *      else if (hp < 120) { return 'moderate'; }\n    *      else { return 'high' }\n    *  }]);\n    *\n    * @public\n    *\n    * @param {Object} schema - The schema of newly defined variable.\n    * @param {Array.<string|function>} dependency - An array containing the dependency variable names and a resolver\n    * function as the last element.\n    * @param {Object} config - An optional config object.\n    * @param {boolean} [config.saveChild] - Whether the newly created DataModel will be a child.\n    * @param {boolean} [config.replaceVar] - Whether the newly created variable will replace the existing variable.\n    * @return {DataModel} Returns an instance of DataModel with the new field.\n    */\n    calculateVariable (schema, dependency, config) {\n        schema = sanitizeUnitSchema(schema);\n        config = Object.assign({}, { saveChild: true, replaceVar: false }, config);\n\n        const fieldsConfig = this.getFieldsConfig();\n        const depVars = dependency.slice(0, dependency.length - 1);\n        const retrieveFn = dependency[dependency.length - 1];\n\n        if (fieldsConfig[schema.name] && !config.replaceVar) {\n            throw new Error(`${schema.name} field already exists in datamodel`);\n        }\n\n        const depFieldIndices = depVars.map((field) => {\n            const fieldSpec = fieldsConfig[field];\n            if (!fieldSpec) {\n                // @todo dont throw error here, use warning in production mode\n                throw new Error(`${field} is not a valid column name.`);\n            }\n            return fieldSpec.index;\n        });\n\n        const clone = this.clone(config.saveChild);\n\n        const fs = clone.getFieldspace().fields;\n        const suppliedFields = depFieldIndices.map(idx => fs[idx]);\n\n        let cachedStore = {};\n        let cloneProvider = () => this.detachedRoot();\n\n        const computedValues = [];\n        rowDiffsetIterator(clone._rowDiffset, (i) => {\n            const fieldsData = suppliedFields.map(field => field.partialField.data[i]);\n            computedValues[i] = retrieveFn(...fieldsData, i, cloneProvider, cachedStore);\n        });\n        const [field] = createFields([computedValues], [schema], [schema.name]);\n        clone.addField(field);\n\n        persistDerivations(\n            this,\n            clone,\n            DM_DERIVATIVES.CAL_VAR,\n            { config: schema, fields: depVars },\n            retrieveFn\n        );\n\n        return clone;\n    }\n\n    /**\n     * Propagates changes across all the connected DataModel instances.\n     *\n     * @param {Array} identifiers - A list of identifiers that were interacted with.\n     * @param {Object} payload - The interaction specific details.\n     *\n     * @return {DataModel} DataModel instance.\n     */\n    propagate (identifiers, config = {}, addToNameSpace, propConfig = {}) {\n        const isMutableAction = config.isMutableAction;\n        const propagationSourceId = config.sourceId;\n        const payload = config.payload;\n        const rootModel = getRootDataModel(this);\n        const propagationNameSpace = rootModel._propagationNameSpace;\n        const rootGroupByModel = getRootGroupByModel(this);\n        const rootModels = {\n            groupByModel: rootGroupByModel,\n            model: rootModel\n        };\n\n        addToNameSpace && addToPropNamespace(propagationNameSpace, config, this);\n        propagateToAllDataModels(identifiers, rootModels, { propagationNameSpace, sourceId: propagationSourceId },\n            Object.assign({\n                payload\n            }, config));\n\n        if (isMutableAction) {\n            propagateImmutableActions(propagationNameSpace, rootModels, {\n                config,\n                propConfig\n            }, this);\n        }\n\n        return this;\n    }\n\n    /**\n     * Associates a callback with an event name.\n     *\n     * @param {string} eventName - The name of the event.\n     * @param {Function} callback - The callback to invoke.\n     * @return {DataModel} Returns this current DataModel instance itself.\n     */\n    on (eventName, callback) {\n        switch (eventName) {\n        case PROPAGATION:\n            this._onPropagation.push(callback);\n            break;\n        }\n        return this;\n    }\n\n    /**\n     * Unsubscribes the callbacks for the provided event name.\n     *\n     * @param {string} eventName - The name of the event to unsubscribe.\n     * @return {DataModel} Returns the current DataModel instance itself.\n     */\n    unsubscribe (eventName) {\n        switch (eventName) {\n        case PROPAGATION:\n            this._onPropagation = [];\n            break;\n\n        }\n        return this;\n    }\n\n    /**\n     * This method is used to invoke the method associated with propagation.\n     *\n     * @param {Object} payload The interaction payload.\n     * @param {DataModel} identifiers The propagated DataModel.\n     * @memberof DataModel\n     */\n    handlePropagation (propModel, payload) {\n        let propListeners = this._onPropagation;\n        propListeners.forEach(fn => fn.call(this, propModel, payload));\n    }\n\n    /**\n     * Performs the binning operation on a measure field based on the binning configuration. Binning means discretizing\n     * values of a measure. Binning configuration contains an array; subsequent values from the array marks the boundary\n     * of buckets in [inclusive, exclusive) range format. This operation does not mutate the subject measure field,\n     * instead, it creates a new field (variable) of type dimension and subtype binned.\n     *\n     * Binning can be configured by\n     * - providing custom bin configuration with non-uniform buckets,\n     * - providing bins count,\n     * - providing each bin size,\n     *\n     * When custom `buckets` are provided as part of binning configuration:\n     * @example\n     *  // DataModel already prepared and assigned to dm variable\n     *  const config = { name: 'binnedHP', buckets: [30, 80, 100, 110] }\n     *  const binnedDM = dataModel.bin('horsepower', config);\n     *\n     * @text\n     * When `binsCount` is defined as part of binning configuration:\n     * @example\n     *  // DataModel already prepared and assigned to dm variable\n     *  const config = { name: 'binnedHP', binsCount: 5, start: 0, end: 100 }\n     *  const binDM = dataModel.bin('horsepower', config);\n     *\n     * @text\n     * When `binSize` is defined as part of binning configuration:\n     * @example\n     *  // DataModel already prepared and assigned to dm variable\n     *  const config = { name: 'binnedHorsepower', binSize: 20, start: 5}\n     *  const binDM = dataModel.bin('horsepower', config);\n     *\n     * @public\n     *\n     * @param {string} measureFieldName - The name of the target measure field.\n     * @param {Object} config - The config object.\n     * @param {string} [config.name] - The name of the new field which will be created.\n     * @param {string} [config.buckets] - An array containing the bucket ranges.\n     * @param {string} [config.binSize] - The size of each bin. It is ignored when buckets are given.\n     * @param {string} [config.binsCount] - The total number of bins to generate. It is ignored when buckets are given.\n     * @param {string} [config.start] - The start value of the bucket ranges. It is ignored when buckets are given.\n     * @param {string} [config.end] - The end value of the bucket ranges. It is ignored when buckets are given.\n     * @return {DataModel} Returns a new {@link DataModel} instance with the new field.\n     */\n    bin (measureFieldName, config) {\n        const fieldsConfig = this.getFieldsConfig();\n\n        if (!fieldsConfig[measureFieldName]) {\n            throw new Error(`Field ${measureFieldName} doesn't exist`);\n        }\n\n        const binFieldName = config.name || `${measureFieldName}_binned`;\n\n        if (fieldsConfig[binFieldName]) {\n            throw new Error(`Field ${binFieldName} already exists`);\n        }\n\n        const measureField = this.getFieldspace().fieldsObj()[measureFieldName];\n        const { binnedData, bins } = createBinnedFieldData(measureField, this._rowDiffset, config);\n\n        const binField = createFields([binnedData], [\n            {\n                name: binFieldName,\n                type: FieldType.DIMENSION,\n                subtype: DimensionSubtype.BINNED,\n                bins\n            }], [binFieldName])[0];\n\n        const clone = this.clone(config.saveChild);\n        clone.addField(binField);\n\n        persistDerivations(\n            this,\n            clone,\n            DM_DERIVATIVES.BIN,\n             { measureFieldName, config, binFieldName },\n             null\n        );\n\n        return clone;\n    }\n\n    /**\n     * Creates a new {@link DataModel} instance with completely detached root from current {@link DataModel} instance,\n     * the new {@link DataModel} instance has no parent-children relationship with the current one, but has same data as\n     * the current one.\n     * This API is useful when a completely different {@link DataModel} but with same data as the current instance is\n     * needed.\n     *\n     * @example\n     *  const dm = new DataModel(data, schema);\n     *  const detachedDm = dm.detachedRoot();\n     *\n     * // has different namespace\n     * console.log(dm.getPartialFieldspace().name);\n     * console.log(detachedDm.getPartialFieldspace().name);\n     *\n     * // has same data\n     * console.log(dm.getData());\n     * console.log(detachedDm.getData());\n     *\n     * @public\n     *\n     * @return {DataModel} Returns a detached {@link DataModel} instance.\n     */\n    detachedRoot () {\n        const data = this.serialize(DataFormat.FLAT_JSON);\n        const schema = this.getSchema();\n\n        return new DataModel(data, schema);\n    }\n}\n\nexport default DataModel;\n","import { fnList } from '../operator/group-by-function';\n\nexport const { sum, avg, min, max, first, last, count, std: sd } = fnList;\n","import DataModel from './datamodel';\nimport {\n  compose,\n  bin,\n  select,\n  project,\n  groupby as groupBy,\n  calculateVariable,\n  sort,\n  crossProduct,\n  difference,\n  naturalJoin,\n  leftOuterJoin,\n  rightOuterJoin,\n  fullOuterJoin,\n  union\n} from './operator';\nimport * as Stats from './stats';\nimport * as enums from './enums';\nimport { DateTimeFormatter } from './utils';\nimport { DataFormat, FilteringMode, DM_DERIVATIVES } from './constants';\nimport InvalidAwareTypes from './invalid-aware-types';\nimport pkg from '../package.json';\n\nconst Operators = {\n    compose,\n    bin,\n    select,\n    project,\n    groupBy,\n    calculateVariable,\n    sort,\n    crossProduct,\n    difference,\n    naturalJoin,\n    leftOuterJoin,\n    rightOuterJoin,\n    fullOuterJoin,\n    union\n};\n\nconst version = pkg.version;\nObject.assign(DataModel, {\n    Operators,\n    Stats,\n    DM_DERIVATIVES,\n    DateTimeFormatter,\n    DataFormat,\n    FilteringMode,\n    InvalidAwareTypes,\n    version\n}, enums);\n\nexport default DataModel;\n","/**\n * Wrapper on calculateVariable() method of DataModel to behave\n * the pure-function functionality.\n *\n * @param {Array} args - The argument list.\n * @return {any} Returns the returned value of calling function.\n */\nexport const calculateVariable = (...args) => dm => dm.calculateVariable(...args);\n\n/**\n * Wrapper on sort() method of DataModel to behave\n * the pure-function functionality.\n *\n * @param {Array} args - The argument list.\n * @return {any} Returns the returned value of calling function.\n */\nexport const sort = (...args) => dm => dm.sort(...args);\n","import { crossProduct } from './cross-product';\nimport { naturalJoinFilter } from './natural-join-filter-function';\n\nexport function naturalJoin (dataModel1, dataModel2) {\n    return crossProduct(dataModel1, dataModel2, naturalJoinFilter(dataModel1, dataModel2), true);\n}\n"],"sourceRoot":""}
=======
{"version":3,"sources":["webpack://DataModel/webpack/universalModuleDefinition","webpack://DataModel/webpack/bootstrap","webpack://DataModel/./src/index.js","webpack://DataModel/./src/enums/data-format.js","webpack://DataModel/./src/enums/dimension-subtype.js","webpack://DataModel/./src/enums/measure-subtype.js","webpack://DataModel/./src/enums/field-type.js","webpack://DataModel/./src/enums/filtering-mode.js","webpack://DataModel/./src/enums/group-by-functions.js","webpack://DataModel/./src/utils/date-time-formatter.js","webpack://DataModel/./src/utils/column-major.js","webpack://DataModel/./src/utils/extend2.js","webpack://DataModel/./src/utils/helper.js","webpack://DataModel/./src/field-store.js","webpack://DataModel/./src/value.js","webpack://DataModel/./src/operator/row-diffset-iterator.js","webpack://DataModel/./src/invalid-aware-types.js","webpack://DataModel/./src/operator/bucket-creator.js","webpack://DataModel/./src/constants/index.js","webpack://DataModel/./src/operator/compose.js","webpack://DataModel/./src/operator/get-common-schema.js","webpack://DataModel/./src/operator/cross-product.js","webpack://DataModel/./src/operator/merge-sort.js","webpack://DataModel/./src/operator/data-builder.js","webpack://DataModel/./src/operator/difference.js","webpack://DataModel/./src/operator/group-by-function.js","webpack://DataModel/./src/utils/reducer-store.js","webpack://DataModel/./src/operator/group-by.js","webpack://DataModel/./src/operator/natural-join-filter-function.js","webpack://DataModel/./src/operator/union.js","webpack://DataModel/./src/operator/outer-join.js","webpack://DataModel/./src/fields/field/index.js","webpack://DataModel/./src/fields/dimension/index.js","webpack://DataModel/./src/fields/categorical/index.js","webpack://DataModel/./src/fields/temporal/index.js","webpack://DataModel/./src/fields/binned/index.js","webpack://DataModel/./src/fields/measure/index.js","webpack://DataModel/./src/fields/continuous/index.js","webpack://DataModel/./src/fields/parsers/field-parser/index.js","webpack://DataModel/./src/fields/parsers/categorical-parser/index.js","webpack://DataModel/./src/fields/parsers/temporal-parser/index.js","webpack://DataModel/./src/fields/parsers/binned-parser/index.js","webpack://DataModel/./src/fields/parsers/continuous-parser/index.js","webpack://DataModel/./src/fields/partial-field/index.js","webpack://DataModel/./src/field-creator.js","webpack://DataModel/./src/default-config.js","webpack://DataModel/./src/converter/dsv-arr.js","webpack://DataModel/./node_modules/d3-dsv/src/dsv.js","webpack://DataModel/./node_modules/d3-dsv/src/csv.js","webpack://DataModel/./node_modules/d3-dsv/src/tsv.js","webpack://DataModel/./src/converter/dsv-str.js","webpack://DataModel/./src/converter/flat-json.js","webpack://DataModel/./src/converter/auto-resolver.js","webpack://DataModel/./src/helper.js","webpack://DataModel/./src/relation.js","webpack://DataModel/./src/datamodel.js","webpack://DataModel/./src/stats/index.js","webpack://DataModel/./src/export.js","webpack://DataModel/./src/operator/pure-operators.js","webpack://DataModel/./src/operator/natural-join.js"],"names":["root","factory","exports","module","define","amd","window","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","DataModel","require","default","DataFormat","FLAT_JSON","DSV_STR","DSV_ARR","AUTO","DimensionSubtype","CATEGORICAL","TEMPORAL","GEO","BINNED","MeasureSubtype","CONTINUOUS","FieldType","MEASURE","DIMENSION","FilteringMode","NORMAL","INVERSE","ALL","GROUP_BY_FUNCTIONS","SUM","AVG","MIN","MAX","FIRST","LAST","COUNT","STD","convertToNativeDate","date","Date","pad","DateTimeFormatter","format","this","dtParams","undefined","nativeDate","RegExp","escape","text","replace","TOKEN_PREFIX","DATETIME_PARAM_SEQUENCE","YEAR","MONTH","DAY","HOUR","MINUTE","SECOND","MILLISECOND","defaultNumberParser","defVal","val","parsedVal","isFinite","parseInt","defaultRangeParser","range","nVal","toLowerCase","length","getTokenDefinitions","daysDef","short","long","monthsDef","H","index","extract","parser","formatter","getHours","toString","hours","P","M","getMinutes","S","getSeconds","K","getMilliseconds","a","join","day","getDay","A","e","getDate","b","month","getMonth","B","y","result","substring","presentDate","presentYear","Math","trunc","getFullYear","year","Y","getTokenFormalNames","definitions","HOUR_12","AMPM_UPPERCASE","AMPM_LOWERCASE","SHORT_DAY","LONG_DAY","DAY_OF_MONTH","DAY_OF_MONTH_CONSTANT_WIDTH","SHORT_MONTH","LONG_MONTH","MONTH_OF_YEAR","SHORT_YEAR","LONG_YEAR","tokenResolver","defaultResolver","arg","targetParam","arguments","hourFormat24","hourFormat12","ampmLower","ampmUpper","amOrpm","isPM","findTokens","tokenPrefix","tokenLiterals","keys","occurrence","forwardChar","indexOf","push","token","formatAs","nDate","formattedStr","String","formattedVal","parse","dateTimeStamp","options","extractTokenValue","dtParamSeq","noBreak","dtParamArr","args","resolverKey","resolverParams","resolverFn","param","resolvedVal","splice","apply","checkIfOnlyYear","unshift","tokenObj","lastOccurrenceIndex","occObj","occIndex","targetText","regexFormat","tokenArr","map","obj","occurrenceLength","extractValues","match","shift","getNativeDate","Number","Function","concat","_toConsumableArray","len","column_major","store","_len","fields","Array","_key","forEach","fieldIndex","from","OBJECTSTRING","objectToStrFn","objectToStr","arrayToStr","checkCyclicRef","parentArr","bIndex","extend2","obj1","obj2","skipUndef","_typeof","merge","tgtArr","srcArr","item","srcVal","tgtVal","str","cRef","isArray","getUniqueId","getTime","round","random","isArrEqual","arr1","arr2","formatNumber","detectDataFormat","data","isObject","fieldStore","createNamespace","fieldArr","dataId","fieldsObj","_cachedFieldsObj","field","getMeasure","measureFields","_cachedMeasure","schema","type","getDimension","dimensionFields","_cachedDimension","Value","_classCallCheck","configurable","writable","_value","rowDiffsetIterator","rowDiffset","callback","split","diffStr","diffStsArr","start","end","InvalidAwareTypes","invalid_aware_types_classCallCheck","config","assign","_invalidAwareValsMap","invalidAwareVals","NULL","NA","NIL","invalid","nil","null","generateBuckets","binSize","buckets","next","findBucketRange","bucketRanges","leftIdx","rightIdx","midIdx","floor","DM_DERIVATIVES","SELECT","PROJECT","GROUPBY","COMPOSE","CAL_VAR","BIN","SORT","JOINS","CROSS","LEFTOUTER","RIGHTOUTER","NATURAL","FULLOUTER","LOGICAL_OPERATORS","getCommonSchema","fs1","fs2","retArr","fs1Arr","defaultFilterFn","crossProduct","dm1","dm2","filterFn","replaceCommonSchema","jointype","applicableFilterFn","dm1FieldStore","getFieldspace","dm2FieldStore","dm1FieldStoreName","dm2FieldStoreName","commonSchemaList","Error","tmpSchema","_rowDiffset","rowAdded","rowPosition","ii","tuple","userArg","partialField","dm1Fields","prepareJoinData","dm2Fields","detachedRoot","tupleObj","cellVal","iii","defSortFn","a1","b1","mergeSort","arr","sortFn","sort","lo","hi","mid","mainArr","auxArr","getSortFn","dataType","sortType","retFunc","groupData","hashMap","Map","groupedData","datum","fieldVal","has","set","createSortingFnArg","groupedDatum","targetFields","targetFieldDetails","label","reduce","acc","idx","dataBuilder","colIdentifier","sortingDetails","addUid","columnWise","retObj","uids","reqSorting","tmpDataArr","colName","insertInd","dataObj","fieldName","sortMeta","fDetails","fieldInSchema","sortingFn","slice","f","data_builder_toConsumableArray","pop","sortData","tmpData","difference","hashTable","schemaNameArr","dm1FieldStoreFieldObj","dm2FieldStoreFieldObj","_colIdentifier","prepareDataHelper","dm","addData","hashData","schemaName","getFilteredValues","filter","sum","filteredNumber","curr","avg","totalSum","isNaN","fnList","_defineProperty","_fnList","filteredValues","min","group_by_function_toConsumableArray","max","sqrt","mean","num","pow","variance","defaultReducerName","ReducerStore","_this","reducer_store_classCallCheck","defReducer","entries","reducer","_this2","__unregister","delete","reducerStore","groupBy","dataModel","reducers","existingDataModel","sFieldArr","dimensions","_ref","group_by_slicedToArray","getFieldArr","reducerObj","measures","defaultReducer","measureName","defAggFn","reducerFn","resolve","getReducerObj","fieldStoreObj","dbName","dimensionArr","measureArr","newDataModel","_ref3","_ref4","rowCount","hash","_","cachedStore","cloneProvider","row","__calculateFieldspace","naturalJoinFilter","commonSchemaArr","retainTuple","union","leftOuterJoin","dataModel1","dataModel2","rightOuterJoin","Field","field_classCallCheck","subtype","description","displayName","Dimension","_cachedDomain","calculateDataDomain","Categorical","Set","domain","add","Temporal","temporal_classCallCheck","temporal_possibleConstructorReturn","__proto__","getPrototypeOf","_cachedMinDiff","sortedData","arrLn","minDiff","POSITIVE_INFINITY","prevDatum","nextDatum","processedCount","_this3","Binned","binsArr","bins","Measure","unit","numberFormat","Continuous","NEGATIVE_INFINITY","FieldParser","CategoricalParser","isInvalid","getInvalidType","trim","TemporalParser","temporal_parser_classCallCheck","temporal_parser_possibleConstructorReturn","_dtf","BinnedParser","matched","parseFloat","ContinuousParser","PartialField","partial_field_classCallCheck","_sanitize","createFields","dataColumn","headers","headersObj","header","createUnitField","default_config","dataFormat","DSVArr","firstRowHeader","columns","columnMajor","EOL","EOF","QUOTE","NEWLINE","RETURN","objectConverter","JSON","stringify","inferColumns","rows","columnSet","column","width","formatDate","getUTCHours","minutes","getUTCMinutes","seconds","getUTCSeconds","milliseconds","getUTCMilliseconds","getUTCFullYear","getUTCMonth","getUTCDate","src_dsv","delimiter","reFormat","DELIMITER","charCodeAt","parseRows","N","I","eof","eol","j","preformatBody","formatValue","formatRow","test","convert","customConverter","formatBody","formatRows","csv","dsv","tsv","DSVStr","fieldSeparator","d3Dsv","FlatJSON","insertionIndex","Auto","converters","prepareSelectionData","resp","_iteratorNormalCompletion","_didIteratorError","_iteratorError","_step","_iterator","iterator","done","err","return","updateFields","partialFieldspace","fieldStoreName","_ref2","helper_slicedToArray","collID","partialFieldMap","newFields","coll","createUnitFieldFromPartial","persistDerivations","sourceDm","model","operation","_model$_derivation","criteriaFn","_derivation","src_helper_toConsumableArray","op","meta","criteria","persistCurrentDerivation","newDm","_newDm$_ancestorDeriv","_ancestorDerivation","persistAncestorDerivation","selectModeMap","diffIndex","calcDiff","helper_defineProperty","_selectModeMap","generateRowDiffset","lastInsertedValue","li","selectRowDiffsetIterator","checker","newRowDiffSet","rejRowDiffSet","_selectModeMap$mode$c","shouldSelect","shouldReject","checkerResult","rejectRowDiffset","selectHelper","clonedDm","selectFn","getPartialFieldspace","getKey","fn","filterPropagationModel","propModels","fns","filterByMeasure","clonedModel","clone","calculateFieldsConfig","cloneWithAllFields","modelFieldsConfig","getFieldsConfig","propModel","keyFn","getData","fieldsConfig","dLen","indices","fieldsSpace","v","valuesMap","present","every","select","saveChild","some","splitWithSelect","_selectHelper","params","splitRowDiffset","dimensionMap","dimensionSet","rowSplitDiffsetIterator","clonedDMs","cloned","derivation","addDiffsetToClonedDm","selectConfig","cloneWithProject","projField","allFields","projectionSet","actualProjField","sanitizeUnitSchema","unitSchema","sanitizeAndValidateSchema","supportedMeasureSubTypes","supportedDimSubTypes","validateUnitSchema","updateData","relation","defaultConfig","converterFn","converter","_converterFn","_converterFn2","formattedData","dataHeader","fieldNameAs","as","resolveFieldName","nameSpace","_partialFieldspace","valueObjects","_cachedValueObjects","_dataFormat","applyExistingOperationOnModel","derivations","getDerivations","selectionModel","_selectionModel","_getDerivationArgumen","groupByString","getDerivationArguments","propagateIdentifiers","propModelInf","nonTraversingModel","excludeModels","handlePropagation","_children","child","getPathToRootModel","path","_parent","propagateToAllDataModels","identifiers","rootModels","propagationInf","propagationNameSpace","propagateToSource","propagationSourceId","sourceId","propagateInterpolatedValues","criterias","persistent","actionCriterias","values","mutableActions","filteredCriteria","entry","action","sourceActionCriterias","actionInf","actionConf","applyOnSource","models","rootModel","propConfig","sourceIdentifiers","rootGroupByModel","groupByModel","inf","propagationModel","filteredModel","getFilteredModel","reverse","getNormalizedProFields","fieldConfig","normalizedProjField","constructor","search","Relation","relation_classCallCheck","source","_fieldStoreName","_propagationNameSpace","immutableActions","_fieldspace","joinWith","unionWith","differenceWith","defConfig","cloneConfig","extraCloneDm","setOfRowDiffsets","cloneWithSelect","setParent","_fieldConfig","fieldObj","def","removeChild","findIndex","sibling","parent","datamodel_classCallCheck","datamodel_possibleConstructorReturn","_onPropagation","order","withUid","getAllFields","dataGenerated","fieldNames","fmtFieldIdx","elem","fIdx","fmtFn","datumIdx","ids","_set$split$map","_set$split$map2","datamodel_slicedToArray","datamodel_toConsumableArray","fill","fieldsArr","rawData","dataInCSVArr","sortedDm","colData","rowsCount","serializedData","rowIdx","colIdx","cachedValueObjects","fieldinst","dependency","replaceVar","depVars","retrieveFn","depFieldIndices","fieldSpec","fs","suppliedFields","computedValues","fieldsData","_createFields","addField","addToNameSpace","isMutableAction","payload","getRootDataModel","find","getRootGroupByModel","sourceNamespace","addToPropNamespace","filterImmutableAction","criteriaModel","propagateImmutableActions","eventName","measureFieldName","binFieldName","_createBinnedFieldDat","measureField","binsCount","_measureField$domain","_measureField$domain2","_slicedToArray","dMin","dMax","ceil","abs","binnedData","createBinnedFieldData","binField","serialize","getSchema","uniqueFields","commonFields","normalizedProjFieldSets","fieldSet","projFieldSet","projFields","splitWithProject","first","last","count","sd","std","Operators","compose","_len5","operations","_key5","currentDM","firstChild","compose_toConsumableArray","dispose","bin","_len3","_key3","project","_len2","_key2","_len4","_key4","calculateVariable","naturalJoin","fullOuterJoin","version","Stats","enums"],"mappings":"CAAA,SAAAA,EAAAC,GACA,iBAAAC,SAAA,iBAAAC,OACAA,OAAAD,QAAAD,IACA,mBAAAG,eAAAC,IACAD,OAAA,eAAAH,GACA,iBAAAC,QACAA,QAAA,UAAAD,IAEAD,EAAA,UAAAC,IARA,CASCK,OAAA,WACD,mBCTA,IAAAC,EAAA,GAGA,SAAAC,EAAAC,GAGA,GAAAF,EAAAE,GACA,OAAAF,EAAAE,GAAAP,QAGA,IAAAC,EAAAI,EAAAE,GAAA,CACAC,EAAAD,EACAE,GAAA,EACAT,QAAA,IAUA,OANAU,EAAAH,GAAAI,KAAAV,EAAAD,QAAAC,IAAAD,QAAAM,GAGAL,EAAAQ,GAAA,EAGAR,EAAAD,QA0DA,OArDAM,EAAAM,EAAAF,EAGAJ,EAAAO,EAAAR,EAGAC,EAAAQ,EAAA,SAAAd,EAAAe,EAAAC,GACAV,EAAAW,EAAAjB,EAAAe,IACAG,OAAAC,eAAAnB,EAAAe,EAAA,CAA0CK,YAAA,EAAAC,IAAAL,KAK1CV,EAAAgB,EAAA,SAAAtB,GACA,oBAAAuB,eAAAC,aACAN,OAAAC,eAAAnB,EAAAuB,OAAAC,YAAA,CAAwDC,MAAA,WAExDP,OAAAC,eAAAnB,EAAA,cAAiDyB,OAAA,KAQjDnB,EAAAoB,EAAA,SAAAD,EAAAE,GAEA,GADA,EAAAA,IAAAF,EAAAnB,EAAAmB,IACA,EAAAE,EAAA,OAAAF,EACA,KAAAE,GAAA,iBAAAF,QAAAG,WAAA,OAAAH,EACA,IAAAI,EAAAX,OAAAY,OAAA,MAGA,GAFAxB,EAAAgB,EAAAO,GACAX,OAAAC,eAAAU,EAAA,WAAyCT,YAAA,EAAAK,UACzC,EAAAE,GAAA,iBAAAF,EAAA,QAAAM,KAAAN,EAAAnB,EAAAQ,EAAAe,EAAAE,EAAA,SAAAA,GAAgH,OAAAN,EAAAM,IAAqBC,KAAA,KAAAD,IACrI,OAAAF,GAIAvB,EAAA2B,EAAA,SAAAhC,GACA,IAAAe,EAAAf,KAAA2B,WACA,WAA2B,OAAA3B,EAAA,SAC3B,WAAiC,OAAAA,GAEjC,OADAK,EAAAQ,EAAAE,EAAA,IAAAA,GACAA,GAIAV,EAAAW,EAAA,SAAAiB,EAAAC,GAAsD,OAAAjB,OAAAkB,UAAAC,eAAA1B,KAAAuB,EAAAC,IAGtD7B,EAAAgC,EAAA,GAIAhC,IAAAiC,EAAA,k+DClFA,IAAMC,EAAYC,EAAQ,GAE1BxC,EAAOD,QAAUwC,EAAUE,QAAUF,EAAUE,QAAUF,qxBCKzD,IAOeG,EAPI,CACfC,UAAW,WACXC,QAAS,SACTC,QAAS,SACTC,KAAM,QCEKC,EAPU,CACrBC,YAAa,cACbC,SAAU,WACVC,IAAK,MACLC,OAAQ,UCAGC,EAJQ,CACnBC,WAAY,cCKDC,EALG,CACdC,QAAS,UACTC,UAAW,aCGAC,EANO,CAClBC,OAAQ,SACRC,QAAS,UACTC,IAAK,OCQMC,EAXY,CACvBC,IAAK,MACLC,IAAK,MACLC,IAAK,MACLC,IAAK,MACLC,MAAO,QACPC,KAAM,OACNC,MAAO,QACPC,IAAK,OCRT,SAASC,EAAqBC,GAC1B,OAAIA,aAAgBC,KACTD,EAGJ,IAAIC,KAAKD,GASpB,SAASE,EAAKzC,GACV,OAAQA,EAAI,GAAL,IAAgBA,EAAOA,EA8BP,SAAS0C,EAAmBC,GACnDC,KAAKD,OAASA,EACdC,KAAKC,cAAWC,EAChBF,KAAKG,gBAAaD,EAftBE,OAAOC,OAAS,SAAUC,GACtB,OAAOA,EAAKC,QAAQ,2BAA4B,SAkBpDT,EAAkBU,aAAe,IAIjCV,EAAkBW,wBAA0B,CACxCC,KAAM,EACNC,MAAO,EACPC,IAAK,EACLC,KAAM,EACNC,OAAQ,EACRC,OAAQ,EACRC,YAAa,GAUjBlB,EAAkBmB,oBAAsB,SAAUC,GAC9C,OAAO,SAAUC,GACb,IAAIC,EACJ,OAAIC,SAASD,EAAYE,SAASH,EAAK,KAC5BC,EAGJF,IAYfpB,EAAkByB,mBAAqB,SAAUC,EAAON,GACpD,OAAO,SAACC,GACJ,IACIvF,EADAD,SAGJ,IAAKwF,EAAO,OAAOD,EAEnB,IAAMO,EAAON,EAAIO,cAEjB,IAAK/F,EAAI,EAAGC,EAAI4F,EAAMG,OAAQhG,EAAIC,EAAGD,IACjC,GAAI6F,EAAM7F,GAAG+F,gBAAkBD,EAC3B,OAAO9F,EAIf,YAAUuE,IAANvE,EACOuF,EAEJ,OAqBfpB,EAAkB8B,oBAAsB,WACpC,IAAMC,EAAU,CACZC,MAAO,CACH,MACA,MACA,MACA,MACA,MACA,MACA,OAEJC,KAAM,CACF,SACA,SACA,UACA,YACA,WACA,SACA,aAGFC,EAAY,CACdF,MAAO,CACH,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OAEJC,KAAM,CACF,UACA,WACA,QACA,QACA,MACA,OACA,OACA,SACA,YACA,UACA,WACA,aAsPR,MAlPoB,CAChBE,EAAG,CAEC/F,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAGP,OAFUzB,EAAoByB,GAErBmB,WAAWC,aAG5B3G,EAAG,CAECM,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GACP,IACMqB,EADI9C,EAAoByB,GACdmB,WAAa,GAE7B,OAAkB,IAAVE,EAAc,GAAKA,GAAOD,aAG1C9E,EAAG,CAECvB,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,WACpBC,OAAQ,SAACjB,GACL,OAAIA,EACOA,EAAIO,cAER,MAEXW,UAAW,SAAClB,GAIR,OAHUzB,EAAoByB,GACdmB,WAEA,GAAK,KAAO,OAGpCG,EAAG,CAECvG,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,WACpBC,OAAQ,SAACjB,GACL,OAAIA,EACOA,EAAIO,cAER,MAEXW,UAAW,SAAClB,GAIR,OAHUzB,EAAoByB,GACdmB,WAEA,GAAK,KAAO,OAGpCI,EAAG,CAECxG,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GACfwB,gBAKvBC,EAAG,CAEC1G,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GACZ0B,gBAK1BC,EAAG,CAEC5G,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAHUzB,EAAoByB,GACjB4B,kBAEHR,aAGlBS,EAAG,CAEC9G,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,UAAWN,EAAQC,MAAMmB,KAAK,KAA9B,KACbb,OAAQtC,EAAkByB,mBAAmBM,EAAQC,OACrDO,UAND,SAMYlB,GACP,IACM+B,EADIxD,EAAoByB,GAChBgC,SAEd,OAAQtB,EAAQC,MAAMoB,GAAMX,aAGpCa,EAAG,CAEClH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,UAAWN,EAAQE,KAAKkB,KAAK,KAA7B,KACbb,OAAQtC,EAAkByB,mBAAmBM,EAAQE,MACrDM,UAND,SAMYlB,GACP,IACM+B,EADIxD,EAAoByB,GAChBgC,SAEd,OAAQtB,EAAQE,KAAKmB,GAAMX,aAGnCc,EAAG,CAECnH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAHUzB,EAAoByB,GAChBmC,UAEHf,aAGnBtG,EAAG,CAECC,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GAChBmC,aAKtBC,EAAG,CAECrH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,UAAWH,EAAUF,MAAMmB,KAAK,KAAhC,KACbb,OAAQtC,EAAkByB,mBAAmBS,EAAUF,OACvDO,UAND,SAMYlB,GACP,IACMqC,EADI9D,EAAoByB,GACdsC,WAEhB,OAAQzB,EAAUF,MAAM0B,GAAQjB,aAGxCmB,EAAG,CAECxH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,UAAWH,EAAUD,KAAKkB,KAAK,KAA/B,KACbb,OAAQtC,EAAkByB,mBAAmBS,EAAUD,MACvDM,UAND,SAMYlB,GACP,IACMqC,EADI9D,EAAoByB,GACdsC,WAEhB,OAAQzB,EAAUD,KAAKyB,GAAQjB,aAGvCxG,EAAG,CAECG,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OALD,SAKSjB,GAAO,OAAOrB,EAAkBmB,qBAAlBnB,CAAwCqB,GAAO,GACrEkB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GACdsC,WAEG,KAG3BE,EAAG,CAECzH,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,YACpBC,OALD,SAKSjB,GACJ,IAAIyC,SACJ,GAAIzC,EAAK,CACL,IAAMvF,EAAIuF,EAAIQ,OACdR,EAAMA,EAAI0C,UAAUjI,EAAI,EAAGA,GAE/B,IAAIwF,EAAYtB,EAAkBmB,qBAAlBnB,CAAwCqB,GACpD2C,EAAc,IAAIlE,KAClBmE,EAAcC,KAAKC,MAAOH,EAAYI,cAAiB,KAO3D,OAHIxE,EAFJkE,KAAYG,EAAc3C,GAEM8C,cAAgBJ,EAAYI,gBACxDN,MAAYG,EAAc,GAAI3C,GAE3B1B,EAAoBkE,GAAQM,eAEvC7B,UAtBD,SAsBYlB,GACP,IACIgD,EADMzE,EAAoByB,GACjB+C,cAAc3B,WACvB3G,SAOJ,OALIuI,IACAvI,EAAIuI,EAAKxC,OACTwC,EAAOA,EAAKN,UAAUjI,EAAI,EAAGA,IAG1BuI,IAGfC,EAAG,CAEClI,KAAM,IACNgG,MAAO,EACPC,QAJD,WAIc,MAAO,YACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAHUzB,EAAoByB,GACf+C,cAAc3B,eAgB7CzC,EAAkBuE,oBAAsB,WACpC,IAAMC,EAAcxE,EAAkB8B,sBAEtC,MAAO,CACHf,KAAMyD,EAAYrC,EAClBsC,QAASD,EAAY1I,EACrB4I,eAAgBF,EAAY7G,EAC5BgH,eAAgBH,EAAY7B,EAC5B3B,OAAQwD,EAAY5B,EACpB3B,OAAQuD,EAAY1B,EACpB8B,UAAWJ,EAAYtB,EACvB2B,SAAUL,EAAYlB,EACtBwB,aAAcN,EAAYjB,EAC1BwB,4BAA6BP,EAAYrI,EACzC6I,YAAaR,EAAYf,EACzBwB,WAAYT,EAAYZ,EACxBsB,cAAeV,EAAYvI,EAC3BkJ,WAAYX,EAAYX,EACxBuB,UAAWZ,EAAYF,IAW/BtE,EAAkBqF,cAAgB,WAC9B,IAAMb,EAAcxE,EAAkB8B,sBAChCwD,EAAkB,WAMpB,IALA,IAAIzJ,EAAI,EACJ0J,SACAC,SACE1J,EAAI2J,UAAK5D,OAERhG,EAAIC,EAAGD,IACV0J,oBAAW1J,OAAXuE,EAAAqF,UAAW5J,IACX4J,UAAA5D,QAAShG,OAATuE,EAAAqF,UAAS5J,MACL2J,EAAcD,GAItB,OAAKC,EAEEA,EAAY,GAAGlD,OAAOkD,EAAY,IAFd,MAK/B,MAAO,CACH5E,KAAM,CAAC4D,EAAYX,EAAGW,EAAYF,EAC9BgB,GAEJzE,MAAO,CAAC2D,EAAYf,EAAGe,EAAYZ,EAAGY,EAAYvI,EAC9CqJ,GAEJxE,IAAK,CAAC0D,EAAYtB,EAAGsB,EAAYlB,EAAGkB,EAAYjB,EAAGiB,EAAYrI,EAC3DmJ,GAEJvE,KAAM,CAACyD,EAAYrC,EAAGqC,EAAY1I,EAAG0I,EAAY7G,EAAG6G,EAAY7B,EAC5D,SAAU+C,EAAcC,EAAcC,EAAWC,GAC7C,IAAIL,SACAM,SACAC,SACA1E,SAcJ,OAZIsE,IAAiBG,EAAUF,GAAaC,IACJ,OAAhCC,EAAO,GAAGxD,OAAOwD,EAAO,MACxBC,GAAO,GAGXP,EAAcG,GAEdH,EADOG,GAGOD,EAGbF,GAELnE,EAAMmE,EAAY,GAAGlD,OAAOkD,EAAY,IACpCO,IACA1E,GAAO,IAEJA,GANoB,OASnCL,OAAQ,CAACwD,EAAY5B,EACjB0C,GAEJrE,OAAQ,CAACuD,EAAY1B,EACjBwC,KAUZtF,EAAkBgG,WAAa,SAAU/F,GAQrC,IAPA,IAAMgG,EAAcjG,EAAkBU,aAChC8D,EAAcxE,EAAkB8B,sBAChCoE,EAAgB3J,OAAO4J,KAAK3B,GAC5B4B,EAAa,GACfvK,SACAwK,UAEIxK,EAAIoE,EAAOqG,QAAQL,EAAapK,EAAI,KAAO,GAC/CwK,EAAcpG,EAAOpE,EAAI,IACmB,IAAxCqK,EAAcI,QAAQD,IAE1BD,EAAWG,KAAK,CACZnE,MAAOvG,EACP2K,MAAOH,IAIf,OAAOD,GASXpG,EAAkByG,SAAW,SAAU5G,EAAMI,GACzC,IAQInE,EARE4K,EAAQ9G,EAAoBC,GAC5BuG,EAAapG,EAAkBgG,WAAW/F,GAC1CuE,EAAcxE,EAAkB8B,sBAClC6E,EAAeC,OAAO3G,GACpBgG,EAAcjG,EAAkBU,aAClC8F,SACAK,SACAhL,SAGJ,IAAKA,EAAI,EAAGC,EAAIsK,EAAWvE,OAAQhG,EAAIC,EAAGD,IAEtCgL,EAAerC,EADfgC,EAAQJ,EAAWvK,GAAG2K,OACYjE,UAAUmE,GAC5CC,EAAeA,EAAalG,QAAQ,IAAIH,OAAO2F,EAAcO,EAAO,KAAMK,GAG9E,OAAOF,GAQX3G,EAAkBvC,UAAUqJ,MAAQ,SAAUC,EAAeC,GACzD,IAAM3B,EAAgBrF,EAAkBqF,gBAClClF,EAAWD,KAAK+G,kBAAkBF,GAClCG,EAAalH,EAAkBW,wBAC/BwG,EAAUH,GAAWA,EAAQG,QAC7BC,EAAa,GACbC,EAAO,GACTC,SACAC,SACAC,SACAnG,SACAxF,SACA4L,SACAC,SACA5L,SACAgI,EAAS,GAEb,IAAKwD,KAAejC,EAChB,GAAK,GAAG3H,eAAe1B,KAAKqJ,EAAeiC,GAA3C,CAMA,IAJAD,EAAKxF,OAAS,EAEd2F,GADAD,EAAiBlC,EAAciC,IACHK,OAAOJ,EAAe1F,OAAS,EAAG,GAAG,GAE5DhG,EAAI,EAAGC,EAAIyL,EAAe1F,OAAQhG,EAAIC,EAAGD,SAI9BuE,KAFZiB,EAAMlB,GADNsH,EAAQF,EAAe1L,IACFO,OAGjBiL,EAAKd,KAAK,MAEVc,EAAKd,KAAK,CAACkB,EAAOpG,IAM1B,GAAI,OAFJqG,EAAcF,EAAWI,MAAM1H,KAAMmH,MAEuBF,EACxD,MAGJC,EAAWF,EAAWI,IAAgBI,EAU1C,OAPIN,EAAWvF,QAAU3B,KAAK2H,gBAAgBT,EAAWvF,QAErDiC,EAAOgE,QAAQV,EAAW,GAAI,EAAG,GAEjCtD,EAAOgE,QAAPF,MAAA9D,EAAkBsD,GAGftD,GAQX9D,EAAkBvC,UAAUwJ,kBAAoB,SAAUF,GACtD,IAYIjL,EAZEmE,EAASC,KAAKD,OACduE,EAAcxE,EAAkB8B,sBAChCmE,EAAcjG,EAAkBU,aAChC0F,EAAapG,EAAkBgG,WAAW/F,GAC1C8H,EAAW,GAEbC,SACAC,SACAC,SACAC,SACAC,SAGAvM,SAEJuM,EAAcxB,OAAO3G,GAErB,IAAMoI,EAAWjC,EAAWkC,IAAI,SAAAC,GAAA,OAAOA,EAAI/B,QACrCgC,EAAmBpC,EAAWvE,OACpC,IAAKhG,EAAI2M,EAAmB,EAAG3M,GAAK,EAAGA,KACnCqM,EAAW9B,EAAWvK,GAAGuG,OAEV,IAAMgG,EAAYvG,OAAS,QAKdzB,IAAxB4H,IACAA,EAAsBI,EAAYvG,QAGtCsG,EAAaC,EAAYrE,UAAUmE,EAAW,EAAGF,GACjDI,EAAcA,EAAYrE,UAAU,EAAGmE,EAAW,GAC9C5H,OAAOC,OAAO4H,GACdC,EAAYrE,UAAUiE,EAAqBI,EAAYvG,QAE3DmG,EAAsBE,GAblBF,EAAsBE,EAgB9B,IAAKrM,EAAI,EAAGA,EAAI2M,EAAkB3M,IAC9BoM,EAAS7B,EAAWvK,GACpBuM,EAAcA,EAAY3H,QAAQwF,EAAcgC,EAAOzB,MAAOhC,EAAYyD,EAAOzB,OAAOnE,WAG5F,IAAMoG,EAAgB1B,EAAc2B,MAAM,IAAIpI,OAAO8H,KAAiB,GAGtE,IAFAK,EAAcE,QAET9M,EAAI,EAAGC,EAAIuM,EAASxG,OAAQhG,EAAIC,EAAGD,IACpCkM,EAASM,EAASxM,IAAM4M,EAAc5M,GAE1C,OAAOkM,GAQX/H,EAAkBvC,UAAUmL,cAAgB,SAAU7B,GAClD,IAAIlH,EAAO,KACX,GAAIgJ,OAAOtH,SAASwF,GAChBlH,EAAO,IAAIC,KAAKiH,QACb,IAAK7G,KAAKD,QAAUH,KAAKgH,MAAMC,GAClClH,EAAO,IAAIC,KAAKiH,OAEf,CACD,IAAM5G,EAAWD,KAAKC,SAAWD,KAAK4G,MAAMC,GACxC5G,EAAS0B,SACT3B,KAAKG,WAAL,IAAAyI,SAAArL,UAAAJ,KAAAuK,MAAsB9H,KAAtB,OAAAiJ,6HAAAC,CAA8B7I,MAC9BN,EAAOK,KAAKG,YAGpB,OAAOR,GAGXG,EAAkBvC,UAAUoK,gBAAkB,SAASoB,GACnD,OAAe,IAARA,GAAa/I,KAAKD,OAAOyI,MAAM,QAAQ7G,QASlD7B,EAAkBvC,UAAUgJ,SAAW,SAAUxG,EAAQ8G,GACrD,IAAI1G,SAQJ,OANI0G,EACA1G,EAAaH,KAAKG,WAAaH,KAAK0I,cAAc7B,IACzC1G,EAAaH,KAAKG,cAC3BA,EAAaH,KAAK0I,cAAc7B,IAG7B/G,EAAkByG,SAASpG,EAAYJ,ICruBnC,IAAAiJ,EAAA,SAACC,GACZ,IAAItN,EAAI,EACR,OAAO,WAAe,QAAAuN,EAAA3D,UAAA5D,OAAXwH,EAAWC,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAXF,EAAWE,GAAA9D,UAAA8D,GAClBF,EAAOG,QAAQ,SAACnI,EAAKoI,GACXN,EAAMM,aAAuBH,QAC/BH,EAAMM,GAAcH,MAAMI,KAAK,CAAE7H,OAAQhG,KAE7CsN,EAAMM,GAAYlD,KAAKlF,KAE3BxF,kNCdF8N,EAAe,SACfC,EAAgBrN,OAAOkB,UAAUgF,SACjCoH,EAAc,kBACdC,EAAa,iBAEnB,SAASC,EAAexB,EAAKyB,GAIzB,IAHA,IAAInO,EAAImO,EAAUnI,OACdoI,GAAU,EAEPpO,GAAG,CACN,GAAI0M,IAAQyB,EAAUnO,GAElB,OADAoO,EAASpO,EAGbA,GAAK,EAGT,OAAOoO,EA2GX,SAASC,EAASC,EAAMC,EAAMC,GAE1B,YAAI,IAAOF,EAAP,YAAAG,EAAOH,MAASR,SAAgB,IAAOS,EAAP,YAAAE,EAAOF,MAAST,EACzC,WAGP,IAAOS,EAAP,YAAAE,EAAOF,MAAST,GAAyB,OAATS,EACzBD,SAGP,IAAOA,EAAP,YAAAG,EAAOH,MAASR,IAChBQ,EAAOC,aAAgBd,MAAQ,GAAK,IAnH5C,SAASiB,EAAMJ,EAAMC,EAAMC,EAAWG,EAAQC,GAC1C,IAAIC,EACAC,EACAC,EACAC,EACAC,EAcJ,GATKL,GAKDD,EAAOjE,KAAK4D,GACZM,EAAOlE,KAAK6D,KALZI,EAAS,CAACL,GACVM,EAAS,CAACL,IAOVA,aAAgBd,MAChB,IAAKoB,EAAO,EAAGA,EAAON,EAAKvI,OAAQ6I,GAAQ,EAAG,CAC1C,IACIC,EAASR,EAAKO,GACdE,EAASR,EAAKM,GAElB,MAAOnH,GACH,eAGA,IAAOqH,EAAP,YAAAN,EAAOM,MAAWjB,EACZU,QAAwBjK,IAAXwK,IACfT,EAAKO,GAAQE,IAIF,OAAXD,SAAmB,IAAOA,EAAP,YAAAL,EAAOK,MAAWhB,IACrCgB,EAASR,EAAKO,GAAQE,aAAkBtB,MAAQ,GAAK,KAG3C,KADdwB,EAAOf,EAAea,EAAQH,IAE1BE,EAASR,EAAKO,GAAQF,EAAOM,GAG7BP,EAAMI,EAAQC,EAAQP,EAAWG,EAAQC,SAMrD,IAAKC,KAAQN,EAAM,CACf,IACIO,EAASR,EAAKO,GACdE,EAASR,EAAKM,GAElB,MAAOnH,GACH,SAGJ,GAAe,OAAXqH,SAAmB,IAAOA,EAAP,YAAAN,EAAOM,MAAWjB,GAKrCkB,EAAMjB,EAAc5N,KAAK4O,MACbf,GACO,OAAXc,SAAmB,IAAOA,EAAP,YAAAL,EAAOK,MAAWhB,IACrCgB,EAASR,EAAKO,GAAQ,KAGZ,KADdI,EAAOf,EAAea,EAAQH,IAE1BE,EAASR,EAAKO,GAAQF,EAAOM,GAG7BP,EAAMI,EAAQC,EAAQP,EAAWG,EAAQC,IAGxCI,IAAQf,GACE,OAAXa,GAAqBA,aAAkBrB,QACvCqB,EAASR,EAAKO,GAAQ,KAGZ,KADdI,EAAOf,EAAea,EAAQH,IAE1BE,EAASR,EAAKO,GAAQF,EAAOM,GAG7BP,EAAMI,EAAQC,EAAQP,EAAWG,EAAQC,IAI7CN,EAAKO,GAAQE,MAGhB,CACD,GAAIP,QAAwBjK,IAAXwK,EACb,SAEJT,EAAKO,GAAQE,GAIzB,OAAOT,EAiBPI,CAAMJ,EAAMC,EAAMC,GACXF,GCnIJ,SAASY,EAAS1J,GACrB,OAAOiI,MAAMyB,QAAQ1J,GA2ClB,IAAM2J,EAAc,wBAAY,IAAIlL,MAAOmL,UAAY/G,KAAKgH,MAAsB,IAAhBhH,KAAKiH,WASvE,SAASC,EAAWC,EAAMC,GAC7B,IAAKP,EAAQM,KAAUN,EAAQO,GAC3B,OAAOD,IAASC,EAGpB,GAAID,EAAKxJ,SAAWyJ,EAAKzJ,OACrB,OAAO,EAGX,IAAK,IAAIhG,EAAI,EAAGA,EAAIwP,EAAKxJ,OAAQhG,IAC7B,GAAIwP,EAAKxP,KAAOyP,EAAKzP,GACjB,OAAO,EAIf,OAAO,EASJ,SAAS0P,EAAalK,GACzB,OAAOA,EASJ,IAAMmK,EAAmB,SAACC,GAC7B,MAnEsB,iBAmETA,EACFzN,EAAWE,QACX6M,EAAQU,IAASV,EAAQU,EAAK,IAC9BzN,EAAWG,QACX4M,EAAQU,KAA0B,IAAhBA,EAAK5J,QAlF/B,SAAmBR,GACtB,OAAOA,IAAQ9E,OAAO8E,GAiF4BqK,CAASD,EAAK,KACrDzN,EAAWC,UAEf,MChDI0N,EApDI,CACfF,KAAM,GAENG,gBAHe,SAGEC,EAAUzP,GACvB,IAAM0P,EAAS1P,GAAQ4O,IA4CvB,OA1CA9K,KAAKuL,KAAKK,GAAU,CAChB1P,KAAM0P,EACNzC,OAAQwC,EAERE,UAJgB,WAKZ,IAAIA,EAAY7L,KAAK8L,iBAQrB,OANKD,IACDA,EAAY7L,KAAK8L,iBAAmB,GACpC9L,KAAKmJ,OAAOG,QAAQ,SAACyC,GACjBF,EAAUE,EAAM7P,QAAU6P,KAG3BF,GAEXG,WAfgB,WAgBZ,IAAIC,EAAgBjM,KAAKkM,eAUzB,OARKD,IACDA,EAAgBjM,KAAKkM,eAAiB,GACtClM,KAAKmJ,OAAOG,QAAQ,SAACyC,GACbA,EAAMI,SAASC,OAAS1N,EAAUC,UAClCsN,EAAcF,EAAM7P,QAAU6P,MAInCE,GAEXI,aA5BgB,WA6BZ,IAAIC,EAAkBtM,KAAKuM,iBAU3B,OARKvM,KAAKuM,mBACND,EAAkBtM,KAAKuM,iBAAmB,GAC1CvM,KAAKmJ,OAAOG,QAAQ,SAACyC,GACbA,EAAMI,SAASC,OAAS1N,EAAUE,YAClC0N,EAAgBP,EAAM7P,QAAU6P,MAIrCO,IAGRtM,KAAKuL,KAAKK,8PCKVY,aA1CX,SAAAA,EAAarL,EAAK4K,gGAAOU,CAAAzM,KAAAwM,GACrBnQ,OAAOC,eAAe0D,KAAM,SAAU,CAClCzD,YAAY,EACZmQ,cAAc,EACdC,UAAU,EACV/P,MAAOuE,IAGXnB,KAAK+L,MAAQA,+CAoBb,OAAOrF,OAAO1G,KAAKpD,yCAUnB,OAAOoD,KAAKpD,oCArBZ,OAAOoD,KAAK4M,gBCxBb,SAASC,EAAoBC,EAAYC,GACxCD,EAAWnL,OAAS,GACDmL,EAAWE,MAAM,KACzB1D,QAAQ,SAAC2D,GAChB,IAAMC,EAAaD,EAAQD,MAAM,KAC3BG,GAAUD,EAAW,GACrBE,IAAQF,EAAW,IAAMA,EAAW,IAC1C,GAAIE,GAAOD,EACP,IAAK,IAAIxR,EAAIwR,EAAOxR,GAAKyR,EAAKzR,GAAK,EAC/BoR,EAASpR,kQCVvB0R,aAqBF,SAAAA,EAAazQ,gGAAO0Q,CAAAtN,KAAAqN,GAChBrN,KAAK4M,OAAShQ,0DAdO2Q,GACrB,OAAKA,EAGElR,OAAOmR,OAAOH,EAAkBI,qBAAsBF,GAFlDF,EAAkBI,4DAsB7B,OAAOzN,KAAK4M,0CAUZ,OAAOlG,OAAO1G,KAAK4M,4CAGNzL,GACb,OAAQA,aAAekM,KAAwBA,EAAkBK,mBAAmBvM,0CAGlEA,GAClB,OAAOA,aAAekM,EAAoBlM,EAAMkM,EAAkBK,mBAAmBvM,YAO7FkM,EAAkBM,KAAO,IAAIN,EAAkB,QAC/CA,EAAkBO,GAAK,IAAIP,EAAkB,MAC7CA,EAAkBQ,IAAM,IAAIR,EAAkB,OAO9CA,EAAkBI,qBAAuB,CACrCK,QAAST,EAAkBO,GAC3BG,IAAKV,EAAkBQ,IACvBG,KAAMX,EAAkBM,KACxBzN,UAAWmN,EAAkBO,IAGlBP,2aC5ETY,EAAkB,SAACC,EAASf,EAAOC,GAIrC,IAHA,IAAMe,EAAU,GACZC,EAAOjB,EAEJiB,EAAOhB,GACVe,EAAQ9H,KAAK+H,GACbA,GAAQF,EAIZ,OAFAC,EAAQ9H,KAAK+H,GAEND,GAGLE,EAAkB,SAACC,EAAc1R,GAOnC,IANA,IAAI2R,EAAU,EACVC,EAAWF,EAAa3M,OAAS,EACjC8M,SACAjN,SAGG+M,GAAWC,GAAU,CAIxB,GAAI5R,IAFJ4E,EAAQ8M,EADRG,EAASF,EAAUvK,KAAK0K,OAAOF,EAAWD,GAAW,KAGlCpB,OAASvQ,EAAQ4E,EAAM4L,IACtC,OAAO5L,EACA5E,GAAS4E,EAAM4L,IACtBmB,EAAUE,EAAS,EACZ7R,EAAQ4E,EAAM2L,QACrBqB,EAAWC,EAAS,GAI5B,OAAO,MChCJ,IAUME,EAAiB,CAC1BC,OAAQ,SACRC,QAAS,UACTC,QAAS,QACTC,QAAS,UACTC,QAAS,qBACTC,IAAK,MACLC,KAAM,QAGGC,EAAQ,CACjBC,MAAO,QACPC,UAAW,YACXC,WAAY,aACZC,QAAS,UACTC,UAAW,aAGFC,EACJ,MC0BF,MCnDA,SAASC,EAAiBC,EAAKC,GAClC,IAAMC,EAAS,GACTC,EAAS,GASf,OARAH,EAAIxG,OAAOG,QAAQ,SAACyC,GAChB+D,EAAOzJ,KAAK0F,EAAMI,SAASjQ,QAE/B0T,EAAIzG,OAAOG,QAAQ,SAACyC,IAC6B,IAAzC+D,EAAO1J,QAAQ2F,EAAMI,SAASjQ,OAC9B2T,EAAOxJ,KAAK0F,EAAMI,SAASjQ,QAG5B2T,ECRX,SAASE,IAAoB,OAAO,EAY7B,SAASC,EAAcC,EAAKC,EAAKC,GAA+D,IAArDC,EAAqD7K,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,IAAAA,UAAA,GAAxB8K,EAAwB9K,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAb4J,EAAMC,MACtFjD,EAAS,GACTZ,EAAO,GACP+E,EAAqBH,GAAYJ,EACjCQ,EAAgBN,EAAIO,gBACpBC,EAAgBP,EAAIM,gBACpBE,EAAoBH,EAAcrU,KAClCyU,EAAoBF,EAAcvU,KAClCA,EAAUqU,EAAcrU,KAAxB,IAAgCuU,EAAcvU,KAC9C0U,EAAmBlB,EAAgBa,EAAeE,GAExD,GAAIC,IAAsBC,EACtB,MAAM,IAAIE,MAAM,8CA+EpB,OA5EAN,EAAcpH,OAAOG,QAAQ,SAACyC,GAC1B,IAAM+E,EAAY9G,EAAQ,GAAI+B,EAAMI,WACc,IAA9CyE,EAAiBxK,QAAQ0K,EAAU5U,OAAiBkU,IACpDU,EAAU5U,KAAUqU,EAAcrU,KAAlC,IAA0C4U,EAAU5U,MAExDiQ,EAAO9F,KAAKyK,KAEhBL,EAActH,OAAOG,QAAQ,SAACyC,GAC1B,IAAM+E,EAAY9G,EAAQ,GAAI+B,EAAMI,WACc,IAA9CyE,EAAiBxK,QAAQ0K,EAAU5U,MAC9BkU,IACDU,EAAU5U,KAAUuU,EAAcvU,KAAlC,IAA0C4U,EAAU5U,KACpDiQ,EAAO9F,KAAKyK,IAGhB3E,EAAO9F,KAAKyK,KAKpBjE,EAAmBoD,EAAIc,YAAa,SAACpV,GACjC,IAAIqV,GAAW,EACXC,SACJpE,EAAmBqD,EAAIa,YAAa,SAACG,GACjC,IAAMC,EAAQ,GACRC,EAAU,GAChBA,EAAQV,GAAqB,GAC7BU,EAAQT,GAAqB,GAC7BJ,EAAcpH,OAAOG,QAAQ,SAACyC,GAC1BoF,EAAM9K,KAAK0F,EAAMsF,aAAa9F,KAAK5P,IACnCyV,EAAQV,GAAmB3E,EAAM7P,QAAU6P,EAAMsF,aAAa9F,KAAK5P,KAEvE8U,EAActH,OAAOG,QAAQ,SAACyC,IAC+B,IAAnD6E,EAAiBxK,QAAQ2F,EAAMI,SAASjQ,OAAgBkU,GAC1De,EAAM9K,KAAK0F,EAAMsF,aAAa9F,KAAK2F,IAEvCE,EAAQT,GAAmB5E,EAAM7P,QAAU6P,EAAMsF,aAAa9F,KAAK2F,KAGvE,IAIMI,EAAYC,GAAgBH,EAAQV,IACpCc,EAAYD,GAAgBH,EAAQT,IAC1C,GAAIL,EAAmBgB,EAAWE,EALb,kBAAMvB,EAAIwB,gBACV,kBAAMvB,EAAIuB,gBAFb,IAMyE,CACvF,IAAMC,EAAW,GACjBP,EAAM7H,QAAQ,SAACqI,EAASC,GACpBF,EAASvF,EAAOyF,GAAK1V,MAAQyV,IAE7BX,GAAY7B,EAAMC,QAAUiB,EAC5B9E,EAAK0F,GAAeS,GAGpBnG,EAAKlF,KAAKqL,GACVV,GAAW,EACXC,EAActV,QAEf,IAAK0U,IAAalB,EAAME,WAAagB,IAAalB,EAAMG,cAAgB0B,EAAU,CACrF,IAAMU,EAAW,GACb3I,EAAMwH,EAAcpH,OAAOxH,OAAS,EACxCwP,EAAM7H,QAAQ,SAACqI,EAASC,GAEhBF,EAASvF,EAAOyF,GAAK1V,MADrB0V,GAAO7I,EACsB4I,EAGA,OAGrCX,GAAW,EACXC,EAActV,EACd4P,EAAKlF,KAAKqL,QAKf,IAAI/T,GAAU4N,EAAMY,EAAQ,CAAEjQ,SC3GzC,SAAS2V,EAAW7O,EAAGO,GACnB,IAAMuO,KAAQ9O,EACR+O,KAAQxO,EACd,OAAIuO,EAAKC,GACG,EAERD,EAAKC,EACE,EAEJ,EAqEJ,SAASC,EAAWC,GAAyB,IAApBC,EAAoB3M,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAXsM,EAIrC,OAHII,EAAItQ,OAAS,GArBrB,SAASwQ,EAAMF,EAAKG,EAAIC,EAAIH,GACxB,GAAIG,IAAOD,EAAM,OAAOH,EAExB,IAAMK,EAAMF,EAAKpO,KAAK0K,OAAO2D,EAAKD,GAAM,GAKxC,OAJAD,EAAKF,EAAKG,EAAIE,EAAKJ,GACnBC,EAAKF,EAAKK,EAAM,EAAGD,EAAIH,GAzC3B,SAAgBD,EAAKG,EAAIE,EAAKD,EAAIH,GAG9B,IAFA,IAAMK,EAAUN,EACVO,EAAS,GACN7W,EAAIyW,EAAIzW,GAAK0W,EAAI1W,GAAK,EAC3B6W,EAAO7W,GAAK4W,EAAQ5W,GAKxB,IAHA,IAAIqH,EAAIoP,EACJ7O,EAAI+O,EAAM,EAEL3W,EAAIyW,EAAIzW,GAAK0W,EAAI1W,GAAK,EACvBqH,EAAIsP,GACJC,EAAQ5W,GAAK6W,EAAOjP,GACpBA,GAAK,GACEA,EAAI8O,GACXE,EAAQ5W,GAAK6W,EAAOxP,GACpBA,GAAK,GACEkP,EAAOM,EAAOxP,GAAIwP,EAAOjP,KAAO,GACvCgP,EAAQ5W,GAAK6W,EAAOxP,GACpBA,GAAK,IAELuP,EAAQ5W,GAAK6W,EAAOjP,GACpBA,GAAK,GAqBb8G,CAAM4H,EAAKG,EAAIE,EAAKD,EAAIH,GAEjBD,EAcHE,CAAKF,EAAK,EAAGA,EAAItQ,OAAS,EAAGuQ,GAE1BD,0HC3EX,SAASQ,EAAWC,EAAUC,EAAUzQ,GACpC,IAAI0Q,SACJ,OAAQF,GACR,KAAKlU,EAAeC,WACpB,KAAKN,EAAiBE,SAEduU,EADa,SAAbD,EACU,SAAC3P,EAAGO,GAAJ,OAAUA,EAAErB,GAASc,EAAEd,IAEvB,SAACc,EAAGO,GAAJ,OAAUP,EAAEd,GAASqB,EAAErB,IAErC,MACJ,QACI0Q,EAAU,SAAC5P,EAAGO,GACV,IAAMuO,KAAQ9O,EAAEd,GACV6P,KAAQxO,EAAErB,GAChB,OAAI4P,EAAKC,EACe,SAAbY,EAAsB,GAAK,EAElCb,EAAKC,EACe,SAAbY,GAAuB,EAAI,EAE/B,GAGf,OAAOC,EAUX,SAASC,EAAUtH,EAAMhC,GACrB,IAAMuJ,EAAU,IAAIC,IACdC,EAAc,GAYpB,OAVAzH,EAAKjC,QAAQ,SAAC2J,GACV,IAAMC,EAAWD,EAAM1J,GACnBuJ,EAAQK,IAAID,GACZF,EAAYF,EAAQtW,IAAI0W,IAAW,GAAG7M,KAAK4M,IAE3CD,EAAY3M,KAAK,CAAC6M,EAAU,CAACD,KAC7BH,EAAQM,IAAIF,EAAUF,EAAYrR,OAAS,MAI5CqR,EAYX,SAASK,EAAmBC,EAAcC,EAAcC,GACpD,IAAMnO,EAAM,CACRoO,MAAOH,EAAa,IAQxB,OALAC,EAAaG,OAAO,SAACC,EAAKvF,EAAMwF,GAE5B,OADAD,EAAIvF,GAAQkF,EAAa,GAAGlL,IAAI,SAAA6K,GAAA,OAASA,EAAMO,EAAmBI,GAAK1R,SAChEyR,GACRtO,GAEIA,EA0EJ,SAASwO,EAAapI,EAAYqB,EAAYgH,EAAeC,EAAgBjN,GAKhFA,EAAUzK,OAAOmR,OAAO,GAJL,CACfwG,QAAQ,EACRC,YAAY,GAEwBnN,GAExC,IAAMoN,EAAS,CACX/H,OAAQ,GACRZ,KAAM,GACN4I,KAAM,IAEJH,EAASlN,EAAQkN,OACjBI,EAAaL,GAAkBA,EAAepS,OAAS,EAEvD0S,EAAa,GAiDnB,GA/CgBP,EAAc9G,MAAM,KAE5B1D,QAAQ,SAACgL,GACb,IAAK,IAAI3Y,EAAI,EAAGA,EAAI8P,EAAW9J,OAAQhG,GAAK,EACxC,GAAI8P,EAAW9P,GAAGO,SAAWoY,EAAS,CAClCD,EAAWhO,KAAKoF,EAAW9P,IAC3B,SAMZ0Y,EAAW/K,QAAQ,SAACyC,GAEhBmI,EAAO/H,OAAO9F,KAAK0F,EAAMI,YAGzB6H,GACAE,EAAO/H,OAAO9F,KAAK,CACfnK,KAAM,MACNkQ,KAAM,eAIdS,EAAmBC,EAAY,SAACnR,GAC5BuY,EAAO3I,KAAKlF,KAAK,IACjB,IAAMkO,EAAYL,EAAO3I,KAAK5J,OAAS,EAEvC0S,EAAW/K,QAAQ,SAACyC,EAAOmF,GACvBgD,EAAO3I,KAAKgJ,GAAWrD,EAFf,GAE6BnF,EAAMsF,aAAa9F,KAAK5P,KAE7DqY,IACAE,EAAO3I,KAAKgJ,GAAWF,EAAW1S,QAAUhG,GAGhDuY,EAAOC,KAAK9N,KAAK1K,GAIbyY,GAAcF,EAAO3I,KAAKgJ,GAAWlO,KAAK1K,KAI9CyY,GA7HR,SAAkBI,EAAST,GAOvB,IAPuC,IAC/BxI,EAAiBiJ,EAAjBjJ,KAAMY,EAAWqI,EAAXrI,OACVsI,SACAC,SACAC,SACAhZ,EAAIoY,EAAepS,OAAS,EAEzBhG,GAAK,EAAGA,IACX8Y,EAAYV,EAAepY,GAAG,GAC9B+Y,EAAWX,EAAepY,GAAG,IAC7BgZ,EAAWC,GAAczI,EAAQsI,MXhEf,mBWuEHC,EAEX1C,EAAUzG,EAAM,SAACvI,EAAGO,GAAJ,OAAUmR,EAAS1R,EAAE2R,EAASzS,OAAQqB,EAAEoR,EAASzS,UAC1D2I,EAAQ6J,GAAW,WAC1B,IAAM1B,EAAcH,EAAUtH,EAAMoJ,EAASzS,OACvC2S,EAAYH,EAASA,EAAS/S,OAAS,GACvC4R,EAAemB,EAASI,MAAM,EAAGJ,EAAS/S,OAAS,GACnD6R,EAAqBD,EAAanL,IAAI,SAAA2M,GAAA,OAAKH,GAAczI,EAAQ4I,KAEvE/B,EAAY1J,QAAQ,SAACgK,GACjBA,EAAajN,KAAKgN,EAAmBC,EAAcC,EAAcC,MAGrExB,EAAUgB,EAAa,SAAChQ,EAAGO,GACvB,IAAMxH,EAAIiH,EAAE,GACN5F,EAAImG,EAAE,GACZ,OAAOsR,EAAU9Y,EAAGqB,KAIxBmO,EAAK5J,OAAS,EACdqR,EAAY1J,QAAQ,SAAC2J,GACjB1H,EAAKlF,KAALqB,MAAA6D,EAAAyJ,EAAa/B,EAAM,OAnBG,IAsB1ByB,EAA8C,SAAnChO,OAAOgO,GAAUhT,cAA2B,OAAS,MAChEsQ,EAAUzG,EAAMkH,EAAUkC,EAASvI,KAAMsI,EAAUC,EAASzS,UAIpEsS,EAAQL,KAAO,GACf5I,EAAKjC,QAAQ,SAAC1M,GACV4X,EAAQL,KAAK9N,KAAKzJ,EAAMqY,SA6ExBC,CAAShB,EAAQH,GAGjBjN,EAAQmN,WAAY,CACpB,IAAMkB,EAAU/L,qBAASA,MAAM8K,EAAO/H,OAAOxK,UAASyG,IAAI,iBAAM,KAChE8L,EAAO3I,KAAKjC,QAAQ,SAAC6H,GACjBA,EAAM7H,QAAQ,SAACiC,EAAM5P,GACjBwZ,EAAQxZ,GAAG0K,KAAKkF,OAGxB2I,EAAO3I,KAAO4J,EAGlB,OAAOjB,EC1NJ,SAASkB,EAAYnF,EAAKC,GAC7B,IAAMmF,EAAY,GACZlJ,EAAS,GACTmJ,EAAgB,GAChB/J,EAAO,GACPgF,EAAgBN,EAAIO,gBACpBC,EAAgBP,EAAIM,gBACpB+E,EAAwBhF,EAAc1E,YACtC2J,EAAwB/E,EAAc5E,YACtC3P,EAAUqU,EAAcrU,KAAxB,UAAsCuU,EAAcvU,KAG1D,IAAKgP,EAAW+E,EAAIwF,eAAezI,MAAM,KAAKmF,OAAQjC,EAAIuF,eAAezI,MAAM,KAAKmF,QAChF,OAAO,KAiBX,SAASuD,EAAkBC,EAAI9J,EAAW+J,GACtC/I,EAAmB8I,EAAG5E,YAAa,SAACpV,GAChC,IAAMwV,EAAQ,GACV0E,EAAW,GACfP,EAAchM,QAAQ,SAACwM,GACnB,IAAMlZ,EAAQiP,EAAUiK,GAAYzE,aAAa9F,KAAK5P,GACtDka,OAAgBjZ,EAChBuU,EAAM2E,GAAclZ,IAEnByY,EAAUQ,KACPD,GAAWrK,EAAKlF,KAAK8K,GACzBkE,EAAUQ,IAAY,KASlC,OAjCC5F,EAAIwF,eAAezI,MAAM,KAAM1D,QAAQ,SAACmL,GACrC,IAAM1I,EAAQwJ,EAAsBd,GACpCtI,EAAO9F,KAAK2D,EAAQ,GAAI+B,EAAMI,WAC9BmJ,EAAcjP,KAAK0F,EAAMI,SAASjQ,QA2BtCwZ,EAAkBxF,EAAKsF,GAAuB,GAC9CE,EAAkBzF,EAAKsF,GAAuB,GAEvC,IAAI5X,GAAU4N,EAAMY,EAAQ,CAAEjQ,8PC5DjCgD,GAAgDD,EAAhDC,IAAKC,GAA2CF,EAA3CE,IAAKG,GAAsCL,EAAtCK,MAAOC,GAA+BN,EAA/BM,KAAMC,GAAyBP,EAAzBO,MAAOC,GAAkBR,EAAlBQ,IAAKL,GAAaH,EAAbG,IAAKC,GAAQJ,EAARI,IAEhD,SAAS0W,GAAkB9D,GACvB,OAAOA,EAAI+D,OAAO,SAAAxL,GAAA,QAAUA,aAAgB6C,KAShD,SAAS4I,GAAKhE,GACV,GAAIpH,EAAQoH,MAAUA,EAAI,aAAc7I,OAAQ,CAC5C,IAAM8M,EAAiBH,GAAkB9D,GAIzC,OAHiBiE,EAAevU,OACZuU,EAAexC,OAAO,SAACC,EAAKwC,GAAN,OAAexC,EAAMwC,GAAM,GAC/C9I,EAAkBM,KAG5C,OAAON,EAAkBM,KAU7B,SAASyI,GAAKnE,GACV,GAAIpH,EAAQoH,MAAUA,EAAI,aAAc7I,OAAQ,CAC5C,IAAMiN,EAAWJ,GAAIhE,GACflJ,EAAMkJ,EAAItQ,QAAU,EAC1B,OAAQgH,OAAO2N,MAAMD,IAAaA,aAAoBhJ,EAC7CA,EAAkBM,KAAO0I,EAAWtN,EAEjD,OAAOsE,EAAkBM,KAgG7B,IAAM4I,WACDrX,GAAM+W,IADLO,EAAAC,EAEDtX,GAAMiX,IAFLI,EAAAC,EAGDrX,GAzFL,SAAc6S,GACV,GAAIpH,EAAQoH,MAAUA,EAAI,aAAc7I,OAAQ,CAE5C,IAAMsN,EAAiBX,GAAkB9D,GAEzC,OAAQyE,EAAe/U,OAAUqC,KAAK2S,IAALjP,MAAA1D,KAAA4S,GAAYF,IAAkBrJ,EAAkBM,KAErF,OAAON,EAAkBM,OA+EvB6I,EAAAC,EAIDpX,GAzEL,SAAc4S,GACV,GAAIpH,EAAQoH,MAAUA,EAAI,aAAc7I,OAAQ,CAE5C,IAAMsN,EAAiBX,GAAkB9D,GAEzC,OAAQyE,EAAe/U,OAAUqC,KAAK6S,IAALnP,MAAA1D,KAAA4S,GAAYF,IAAkBrJ,EAAkBM,KAErF,OAAON,EAAkBM,OA8DvB6I,EAAAC,EAKDnX,GAzDL,SAAgB2S,GACZ,OAAOA,EAAI,KAmDTuE,EAAAC,EAMDlX,GA/CL,SAAe0S,GACX,OAAOA,EAAIA,EAAItQ,OAAS,KAwCtB6U,EAAAC,EAODjX,GArCL,SAAgByS,GACZ,OAAIpH,EAAQoH,GACDA,EAAItQ,OAER0L,EAAkBM,OA0BvB6I,EAAAC,EAQDhX,GAbL,SAAcwS,GACV,OAAOjO,KAAK8S,KAbhB,SAAmB7E,GACf,IAAI8E,EAAOX,GAAInE,GACf,OAAOmE,GAAInE,EAAI7J,IAAI,SAAA4O,GAAA,OAAAhT,KAAAiT,IAAQD,EAAMD,EAAS,MAWzBG,CAASjF,MAIxBwE,GAWAU,GAAqBjY,6PC1IrBkY,cACF,SAAAA,IAAe,IAAAC,EAAArX,kGAAAsX,CAAAtX,KAAAoX,GACXpX,KAAKiJ,MAAQ,IAAI8J,IACjB/S,KAAKiJ,MAAMmK,IAAI,aAAcmE,IAE7Blb,OAAOmb,QAAQjB,IAAQjN,QAAQ,SAACpM,GAC5Bma,EAAKpO,MAAMmK,IAAIlW,EAAI,GAAIA,EAAI,0DAc/B,IAAKqI,UAAO5D,OACR,OAAO3B,KAAKiJ,MAAMzM,IAAI,cAG1B,IAAIib,0CAEJ,GAAuB,mBAAZA,EACPzX,KAAKiJ,MAAMmK,IAAI,aAAcqE,OAC1B,CAEH,GADAA,EAAU/Q,OAAO+Q,IAC6B,IAA1Cpb,OAAO4J,KAAKsQ,IAAQnQ,QAAQqR,GAG5B,MAAM,IAAI5G,MAAJ,WAAqB4G,EAArB,0BAFNzX,KAAKiJ,MAAMmK,IAAI,aAAcmD,GAAOkB,IAK5C,OAAOzX,sCAmCD9D,EAAMub,GAAS,IAAAC,EAAA1X,KACrB,GAAuB,mBAAZyX,EACP,MAAM,IAAI5G,MAAM,gCAMpB,OAHA3U,EAAOwK,OAAOxK,GACd8D,KAAKiJ,MAAMmK,IAAIlX,EAAMub,GAEd,WAAQC,EAAKC,aAAazb,yCAGvBA,GACN8D,KAAKiJ,MAAMkK,IAAIjX,IACf8D,KAAKiJ,MAAM2O,OAAO1b,mCAIjBA,GACL,OAAIA,aAAgB0M,SACT1M,EAEJ8D,KAAKiJ,MAAMzM,IAAIN,YAgBf2b,GAZO,WAClB,IAAI5O,EAAQ,KAQZ,OALkB,OAAVA,IACAA,EAAQ,IAAImO,IAETnO,EAPO,uaCrCtB,SAAS6O,GAASC,EAAWpM,EAAUqM,EAAUC,GAC7C,IAAMC,EAxDV,SAAsBH,EAAWpM,GAC7B,IAAMkE,EAAS,GAETsI,EADaJ,EAAUvH,gBACCnE,eAY9B,OAVAhQ,OAAOmb,QAAQW,GAAY7O,QAAQ,SAAA8O,GAAW,IAATlb,EAASmb,GAAAD,EAAA,MACtCzM,GAAYA,EAAShK,QACU,IAA3BgK,EAASvF,QAAQlJ,IACjB2S,EAAOxJ,KAAKnJ,GAGhB2S,EAAOxJ,KAAKnJ,KAIb2S,EAyCWyI,CAAYP,EAAWpM,GACnC4M,EAhCV,SAAwBR,GAA0B,IAAfC,EAAezS,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAJ,GACpC2O,EAAS,GAETsE,EADaT,EAAUvH,gBACDxE,aACtBuL,EAAaM,GAAaY,iBAchC,OAZApc,OAAO4J,KAAKuS,GAAUlP,QAAQ,SAACoP,GACU,iBAA1BV,EAASU,KAChBV,EAASU,GAAeF,EAASE,GAAaC,YAElD,IAAMC,EAAYf,GAAagB,QAAQb,EAASU,IAC5CE,EACA1E,EAAOwE,GAAeE,GAEtB1E,EAAOwE,GAAenB,EACtBS,EAASU,GAAevB,MAGzBjD,EAcY4E,CAAcf,EAAWC,GACtCvM,EAAasM,EAAUvH,gBACvBuI,EAAgBtN,EAAWI,YAC3BmN,EAASvN,EAAWvP,KACpB+c,EAAe,GACfC,EAAa,GACb/M,EAAS,GACT2G,EAAU,GACVvH,EAAO,GACT4N,SAGJ9c,OAAOmb,QAAQuB,GAAezP,QAAQ,SAAA8P,GAAkB,IAAAC,EAAAhB,GAAAe,EAAA,GAAhBlc,EAAgBmc,EAAA,GAAXzc,EAAWyc,EAAA,GACpD,IAAgC,IAA5BnB,EAAU9R,QAAQlJ,IAAeqb,EAAWrb,GAG5C,OAFAiP,EAAO9F,KAAK2D,EAAQ,GAAIpN,EAAMuP,WAEtBvP,EAAMuP,SAASC,MACvB,KAAK1N,EAAUC,QACXua,EAAW7S,KAAKnJ,GAChB,MACJ,QACA,KAAKwB,EAAUE,UACXqa,EAAa5S,KAAKnJ,MAK9B,IAAIoc,EAAW,EACfzM,EAAmBkL,EAAUhH,YAAa,SAACpV,GACvC,IAAI4d,EAAO,GACXN,EAAa3P,QAAQ,SAACkQ,GAClBD,EAAUA,EAAV,IAAkBR,EAAcS,GAAGnI,aAAa9F,KAAK5P,UAEnCuE,IAAlB4S,EAAQyG,IACRzG,EAAQyG,GAAQD,EAChB/N,EAAKlF,KAAK,IACV4S,EAAa3P,QAAQ,SAACkQ,GAClBjO,EAAK+N,GAAUE,GAAKT,EAAcS,GAAGnI,aAAa9F,KAAK5P,KAE3Dud,EAAW5P,QAAQ,SAACkQ,GAChBjO,EAAK+N,GAAUE,GAAK,CAACT,EAAcS,GAAGnI,aAAa9F,KAAK5P,MAE5D2d,GAAY,GAEZJ,EAAW5P,QAAQ,SAACkQ,GAChBjO,EAAKuH,EAAQyG,IAAOC,GAAGnT,KAAK0S,EAAcS,GAAGnI,aAAa9F,KAAK5P,QAM3E,IAAI8d,EAAc,GACdC,EAAgB,kBAAM3B,EAAUtG,gBAcpC,OAbAlG,EAAKjC,QAAQ,SAACqQ,GACV,IAAMxI,EAAQwI,EACdT,EAAW5P,QAAQ,SAACkQ,GAChBrI,EAAMqI,GAAKjB,EAAWiB,GAAGG,EAAIH,GAAIE,EAAeD,OAGpDxB,GACAA,EAAkB2B,wBAClBT,EAAelB,GAGfkB,EAAe,IAAIxb,GAAU4N,EAAMY,EAAQ,CAAEjQ,KAAM8c,IAEhDG,EC9HJ,SAASU,GAAmB5J,EAAKC,GACpC,IAIM4J,EAAkBpK,EAJFO,EAAIO,gBACJN,EAAIM,iBAK1B,OAAO,SAACc,EAAWE,GACf,IAAIuI,GAAc,EASlB,OARAD,EAAgBxQ,QAAQ,SAACmL,GAGjBsF,IAFAzI,EAAUmD,GAAW7X,QACrB4U,EAAUiD,GAAW7X,QAASmd,KAM/BA,GCjBR,SAASC,GAAO/J,EAAKC,GACxB,IAAMmF,EAAY,GACZlJ,EAAS,GACTmJ,EAAgB,GAChB/J,EAAO,GACPgF,EAAgBN,EAAIO,gBACpBC,EAAgBP,EAAIM,gBACpB+E,EAAwBhF,EAAc1E,YACtC2J,EAAwB/E,EAAc5E,YACtC3P,EAAUqU,EAAcrU,KAAxB,UAAsCuU,EAAcvU,KAG1D,IAAKgP,EAAW+E,EAAIwF,eAAezI,MAAM,KAAKmF,OAAQjC,EAAIuF,eAAezI,MAAM,KAAKmF,QAChF,OAAO,KAgBX,SAASuD,EAAmBC,EAAI9J,GAC5BgB,EAAmB8I,EAAG5E,YAAa,SAACpV,GAChC,IAAMwV,EAAQ,GACV0E,EAAW,GACfP,EAAchM,QAAQ,SAACwM,GACnB,IAAMlZ,EAAQiP,EAAUiK,GAAYzE,aAAa9F,KAAK5P,GACtDka,OAAgBjZ,EAChBuU,EAAM2E,GAAclZ,IAEnByY,EAAUQ,KACXtK,EAAKlF,KAAK8K,GACVkE,EAAUQ,IAAY,KASlC,OAhCC5F,EAAIwF,eAAezI,MAAM,KAAM1D,QAAQ,SAACmL,GACrC,IAAM1I,EAAQwJ,EAAsBd,GACpCtI,EAAO9F,KAAK2D,EAAQ,GAAI+B,EAAMI,WAC9BmJ,EAAcjP,KAAK0F,EAAMI,SAASjQ,QA0BtCwZ,EAAkBzF,EAAKsF,GACvBG,EAAkBxF,EAAKsF,GAEhB,IAAI7X,GAAU4N,EAAMY,EAAQ,CAAEjQ,SCvDlC,SAAS+d,GAAeC,EAAYC,EAAYhK,GACnD,OAAOH,EAAakK,EAAYC,EAAYhK,GAAU,EAAOhB,EAAME,WAGhE,SAAS+K,GAAgBF,EAAYC,EAAYhK,GACpD,OAAOH,EAAamK,EAAYD,EAAY/J,GAAU,EAAOhB,EAAMG,0QCWlD+K,cAQjB,SAAAA,EAAahJ,EAAcvE,gGAAYwN,CAAAta,KAAAqa,GACnCra,KAAKqR,aAAeA,EACpBrR,KAAK8M,WAAaA,8CAUlB,MAAM,IAAI+D,MAAM,wDAUhB,OAAO7Q,KAAKqR,aAAalF,sCAUzB,OAAOnM,KAAKqR,aAAanV,oCAUzB,OAAO8D,KAAKqR,aAAalF,OAAOC,uCAUhC,OAAOpM,KAAKqR,aAAalF,OAAOoO,8CAUhC,OAAOva,KAAKqR,aAAalF,OAAOqO,kDAUhC,OAAOxa,KAAKqR,aAAalF,OAAOsO,aAAeza,KAAKqR,aAAalF,OAAOjQ,oCASpE,IAAAmb,EAAArX,KACEuL,EAAO,GAIb,OAHAsB,EAAmB7M,KAAK8M,WAAY,SAACnR,GACjC4P,EAAKlF,KAAKgR,EAAKhG,aAAa9F,KAAK5P,MAE9B4P,0CAUP,MAAM,IAAIsF,MAAM,0RCpHH6J,irBAAkBL,yCAY/B,OAHKra,KAAK2a,gBACN3a,KAAK2a,cAAgB3a,KAAK4a,uBAEvB5a,KAAK2a,4DAUZ,MAAM,IAAI9J,MAAM,+DAWhB,OAAO7Q,KAAKuL,0QChCCsP,irBAAoBH,0CASjC,OAAOvc,EAAiBC,0DAUL,IAAAsZ,EAAA1X,KACbuZ,EAAO,IAAIuB,IACXC,EAAS,GAUf,OAPAlO,EAAmB7M,KAAK8M,WAAY,SAACnR,GACjC,IAAMsX,EAAQyE,EAAKrG,aAAa9F,KAAK5P,GAChC4d,EAAKpG,IAAIF,KACVsG,EAAKyB,IAAI/H,GACT8H,EAAO1U,KAAK4M,MAGb8H,qQC7BME,eAQjB,SAAAA,EAAa5J,EAAcvE,gGAAYoO,CAAAlb,KAAAib,GAAA,IAAA5D,mKAAA8D,CAAAnb,MAAAib,EAAAG,WAAA/e,OAAAgf,eAAAJ,IAAAnf,KAAAkE,KAC7BqR,EAAcvE,IADe,OAGnCuK,EAAKiE,eAAiB,KAHajE,qUARLqD,sDAqBX,IAAAhD,EAAA1X,KACbuZ,EAAO,IAAIuB,IACXC,EAAS,GAYf,OARAlO,EAAmB7M,KAAK8M,WAAY,SAACnR,GACjC,IAAMsX,EAAQyE,EAAKrG,aAAa9F,KAAK5P,GAChC4d,EAAKpG,IAAIF,KACVsG,EAAKyB,IAAI/H,GACT8H,EAAO1U,KAAK4M,MAIb8H,yDAWP,GAAI/a,KAAKsb,eACL,OAAOtb,KAAKsb,eAUhB,IAPA,IAAMC,EAAavb,KAAKuL,OAAOyK,OAAO,SAAAxL,GAAA,QAAUA,aAAgB6C,KAAoB8E,KAAK,SAACnP,EAAGO,GAAJ,OAAUP,EAAIO,IACjGiY,EAAQD,EAAW5Z,OACrB8Z,EAAU9S,OAAO+S,kBACjBC,SACAC,SACAC,EAAiB,EAEZlgB,EAAI,EAAGA,EAAI6f,EAAO7f,IACvBggB,EAAYJ,EAAW5f,EAAI,IAC3BigB,EAAYL,EAAW5f,MAELggB,IAIlBF,EAAUzX,KAAK2S,IAAI8E,EAASG,EAAYL,EAAW5f,EAAI,IACvDkgB,KAQJ,OALKA,IACDJ,EAAU,MAEdzb,KAAKsb,eAAiBG,EAEfzb,KAAKsb,gDAUZ,OAAOtb,KAAKqR,aAAalF,OAAOpM,+CAUnB,IAAA+b,EAAA9b,KACPuL,EAAO,GASb,OARAsB,EAAmB7M,KAAK8M,WAAY,SAACnR,GACjC,IAAMsX,EAAQ6I,EAAKzK,aAAa9F,KAAK5P,GACjCsX,aAAiB5F,EACjB9B,EAAKlF,KAAK4M,GAEV1H,EAAKlF,KAAKvG,EAAkByG,SAAS0M,EAAO6I,EAAK/b,aAGlDwL,qQC3GMwQ,irBAAerB,sDAS5B,IAAMsB,EAAUhc,KAAKqR,aAAalF,OAAO8P,KACzC,MAAO,CAACD,EAAQ,GAAIA,EAAQA,EAAQra,OAAS,mCAU7C,OAAO3B,KAAKqR,aAAalF,OAAO8P,wQClBnBC,irBAAgB7B,yCAY7B,OAHKra,KAAK2a,gBACN3a,KAAK2a,cAAgB3a,KAAK4a,uBAEvB5a,KAAK2a,6CAUZ,OAAO3a,KAAKqR,aAAalF,OAAOgQ,wCAUhC,OAAOnc,KAAKqR,aAAalF,OAAOwM,UAAYxB,0CAShC,IACJiF,EAAiBpc,KAAKqR,aAAalF,OAAnCiQ,aACR,OAAOA,aAAwBxT,SAAWwT,EAAe/Q,gDAUzD,MAAM,IAAIwF,MAAM,+DAWhB,OAAO7Q,KAAKuL,0QC/DC8Q,irBAAmBH,0CAShC,OAAO1d,EAAeC,yDAUH,IAAAiZ,EAAA1X,KACf2W,EAAMhO,OAAO+S,kBACb7E,EAAMlO,OAAO2T,kBAiBjB,OAdAzP,EAAmB7M,KAAK8M,WAAY,SAACnR,GACjC,IAAMsX,EAAQyE,EAAKrG,aAAa9F,KAAK5P,GACjCsX,aAAiB5F,IAIjB4F,EAAQ0D,IACRA,EAAM1D,GAENA,EAAQ4D,IACRA,EAAM5D,MAIP,CAAC0D,EAAKE,sQC5CA0F,4KAQb,MAAM,IAAI1L,MAAM,0RCJH2L,irBAA0BD,sCAQpCpb,GAQH,OALKkM,EAAkBoP,UAAUtb,GAGpBkM,EAAkBqP,eAAevb,GAFjCuF,OAAOvF,GAAKwb,0QCXZC,eAOjB,SAAAA,EAAazQ,gGAAQ0Q,CAAA7c,KAAA4c,GAAA,IAAAvF,mKAAAyF,CAAA9c,MAAA4c,EAAAxB,WAAA/e,OAAAgf,eAAAuB,IAAA9gB,KAAAkE,OAAA,OAEjBqX,EAAKlL,OAASA,EACdkL,EAAK0F,KAAO,IAAIjd,EAAkBuX,EAAKlL,OAAOpM,QAH7BsX,qUAPmBkF,sCAoBjCpb,GACH,IAAIyC,SAEJ,GAAKyJ,EAAkBoP,UAAUtb,GAI7ByC,EAASyJ,EAAkBqP,eAAevb,OAJP,CACnC,IAAIhB,EAAaH,KAAK+c,KAAKrU,cAAcvH,GACzCyC,EAASzD,EAAaA,EAAW4K,UAAYsC,EAAkBO,GAInE,OAAOhK,qQC9BMoZ,irBAAqBT,sCAQ/Bpb,GAEHA,EAAMuF,OAAOvF,GACb,IAAIyC,SAEJ,GAAKyJ,EAAkBoP,UAAUtb,GAK7ByC,EAASyJ,EAAkBqP,eAAevb,OALP,CACnC,IAAI8b,EAAU9b,EAAIqH,MALR,2DAMV5E,EAASqZ,EAAatU,OAAOuU,WAAWD,EAAQ,IAAvC,IAA8CtU,OAAOuU,WAAWD,EAAQ,IAC9D5P,EAAkBO,GAIzC,OAAOhK,qQCpBMuZ,irBAAyBZ,sCAQnCpb,GACH,IAAIyC,SAEJ,GAAKyJ,EAAkBoP,UAAUtb,GAI7ByC,EAASyJ,EAAkBqP,eAAevb,OAJP,CACnC,IAAIC,EAAY8b,WAAW/b,EAAK,IAChCyC,EAAS+E,OAAO2N,MAAMlV,GAAaiM,EAAkBO,GAAKxM,EAI9D,OAAOwC,qQCnBMwZ,cAUjB,SAAAA,EAAalhB,EAAMqP,EAAMY,EAAQ/J,gGAAQib,CAAArd,KAAAod,GACrCpd,KAAK9D,KAAOA,EACZ8D,KAAKmM,OAASA,EACdnM,KAAKoC,OAASA,EACdpC,KAAKuL,KAAOvL,KAAKsd,UAAU/R,gDAUpBA,GAAM,IAAA8L,EAAArX,KACb,OAAOuL,EAAKnD,IAAI,SAAA6K,GAAA,OAASoE,EAAKjV,OAAOwE,MAAMqM,cCiE5C,SAASsK,GAAaC,EAAYrR,EAAQsR,GAC7C,IAAMC,EAAa,GAUnB,OARMD,GAAWA,EAAQ9b,SACrB8b,EAAUtR,EAAO/D,IAAI,SAAAoC,GAAA,OAAQA,EAAKtO,QAGtCuhB,EAAQnU,QAAQ,SAACqU,EAAQhiB,GACrB+hB,EAAWC,GAAUhiB,IAGlBwQ,EAAO/D,IAAI,SAAAoC,GAAA,OAzFtB,SAAyBe,EAAMY,GAC3BZ,EAAOA,GAAQ,GACf,IAAI8F,SAEJ,OAAQlF,EAAOC,MACf,KAAK1N,EAAUC,QACX,OAAQwN,EAAOoO,SACf,KAAK/b,EAAeC,WAGpB,QAEI,OADA4S,EAAe,IAAI+L,GAAajR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAIgR,IACxD,IAAId,GAAWhL,EAAf,MAAkC9F,EAAK5J,OAAS,IAE/D,KAAKjD,EAAUE,UACX,OAAQuN,EAAOoO,SACf,KAAKpc,EAAiBC,YAElB,OADAiT,EAAe,IAAI+L,GAAajR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAIqQ,IACxD,IAAI3B,GAAYxJ,EAAhB,MAAmC9F,EAAK5J,OAAS,IAC5D,KAAKxD,EAAiBE,SAElB,OADAgT,EAAe,IAAI+L,GAAajR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAIyQ,GAAezQ,IACvE,IAAI8O,GAAS5J,EAAb,MAAgC9F,EAAK5J,OAAS,IACzD,KAAKxD,EAAiBI,OAElB,OADA8S,EAAe,IAAI+L,GAAajR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAI6Q,IACxD,IAAIjB,GAAO1K,EAAX,MAA8B9F,EAAK5J,OAAS,IACvD,QAEI,OADA0P,EAAe,IAAI+L,GAAajR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAIqQ,IACxD,IAAI3B,GAAYxJ,EAAhB,MAAmC9F,EAAK5J,OAAS,IAEhE,QAEI,OADA0P,EAAe,IAAI+L,GAAajR,EAAOjQ,KAAMqP,EAAMY,EAAQ,IAAIqQ,IACxD,IAAI3B,GAAYxJ,EAAhB,MAAmC9F,EAAK5J,OAAS,KA0DlCic,CAAgBJ,EAAWE,EAAWlT,EAAKtO,OAAQsO,KC3GlE,IAAAqT,GAAA,CACXC,WAAYhgB,EAAWI,MCuCZ6f,OAvBf,SAAiB9L,EAAKnL,GAIlBA,EAAUzK,OAAOmR,OAAO,GAHF,CAClBwQ,gBAAgB,GAEuBlX,GAE3C,IAAI6W,SACEM,EAAU,GACV5X,EAAO6X,EAAYD,GAYzB,OAPIN,EAHA7W,EAAQkX,eAGC/L,EAAIxK,OAAO,EAAG,GAAG,GAEjB,GAGbwK,EAAI3I,QAAQ,SAAAyC,GAAA,OAAS1F,sIAAQ0F,MAEtB,CAAC4R,EAAQM,ICvChBE,GAAM,GACNC,GAAM,GACNC,GAAQ,GACRC,GAAU,GACVC,GAAS,GAEb,SAASC,GAAgBP,GACvB,OAAO,IAAIrV,SAAS,IAAK,WAAaqV,EAAQ7V,IAAI,SAASlM,EAAMP,GAC/D,OAAO8iB,KAAKC,UAAUxiB,GAAQ,OAASP,EAAI,MAC1CsH,KAAK,KAAO,KAWjB,SAAS0b,GAAaC,GACpB,IAAIC,EAAYxiB,OAAOY,OAAO,MAC1BghB,EAAU,GAUd,OARAW,EAAKtV,QAAQ,SAASqQ,GACpB,IAAK,IAAImF,KAAUnF,EACXmF,KAAUD,GACdZ,EAAQ5X,KAAKwY,EAAUC,GAAUA,KAKhCb,EAGT,SAASpe,GAAIjD,EAAOmiB,GAClB,IAAIrhB,EAAId,EAAQ,GAAI+E,EAASjE,EAAEiE,OAC/B,OAAOA,EAASod,EAAQ,IAAI3V,MAAM2V,EAAQpd,EAAS,GAAGsB,KAAK,GAAKvF,EAAIA,EAStE,SAASshB,GAAWrf,GAClB,IAPkBwE,EAOd3B,EAAQ7C,EAAKsf,cACbC,EAAUvf,EAAKwf,gBACfC,EAAUzf,EAAK0f,gBACfC,EAAe3f,EAAK4f,qBACxB,OAAOjJ,MAAM3W,GAAQ,iBAXHwE,EAYDxE,EAAK6f,kBAXR,EAAI,IAAM3f,IAAKsE,EAAM,GAC/BA,EAAO,KAAO,IAAMtE,GAAIsE,EAAM,GAC9BtE,GAAIsE,EAAM,IAS+B,IAAMtE,GAAIF,EAAK8f,cAAgB,EAAG,GAAK,IAAM5f,GAAIF,EAAK+f,aAAc,IAC1GJ,EAAe,IAAMzf,GAAI2C,EAAO,GAAK,IAAM3C,GAAIqf,EAAS,GAAK,IAAMrf,GAAIuf,EAAS,GAAK,IAAMvf,GAAIyf,EAAc,GAAK,IACnHF,EAAU,IAAMvf,GAAI2C,EAAO,GAAK,IAAM3C,GAAIqf,EAAS,GAAK,IAAMrf,GAAIuf,EAAS,GAAK,IAChFF,GAAW1c,EAAQ,IAAM3C,GAAI2C,EAAO,GAAK,IAAM3C,GAAIqf,EAAS,GAAK,IACjE,IAGO,IAAAS,GAAA,SAASC,GACtB,IAAIC,EAAW,IAAIzf,OAAO,KAAQwf,EAAY,SAC1CE,EAAYF,EAAUG,WAAW,GAWrC,SAASC,EAAU1f,EAAMyU,GACvB,IAIIlY,EAJA+hB,EAAO,GACPqB,EAAI3f,EAAKqB,OACTue,EAAI,EACJ9iB,EAAI,EAEJ+iB,EAAMF,GAAK,EACXG,GAAM,EAMV,SAAS9Z,IACP,GAAI6Z,EAAK,OAAO/B,GAChB,GAAIgC,EAAK,OAAOA,GAAM,EAAOjC,GAG7B,IAAIxiB,EAAUK,EAAPqkB,EAAIH,EACX,GAAI5f,EAAKyf,WAAWM,KAAOhC,GAAO,CAChC,KAAO6B,IAAMD,GAAK3f,EAAKyf,WAAWG,KAAO7B,IAAS/d,EAAKyf,aAAaG,KAAO7B,KAI3E,OAHK1iB,EAAIukB,IAAMD,EAAGE,GAAM,GACdnkB,EAAIsE,EAAKyf,WAAWG,QAAU5B,GAAS8B,GAAM,EAC9CpkB,IAAMuiB,KAAU6B,GAAM,EAAU9f,EAAKyf,WAAWG,KAAO5B,MAAW4B,GACpE5f,EAAKwU,MAAMuL,EAAI,EAAG1kB,EAAI,GAAG4E,QAAQ,MAAO,KAIjD,KAAO2f,EAAID,GAAG,CACZ,IAAKjkB,EAAIsE,EAAKyf,WAAWpkB,EAAIukB,QAAU5B,GAAS8B,GAAM,OACjD,GAAIpkB,IAAMuiB,GAAU6B,GAAM,EAAU9f,EAAKyf,WAAWG,KAAO5B,MAAW4B,OACtE,GAAIlkB,IAAM8jB,EAAW,SAC1B,OAAOxf,EAAKwU,MAAMuL,EAAG1kB,GAIvB,OAAOwkB,GAAM,EAAM7f,EAAKwU,MAAMuL,EAAGJ,GAGnC,IA7BI3f,EAAKyf,WAAWE,EAAI,KAAO3B,MAAW2B,EACtC3f,EAAKyf,WAAWE,EAAI,KAAO1B,MAAU0B,GA4BjCpjB,EAAIyJ,OAAa8X,IAAK,CAE5B,IADA,IAAIzE,EAAM,GACH9c,IAAMshB,IAAOthB,IAAMuhB,IAAKzE,EAAItT,KAAKxJ,GAAIA,EAAIyJ,IAC5CyO,GAA4B,OAAtB4E,EAAM5E,EAAE4E,EAAKvc,OACvBwhB,EAAKvY,KAAKsT,GAGZ,OAAOiF,EAGT,SAAS0B,EAAc1B,EAAMX,GAC3B,OAAOW,EAAKxW,IAAI,SAASuR,GACvB,OAAOsE,EAAQ7V,IAAI,SAAS0W,GAC1B,OAAOyB,EAAY5G,EAAImF,MACtB7b,KAAK2c,KAkBZ,SAASY,EAAU7G,GACjB,OAAOA,EAAIvR,IAAImY,GAAatd,KAAK2c,GAGnC,SAASW,EAAY3jB,GACnB,OAAgB,MAATA,EAAgB,GACjBA,aAAiBgD,KAAOof,GAAWpiB,GACnCijB,EAASY,KAAK7jB,GAAS,IAAM,IAAOA,EAAM2D,QAAQ,KAAM,MAAU,IAClE3D,EAGR,MAAO,CACLgK,MA5FF,SAAetG,EAAMyU,GACnB,IAAI2L,EAASzC,EAASW,EAAOoB,EAAU1f,EAAM,SAASqZ,EAAKhe,GACzD,GAAI+kB,EAAS,OAAOA,EAAQ/G,EAAKhe,EAAI,GACrCsiB,EAAUtE,EAAK+G,EAAU3L,EAtD/B,SAAyBkJ,EAASlJ,GAChC,IAAI1X,EAASmhB,GAAgBP,GAC7B,OAAO,SAAStE,EAAKhe,GACnB,OAAOoZ,EAAE1X,EAAOsc,GAAMhe,EAAGsiB,IAmDM0C,CAAgBhH,EAAK5E,GAAKyJ,GAAgB7E,KAGzE,OADAiF,EAAKX,QAAUA,GAAW,GACnBW,GAuFPoB,UAAWA,EACXjgB,OA5BF,SAAgB6e,EAAMX,GAEpB,OADe,MAAXA,IAAiBA,EAAUU,GAAaC,IACrC,CAACX,EAAQ7V,IAAImY,GAAatd,KAAK2c,IAAY/W,OAAOyX,EAAc1B,EAAMX,IAAUhb,KAAK,OA2B5F2d,WAxBF,SAAoBhC,EAAMX,GAExB,OADe,MAAXA,IAAiBA,EAAUU,GAAaC,IACrC0B,EAAc1B,EAAMX,GAAShb,KAAK,OAuBzC4d,WApBF,SAAoBjC,GAClB,OAAOA,EAAKxW,IAAIoY,GAAWvd,KAAK,SC1IhC6d,GAAMC,GAAI,KCAVC,IDEkBF,GAAIla,MACAka,GAAId,UACPc,GAAI/gB,OACA+gB,GAAIF,WACJE,GAAID,WCNrBE,GAAI,OAEQC,GAAIpa,MACAoa,GAAIhB,UACPgB,GAAIjhB,OACAihB,GAAIJ,WACJI,GAAIH,WC2BhBI,OAXf,SAAiBtW,EAAK7D,GAKlBA,EAAUzK,OAAOmR,OAAO,GAJF,CAClBwQ,gBAAgB,EAChBkD,eAAgB,KAEuBpa,GAE3C,IAAMia,EAAMI,GAAMra,EAAQoa,gBAC1B,OAAOnD,GAAOgD,EAAIf,UAAUrV,GAAM7D,ICoBvBsa,OAxBf,SAAmBnP,GACf,IAAM0L,EAAS,GACXhiB,EAAI,EACJ0lB,SACEpD,EAAU,GACV5X,EAAO6X,EAAYD,GAgBzB,OAdAhM,EAAI3I,QAAQ,SAACkB,GACT,IAAMrB,EAAS,GACf,IAAK,IAAIjM,KAAOsN,EACRtN,KAAOygB,EACP0D,EAAiB1D,EAAOzgB,IAExBygB,EAAOzgB,GAAOvB,IACd0lB,EAAiB1lB,EAAI,GAEzBwN,EAAOkY,GAAkB7W,EAAKtN,GAElCmJ,eAAQ8C,KAGL,CAAC9M,OAAO4J,KAAK0X,GAASM,IC1BlBqD,UAXf,SAAe/V,EAAMzE,GACjB,IAAMya,EAAa,CAAEH,YAAUH,UAAQlD,WACjCD,EAAaxS,EAAiBC,GAEpC,IAAKuS,EACD,MAAM,IAAIjN,MAAM,mCAGpB,OAAO0Q,EAAWzD,GAAYvS,EAAMzE,0pBCLxC,SAAS0a,GAAsBrY,EAAQxN,GACnC,IAAM8lB,EAAO,GADyBC,GAAA,EAAAC,GAAA,EAAAC,OAAA1hB,EAAA,IAEtC,QAAA2hB,EAAAC,EAAkB3Y,EAAlBzM,OAAAqlB,cAAAL,GAAAG,EAAAC,EAAA1T,QAAA4T,MAAAN,GAAA,EAA0B,KAAjB3V,EAAiB8V,EAAAjlB,MACtB6kB,EAAK1V,EAAM7P,QAAU,IAAIsQ,EAAMT,EAAMsF,aAAa9F,KAAK5P,GAAIoQ,IAHzB,MAAAkW,GAAAN,GAAA,EAAAC,EAAAK,EAAA,aAAAP,GAAAI,EAAAI,QAAAJ,EAAAI,SAAA,WAAAP,EAAA,MAAAC,GAKtC,OAAOH,EAGJ,SAASlQ,GAAiBpI,GAC7B,IAAMsY,EAAO,GAEb,OADAplB,OAAO4J,KAAKkD,GAAQG,QAAQ,SAACpM,GAAUukB,EAAKvkB,GAAO,IAAIsP,EAAMrD,EAAOjM,GAAMA,KACnEukB,EAGJ,IAAMU,GAAe,SAAA/J,EAA8BgK,EAAmBC,GAAmB,IAAAC,EAAAC,GAAAnK,EAAA,GAAlEtL,EAAkEwV,EAAA,GAAtDxO,EAAsDwO,EAAA,GACxFE,EAAS1O,EAAcnS,OAASmS,EAAc9G,MAAM,KAAO,GAC3DyV,EAAkBL,EAAkBvW,YACpC6W,EAAYF,EAAOpa,IAAI,SAAAua,GAAA,OT+BxB,SAAoCtR,EAAcvE,GAAY,IACzDX,EAAWkF,EAAXlF,OAER,OAAQA,EAAOC,MACf,KAAK1N,EAAUC,QACX,OAAQwN,EAAOoO,SACf,KAAK/b,EAAeC,WAEpB,QACI,OAAO,IAAI4d,GAAWhL,EAAcvE,GAE5C,KAAKpO,EAAUE,UACX,OAAQuN,EAAOoO,SACf,KAAKpc,EAAiBC,YAClB,OAAO,IAAIyc,GAAYxJ,EAAcvE,GACzC,KAAK3O,EAAiBE,SAClB,OAAO,IAAI4c,GAAS5J,EAAcvE,GACtC,KAAK3O,EAAiBI,OAClB,OAAO,IAAIwd,GAAO1K,EAAcvE,GACpC,QACI,OAAO,IAAI+N,GAAYxJ,EAAcvE,GAE7C,QACI,OAAO,IAAI+N,GAAYxJ,EAAcvE,IStDN8V,CAA2BH,EAAgBE,GAAMtR,aAAcvE,KAClG,OAAOrB,EAAWC,gBAAgBgX,EAAWL,IAmBpCQ,GAAqB,SAACC,EAAUC,EAAOC,IAhBZ,SAACD,EAAOC,GAAuC,IACzCC,EADa1V,EAA4BhI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAnB,GAAI2d,EAAe3d,UAAA,GAC/Eyd,IAAcrU,EAAeI,SAC7BgU,EAAMI,YAAYxhB,OAAS,GAC3BshB,EAAAF,EAAMI,aAAY9c,KAAlBqB,MAAAub,EAAAG,GAA0BF,KAE1BH,EAAMI,YAAY9c,KAAK,CACnBgd,GAAIL,EACJM,KAAM/V,EACNgW,SAAUL,IASlBM,CAAyBT,EAAOC,EADuDzd,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAnB,GAAmBA,UAAA,IAJlD,SAACud,EAAUW,GAAU,IAAAC,GAC1DA,EAAAD,EAAME,qBAAoBtd,KAA1BqB,MAAAgc,EAAAN,GAAkCN,EAASa,qBAA3C9a,OAAAua,GAAmEN,EAASK,eAK5ES,CAA0Bd,EAAUC,IAGlCc,aACDhlB,EAAcC,OAAS,CACpBglB,UAAW,CAAC,cACZC,SAAU,EAAC,GAAM,KAHnBC,GAAAC,GAKDplB,EAAcE,QAAU,CACrB+kB,UAAW,CAAC,oBACZC,SAAU,EAAC,GAAO,KAPpBC,GAAAC,GASDplB,EAAcG,IAAM,CACjB8kB,UAAW,CAAC,aAAc,oBAC1BC,SAAU,EAAC,GAAM,KAXnBE,IAeAC,GAAqB,SAACpX,EAAYnR,EAAGwoB,GACvC,IAA2B,IAAvBA,GAA4BxoB,IAAOwoB,EAAoB,EAAI,CAC3D,IAAMC,EAAKtX,EAAWnL,OAAS,EAE/BmL,EAAWsX,GAAStX,EAAWsX,GAAIpX,MAAM,KAAK,GAA9C,IAAoDrR,OAEpDmR,EAAWzG,KAAX,GAAmB1K,IAId0oB,GAA2B,SAACvX,EAAYwX,EAASxnB,GAC1D,IAEMynB,EAAgB,GAChBC,EAAgB,GAJ6CC,EAAAlC,GAM9BsB,GAAc/mB,GAAMinB,SANU,GAM5DW,EAN4DD,EAAA,GAM9CE,EAN8CF,EAAA,GAanE,OALA5X,EAAmBC,EAAY,SAACnR,GAC5B,IAAMipB,EAAgBN,EAAQ3oB,GAC9BipB,GAAiBF,GAAgBR,GAAmBK,EAAe5oB,GAT5C,IAUtBipB,GAAiBD,GAAgBT,GAAmBM,EAAe7oB,GAT7C,KAWpB,CACHmR,WAAYyX,EAActhB,KAAK,KAC/B4hB,iBAAkBL,EAAcvhB,KAAK,OAwChC6hB,GAAe,SAACC,EAAUC,EAAUzX,EAAQuV,EAAUf,GAC/D,IAAItI,EAAc,GACdC,EAAgB,kBAAMoJ,EAASrR,gBAC3B3U,EAASyQ,EAATzQ,KACFgQ,EAAaiY,EAAShU,YACtB5H,EAAS4b,EAASE,uBAAuB9b,OAQ/C,OAAO4Y,EAASjV,EAPS,SAAA5K,GAAA,OAAS8iB,EAC9BxD,GAAqBrY,EAAQjH,GAC7BA,EACAwX,EACAD,IAG0C3c,IAiB5CooB,GAAS,SAACjT,EAAK1G,EAAM4Z,GAGvB,IAFA,IAAIjoB,EAAMioB,EAAGlT,EAAK1G,EAAM,GAEf5P,EAAI,EAAGoN,EAAMkJ,EAAItQ,OAAQhG,EAAIoN,EAAKpN,IACvCuB,EAASA,EAAT,IAAgBioB,EAAGlT,EAAK1G,EAAM5P,GAElC,OAAOuB,GAGEkoB,GAAyB,SAACrC,EAAOsC,GAA4B,IAAhB9X,EAAgBhI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAP,GAC3D+f,EAAM,GACJtC,EAAYzV,EAAOyV,WAAavT,EAChC8V,EAAkBhY,EAAOgY,kBAAmB,EAC5CC,EA3BwB,SAACzC,GAC/B,IAAMgC,EAAWhC,EAAM0C,OAAM,GACvBrD,EAAoBW,EAAMkC,uBAShC,OARAF,EAAStP,eAAiB2M,EAAkBjZ,OAAOf,IAAI,SAAA2M,GAAA,OAAKA,EAAE7Y,SAAQ+G,KAAK,KAG3Emf,EAAkBtW,iBAAmB,KACrCsW,EAAkB7V,iBAAmB,KACrC6V,EAAkBlW,eAAiB,KACnC6Y,EAASnL,wBAAwB8L,wBAE1BX,EAgBaY,CAAmB5C,GACjC6C,EAAoBJ,EAAYK,kBAKlCP,EAHCD,EAAW1jB,OAGN0jB,EAAWjd,IAAI,SAAA0d,GAAA,OACbC,SACEvR,GAF0BuD,EAqCjC+N,GAnC2BE,UACpBC,EAAelO,EAAU8N,kBACzB1N,EAAa9b,OAAO4J,KAAK8R,EAAUvH,gBAAgBnE,gBACpD2J,OAAO,SAAA/Z,GAAA,OAAKA,KAAK2pB,IAChBM,EAAO/N,EAAWxW,OAClBwkB,EAAUhO,EAAW/P,IAAI,SAAAnM,GAAA,OAC3BgqB,EAAahqB,GAAGiG,QACdsW,EAAWnc,OAAO4J,KAAK8R,EAAUvH,gBAAgBxE,cAClDgK,OAAO,SAAA/Z,GAAA,OAAKA,KAAK2pB,IAChBQ,EAAcrO,EAAUvH,gBAAgB3E,YACxCN,EAAOiJ,EAAQjJ,KACfwP,EAASvC,EAAS9E,OAAO,SAACC,EAAK0S,GAEjC,OADA1S,EAAI0S,GAAKD,EAAYC,GAAGtL,SACjBpH,GACR,IACG2S,EAAY,GAElBP,EAAQ,SAAC9T,EAAK0H,EAAK/F,GAAX,OAAmB+F,EAAI1H,EAAI2B,KAC/BsS,GACA3a,EAAKjC,QAAQ,SAACqQ,GACV,IAAMzc,EAAMgoB,GAAOiB,EAASxM,EAAKoM,GACjCO,EAAUppB,GAAO,IAIzB6oB,EAAQ,SAAC9T,EAAK9I,EAAQyK,GAAd,OAAsBzK,EAAO8I,EAAI2B,IAAMhX,OACxC2O,EAAK5J,OAAS,SAACwH,GAClB,IAAMod,GAAUL,GAAOI,EAAUpB,GAAO/M,EAAYhP,EAAQ4c,IAE5D,OAAIR,EACO/M,EAASgO,MAAM,SAAAza,GAAA,OAAS5C,EAAO4C,GAAOnP,OAASme,EAAOhP,GAAO,IAChE5C,EAAO4C,GAAOnP,OAASme,EAAOhP,GAAO,MAAOwa,EAE7CA,GACP,kBAAM,GApCqB,IAACxO,EAC5BgO,EACEvR,EACAyR,EACA9N,EAEA+N,EACAC,EAEA3N,EAEA4N,EACA7a,EACAwP,EAIAuL,IAnBJ,CAAC,kBAAM,IAqDjB,OAVItD,IAAcvT,EACE+V,EAAYiB,OAAO,SAAAtd,GAAA,OAAUmc,EAAIkB,MAAM,SAAArB,GAAA,OAAMA,EAAGhc,MAAU,CACtEud,WAAW,IAGClB,EAAYiB,OAAO,SAAAtd,GAAA,OAAUmc,EAAIqB,KAAK,SAAAxB,GAAA,OAAMA,EAAGhc,MAAU,CACrEud,WAAW,KAQVE,GAAkB,SAAC9D,EAAU7J,GAAiD,IAAnCL,EAAmCrT,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAvB,SAAApE,GAAA,OAAOA,GAAKoM,EAAWhI,UAAA,GAEnFmhB,EACAnZ,EADAmZ,UAEE3N,EAAgB+J,EAAStS,gBAAgB3E,YAJwCgb,EASnF/B,GACAhC,EAAS2C,MAAMiB,GACf9N,EACArL,EACAuV,EACA,mBAAA5Z,EAAA3D,UAAA5D,OAAImlB,EAAJ1d,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAIyd,EAAJzd,GAAA9D,UAAA8D,GAAA,OAzJ+B,SAACyD,EAAYwX,EAASxnB,EAAMmc,EAAcF,GAC7E,IAAIoL,EAAoB,GAClB4C,EAAkB,GAClBC,EAAe,GAyBrB,OAvBAna,EAAmBC,EAAY,SAACnR,GAC5B,GAAI2oB,EAAQ3oB,GAAI,CACZ,IAAI4d,EAAO,GAEP0N,EAAe,CAAEhhB,KAAM,IAE3BgT,EAAa3P,QAAQ,SAACkQ,GAClB,IAAMjO,EAAOwN,EAAcS,GAAGnI,aAAa9F,KAAK5P,GAChD4d,EAAUA,EAAV,IAAkBhO,EAClB0b,EAAahhB,KAAKuT,GAAKjO,SAGGrL,IAA1B6mB,EAAgBxN,KAChBwN,EAAgBxN,GAAQ,GACxB4K,EAAkB5K,IAAS,EAC3ByN,EAAazN,GAAQ0N,GAGzB/C,GAAmB6C,EAAgBxN,GAAO5d,EAAGwoB,EAAkB5K,IAC/D4K,EAAkB5K,GAAQ5d,KAI3B,CACHorB,kBACAC,iBA2HsCE,aAAIJ,EAA3Bje,OAAA,CAAmCoQ,EAAcF,OAPhEgO,EAPmFF,EAOnFE,gBACAC,EARmFH,EAQnFG,aASEG,EAAY,GAoBlB,OAnBA9qB,OAAO4J,KAAK8gB,GAAiB5U,OAAO7I,QAAQ,SAACjG,GACzC,GAAI0jB,EAAgB1jB,GAAI,CACpB,IAAM+jB,EAAStE,EAAS2C,MAAMiB,GACxBW,EAAaL,EAAa3jB,GAChC+jB,EAAOrW,YAAcgW,EAAgB1jB,GAAGJ,KAAK,KAC7CmkB,EAAOxN,wBAAwB8L,wBAI3BgB,GACA7D,GAAmBC,EAAUsE,EAAQzY,EAAeC,OAAQrB,EAHtC,SAAApE,GAAA,OAAU8P,EAAauN,MAAM,SAAAhN,GAAA,OAAKrQ,EAAOqQ,GAAG5c,QAAUyqB,EAAWphB,KAAKuT,OAKhG4N,EAAOjE,YAAYiE,EAAOjE,YAAYxhB,OAAS,GAAG2hB,KAAO0D,EAAa3jB,GAEtE8jB,EAAU9gB,KAAK+gB,MAKhBD,GAEEG,GAAuB,SAACvC,EAAUjY,EAAYgW,EAAUyE,EAAcvC,GAC/ED,EAAShU,YAAcjE,EACvBiY,EAASnL,wBAAwB8L,wBACjC7C,GACIC,EACAiC,EACApW,EAAeC,OACd,CAAErB,OAAQga,GACTvC,IA+BGwC,GAAmB,SAAC1E,EAAU2E,EAAWla,EAAQma,GAC1D,IAAMN,EAAStE,EAAS2C,MAAMlY,EAAOmZ,WACjCiB,EAAgBF,EAiBpB,OAhBIla,EAAOzQ,OAAS+B,EAAcE,UAC9B4oB,EAAgBD,EAAU1R,OAAO,SAAAvB,GAAA,OAA+C,IAAlCgT,EAAUrhB,QAAQqO,MAIpE2S,EAAO3R,eAAiBkS,EAAc1kB,KAAK,KAC3CmkB,EAAOxN,wBAAwB8L,wBAE/B7C,GACIC,EACAsE,EACAzY,EAAeE,QACf,CAAE4Y,YAAWla,SAAQqa,gBAAiBD,GACtC,MAGGP,GAQES,GAAqB,SAACC,GAO/B,IALAA,EAAa9d,EAAQ,GAAI8d,IACT1b,OACZ0b,EAAW1b,KAAO1N,EAAUE,YAG3BkpB,EAAWvN,QACZ,OAAQuN,EAAW1b,MACnB,KAAK1N,EAAUC,QACXmpB,EAAWvN,QAAU/b,EAAeC,WACpC,MACJ,QACA,KAAKC,EAAUE,UACXkpB,EAAWvN,QAAUpc,EAAiBC,YAK9C,OAAO0pB,GA6BEC,GAA4B,SAAA5b,GAAA,OAAUA,EAAO/D,IAAI,SAAC0f,GAG3D,OA7B8B,SAACA,GAC/B,IAAME,EAA2B,CAACxpB,EAAeC,YAC3CwpB,EAAuB,CACzB9pB,EAAiBC,YACjBD,EAAiBI,OACjBJ,EAAiBE,SACjBF,EAAiBG,KAEb8N,EAAwB0b,EAAxB1b,KAAMmO,EAAkBuN,EAAlBvN,QAASre,EAAS4rB,EAAT5rB,KAEvB,OAAQkQ,GACR,KAAK1N,EAAUE,UACX,IAA+C,IAA3CqpB,EAAqB7hB,QAAQmU,GAC7B,MAAM,IAAI1J,MAAJ,qDAA+D0J,EAA/D,aAAmFre,EAAnF,UAEV,MACJ,KAAKwC,EAAUC,QACX,IAAmD,IAA/CqpB,EAAyB5hB,QAAQmU,GACjC,MAAM,IAAI1J,MAAJ,mDAA6D0J,EAA7D,aAAiFre,EAAjF,UAEV,MACJ,QACI,MAAM,IAAI2U,MAAJ,wCAAkDzE,EAAlD,aAAmElQ,EAAnE,WAMVgsB,CADAJ,EAAaD,GAAmBC,IAEzBA,KAeEK,GAAa,SAACC,EAAU7c,EAAMY,EAAQrF,GAC/CqF,EAAS4b,GAA0B5b,GACnCrF,EAAUzK,OAAOmR,OAAOnR,OAAOmR,OAAO,GAAI6a,IAAgBvhB,GAC1D,IAAMwhB,EAAcC,EAAUzhB,EAAQgX,YAEtC,IAAMwK,GAAsC,mBAAhBA,EACxB,MAAM,IAAIzX,MAAJ,mCAA6C/J,EAAQgX,WAArD,WANiD,IAAA0K,EAS3BF,EAAY/c,EAAMzE,GATS2hB,EAAAlG,GAAAiG,EAAA,GASpD7K,EAToD8K,EAAA,GAS5CC,EAT4CD,EAAA,IAZ/B,SAACtc,EAAQwc,GACrCxc,EAAO7C,QAAQ,SAACwe,GACZ,IAAMc,EAAcd,EAAWe,GAC/B,GAAKD,EAAL,CAEA,IAAMhV,EAAM+U,EAAWviB,QAAQ0hB,EAAW5rB,MAC1CysB,EAAW/U,GAAOgV,EAClBd,EAAW5rB,KAAO0sB,SACXd,EAAWe,MActBC,CAAiB3c,EAAQwR,GACzB,IAAMhS,EAAW4R,GAAamL,EAAevc,EAAQwR,GAG/CoL,EAAYtd,EAAWC,gBAAgBC,EAAU7E,EAAQ5K,MAC/DksB,EAASY,mBAAqBD,EAG9BX,EAASrX,YAAc2X,EAAc/mB,QAAU+mB,EAAc,GAAG/mB,OAAzC,MAAuD+mB,EAAc,GAAG/mB,OAAS,GAAM,GAG9G,IAAMsnB,EAAe,GAQrB,OAPApc,EAAmBub,EAASrX,YAAa,SAACpV,GACtCstB,EAAattB,GAAK6lB,GAAqBuH,EAAU5f,OAAQxN,KAE7DotB,EAAUG,oBAAsBD,EAEhCb,EAAS3S,eAAkBtJ,EAAO/D,IAAI,SAAAoR,GAAA,OAAKA,EAAEtd,OAAO+G,OACpDmlB,EAASe,YAAcriB,EAAQgX,aAAehgB,EAAWI,KAAOoN,EAAiBC,GAAQzE,EAAQgX,WAC1FsK,GAGExT,GAAgB,SAACzI,EAAQJ,GAGlC,IAFA,IAAIpQ,EAAI,EAEDA,EAAIwQ,EAAOxK,SAAUhG,EACxB,GAAIoQ,IAAUI,EAAOxQ,GAAGO,KACpB,MAAO,CACHkQ,KAAMD,EAAOxQ,GAAG4e,SAAWpO,EAAOxQ,GAAGyQ,KACrClK,MAAOvG,GAInB,OAAO,MA6BLytB,GAAgC,SAACtD,EAAW/N,GAC9C,IAAMsR,EAActR,EAAUuR,iBAC1BC,EAAiBzD,EAerB,OAbAuD,EAAY/f,QAAQ,SAAC+d,GACjB,GAAKA,EAAL,CADgC,IAMjBmC,EANiBC,EA7BF,SAACpC,GACnC,IAAIP,EAAS,GACT9D,SAEJ,OADAA,EAAYqE,EAAWhE,IAEvB,KAAK1U,EAAeC,OAChBkY,EAAS,CAACO,EAAW9D,UACrB,MACJ,KAAK5U,EAAeE,QAChBiY,EAAS,CAACO,EAAW/D,KAAKsE,iBAC1B,MACJ,KAAKjZ,EAAeG,QAChBkU,EAAY,UACZ8D,EAAS,CAACO,EAAW/D,KAAKoG,cAAc1c,MAAM,KAAMqa,EAAW9D,UAC/D,MACJ,QACIP,EAAY,KAGhB,MAAO,CACHA,YACA8D,UAa8B6C,CAAuBtC,GAA7CrE,EALwByG,EAKxBzG,UAAW8D,EALa2C,EAKb3C,OACnB,GAAI9D,EACAuG,GAAiBC,EAAAD,GAAevG,GAAftb,MAAA8hB,EAAApG,GAA6B0D,GAA7Bje,OAAA,CAAqC,CAClD6d,WAAW,SAKhB6C,GAWLK,GAAuB,SAAvBA,EAAwB7R,EAAW+N,GAA8C,IAAnCvY,EAAmChI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAA1B,GAAIskB,EAAsBtkB,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAP,GACtEukB,EAAqBD,EAAaC,mBAClCC,EAAgBF,EAAaE,eAAiB,GAEhDhS,IAAc+R,MAIAC,EAAcpoB,SAA+C,IAAtCooB,EAAc3jB,QAAQ2R,KAElDA,EAAUiS,kBAAkBlE,EAAWvY,GAEnCwK,EAAUkS,UAClB3gB,QAAQ,SAAC4gB,GACd,IAAMX,EAAiBH,GAA8BtD,EAAWoE,GAChEN,EAAqBM,EAAOX,EAAgBhc,EAAQsc,OAkB/CM,GAAqB,SAACpH,GAC/B,IADoD,IAAdqH,EAAc7kB,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAP,GACtCwd,EAAMsH,SACTD,EAAK/jB,KAAK0c,GACVA,EAAQA,EAAMsH,QAElB,OAAOD,GAGEE,GAA2B,SAACC,EAAaC,EAAYC,EAAgBld,GAC9E,IAAIgW,SACAuC,SACI4E,EAA4CD,EAA5CC,qBAAsBC,EAAsBF,EAAtBE,kBACxBC,EAAsBH,EAAeI,SACrCC,EAA8Bvd,EAAOud,4BAMvCC,EAAY,GAEhB,GAAoB,OAAhBR,IAA8C,IAAtBhd,EAAOyd,WAC/BD,EAAY,CAAC,CACTxH,SAAU,KAEdA,EAAW,OACR,KAAAnK,EACC6R,EAAkB5uB,OAAO6uB,OAAOR,EAAqBS,iBAC/B,IAAtBR,IACAM,EAAkBA,EAAgBjV,OAAO,SAAA/Z,GAAA,OAAKA,EAAEsR,OAAOsd,WAAaD,KAGxE,IAAMQ,EAAmBH,EAAgBjV,OAlB5B,SAACqV,GAEd,OADe9d,EAAO4C,UAAa,kBAAM,IAC3Bkb,EAAO9d,KAgBqCnF,IAAI,SAAAkjB,GAAA,OAAUA,EAAO/d,OAAOgW,WAEhFwG,EAAgB,GAEtB,IAA0B,IAAtBY,EAA6B,CAC7B,IAAMY,EAAwBlvB,OAAO6uB,OAAOR,EAAqBS,gBAEjEI,EAAsBjiB,QAAQ,SAACkiB,GAC3B,IAAMC,EAAaD,EAAUje,QACI,IAA7Bke,EAAWC,eAA2BD,EAAWH,SAAW/d,EAAO+d,QAC/DG,EAAWZ,WAAaD,IAC5Bb,EAAc1jB,KAAKmlB,EAAUzI,QAC7BQ,EAAWgI,EAAsBvV,OAAO,SAAA/Z,GAAA,OAAKA,IAAMuvB,IAAWpjB,IAAI,SAAAnM,GAAA,OAAKA,EAAEsR,OAAOgW,YACvE5hB,QAAUopB,EAAU1kB,KAAK,CAC9Bkd,WACAoI,OAAQH,EAAUzI,MAClBqH,KAAMD,GAAmBqB,EAAUzI,YAOnDQ,GAAWnK,EAAA,IAAGvQ,OAAHnB,MAAA0R,EAAA,GAAAvQ,OAAAua,GAAiBgI,GAAjB,CAAmCb,KAAcvU,OAAO,SAAA/Z,GAAA,OAAW,OAANA,IACxE8uB,EAAU1kB,KAAK,CACXkd,WACAwG,wBAAmBA,EAAnB3G,GAAqC7V,EAAOwc,eAAiB,OAIrE,IAAM6B,EAAYpB,EAAWzH,MAEvB8I,EAAaxvB,OAAOmR,OAAO,CAC7Bse,kBAAmBvB,EACnBK,uBACDrd,GAEGwe,EAAmBvB,EAAWwB,aAChClB,GAA+BiB,IAC/BjG,EAAYV,GAAuB2G,EAAkBxI,EAAU,CAC3DgC,gBAAiBuF,IAErBlB,GAAqBmC,EAAkBjG,EAAW+F,IAGtDd,EAAUzhB,QAAQ,SAAC2iB,GACf,IAAMC,EAAmB9G,GAAuBwG,EAAWK,EAAI1I,UACzD6G,EAAO6B,EAAI7B,KAEjB,GAAIA,EAAM,CACN,IAAM+B,EA3HO,SAACrG,EAAWsE,GACjC,IAAK,IAAIzuB,EAAI,EAAGoN,EAAMqhB,EAAKzoB,OAAQhG,EAAIoN,EAAKpN,IAAK,CAC7C,IAAMonB,EAAQqH,EAAKzuB,GACnBmqB,EAAYsD,GAA8BtD,EAAW/C,GAEzD,OAAO+C,EAsHuBsG,CAAiBF,EAAkB9B,EAAKiC,WAC9DJ,EAAIN,OAAO3B,kBAAkBmC,EAAeN,QAE5CjC,GAAqBgC,EAAWM,EAAkBL,EAAY,CAC1D9B,cAAekC,EAAIlC,cACnBD,mBAAoBgB,GAA+BiB,OAmDtDO,GAAyB,SAAC7E,EAAWC,EAAW6E,GACzD,IAAMC,EAAsB/E,EAAU/T,OAAO,SAACC,EAAK5H,GAM/C,MAL+B,WAA3BA,EAAM0gB,YAAYvwB,KAClByX,EAAItN,KAAJqB,MAAAiM,EAAAyP,GAAYsE,EAAU1R,OAAO,SAAAvB,GAAA,OAA0C,IAA7BA,EAAUiY,OAAO3gB,OACpDA,KAASwgB,GAChB5Y,EAAItN,KAAK0F,GAEN4H,GACR,IACH,OAAOvK,MAAMI,KAAK,IAAIsR,IAAI0R,IAAsBpkB,IAAI,SAAA2D,GAAA,OAASA,EAAM4Q,oQCnHxDgQ,cA/hBX,SAAAA,iGAAwBC,CAAA5sB,KAAA2sB,GACpB,IAAIE,SAEJ7sB,KAAKqqB,QAAU,KACfrqB,KAAKmjB,YAAc,GACnBnjB,KAAK2jB,oBAAsB,GAC3B3jB,KAAKiqB,UAAY,GANG,QAAA/gB,EAAA3D,UAAA5D,OAARmlB,EAAQ1d,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAARyd,EAAQzd,GAAA9D,UAAA8D,GAQE,IAAlByd,EAAOnlB,SAAkBkrB,EAAS/F,EAAO,cAAe6F,GAExD3sB,KAAKyV,eAAiBoX,EAAOpX,eAC7BzV,KAAK+Q,YAAc8b,EAAO9b,YAC1B/Q,KAAKmpB,YAAc0D,EAAO1D,YAC1BnpB,KAAKqqB,QAAUwC,EACf7sB,KAAKgpB,mBAAqBhpB,KAAKqqB,QAAQrB,mBACvChpB,KAAK8sB,gBAAkBhiB,IACvB9K,KAAK4Z,wBAAwB8L,0BAE7ByC,GAAUA,cAACnoB,MAAX6I,OAAoBie,IACpB9mB,KAAK8sB,gBAAkB9sB,KAAKgpB,mBAAmB9sB,KAC/C8D,KAAK4Z,wBAAwB8L,wBAC7B1lB,KAAK+sB,sBAAwB,CACzB5B,eAAgB,GAChB6B,iBAAkB,oDA0B1B,OAAOhtB,KAAKwQ,gBAAgBrH,OAAOf,IAAI,SAAAnM,GAAA,OAAKA,EAAEkQ,6CAY9C,OAAOnM,KAAK8sB,wDAIZ,OAAO9sB,KAAKitB,4DAMZ,OAFAjtB,KAAKitB,YAAc9K,GAAa,CAACniB,KAAK+Q,YAAa/Q,KAAKyV,gBACnDzV,KAAKilB,uBAAwBjlB,KAAK8sB,iBAChC9sB,oDAIP,OAAOA,KAAKgpB,gDAiCVkE,EAAU/c,GACZ,OAAOH,EAAahQ,KAAMktB,EAAU/c,uCAuB3B+c,GACT,OAAOld,EAAahQ,KAAMktB,EAAUrT,GAAkB7Z,KAAMktB,IAAW,iCAqBpEC,GACH,OAAOnT,GAAMha,KAAMmtB,sCAoBXC,GACR,OAAOhY,EAAWpV,KAAMotB,kCAkDpBpI,EAAUzX,GACd,IAAM8f,EAAY,CACdvwB,KAAM+B,EAAcC,OACpB4nB,WAAW,GAMf,OAJAnZ,EAASlR,OAAOmR,OAAO,GAAI6f,EAAW9f,IAC/BzQ,KAAOyQ,EAAOzQ,MAAQuwB,EAAUvwB,KD2BhB,SAACgmB,EAAUkC,EAAUuC,EAAc+F,GAC9D,IAAIC,EAAe,GAEbzwB,EAASyqB,EAATzqB,KAEAsqB,EAAStE,EAAS2C,MAAM6H,EAAY5G,WACpC8G,EAAmB1I,GACrBsC,EACApC,EACAuC,EACAzE,EACAuB,IAEEP,EAAYD,GAAc/mB,GAAMgnB,UAItC,OAFAwD,GAAqBF,EAAQoG,EAAiB1J,EAAU,IAAKhB,EAAUyE,EAAcvC,GAEjFlB,EAAUniB,OAAS,GACnB4rB,EAAezK,EAAS2C,MAAM6H,EAAY5G,WAC1CY,GAAqBiG,EAAcC,EAAiB1J,EAAU,IAAKhB,EAAUyE,EAAcvC,GACpF,CAACoC,EAAQmG,IAGbnG,EC/CIqG,CACHztB,KACAglB,EACAzX,EAJgB,CAAEmZ,UAAWnZ,EAAOmZ,8CA4BxC,OAAQ1mB,KAAK+Q,YAAYpP,SAAW3B,KAAKyV,eAAe9T,uCAUnC,IAAlB+kB,IAAkBnhB,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,KAAAA,UAAA,GACfwf,EAAW,IAAI/kB,KAAKysB,YAAYzsB,MAMtC,OALI0mB,EACA3B,EAAS2I,UAAU1tB,MAEnB+kB,EAAS2I,UAAU,MAEhB3I,kCA8CF0C,EAAWla,GAChB,IAAM8f,EAAY,CACdvwB,KAAM+B,EAAcC,OACpB4nB,WAAW,GAEfnZ,EAASlR,OAAOmR,OAAO,GAAI6f,EAAW9f,GACtC,IAAMgf,EAAcvsB,KAAK6lB,kBACnB6B,EAAYrrB,OAAO4J,KAAKsmB,GACtBzvB,EAASyQ,EAATzQ,KACF0vB,EAAsBF,GAAuB7E,EAAWC,EAAW6E,GAErExU,SAEAjb,IAAS+B,EAAcG,IASvB+Y,EAAY,CARUyP,GAAiBxnB,KAAMwsB,EAAqB,CAC9D1vB,KAAM+B,EAAcC,OACpB4nB,UAAWnZ,EAAOmZ,WACnBgB,GACkBF,GAAiBxnB,KAAMwsB,EAAqB,CAC7D1vB,KAAM+B,EAAcE,QACpB2nB,UAAWnZ,EAAOmZ,WACnBgB,IAIH3P,EADsByP,GAAiBxnB,KAAMwsB,EAAqBjf,EAAQma,GAI9E,OAAO3P,4CAIP,OAAO/X,KAAK2tB,6DAWZ,OAPA3tB,KAAK2tB,aAAe3tB,KAAKitB,YAAY9jB,OAAOuK,OAAO,SAACC,EAAKia,EAAUjyB,GAK/D,OAJAgY,EAAIia,EAAS1xB,QAAU,CACnBgG,MAAOvG,EACPkyB,IAAKD,EAASzhB,UAEXwH,GACR,IACI3T,uCAWPA,KAAKqqB,SAAWrqB,KAAKqqB,QAAQyD,YAAY9tB,MACzCA,KAAKqqB,QAAU,KACfrqB,KAAKiqB,UAAU3gB,QAAQ,SAAC4gB,GACpBA,EAAMG,QAAU,OAEpBrqB,KAAKiqB,UAAY,uCA6BRC,GACT,IAAItW,EAAM5T,KAAKiqB,UAAU8D,UAAU,SAAAC,GAAA,OAAWA,IAAY9D,KACjD,IAATtW,GAAa5T,KAAKiqB,UAAUxiB,OAAOmM,EAAK,qCAQjCqa,GACPjuB,KAAKqqB,SAAWrqB,KAAKqqB,QAAQyD,YAAY9tB,MACzCA,KAAKqqB,QAAU4D,EACfA,GAAUA,EAAOhE,UAAU5jB,KAAKrG,0CA4BhC,OAAOA,KAAKqqB,8CA6BZ,OAAOrqB,KAAKiqB,mDA4BZ,OAAOjqB,KAAKmjB,6DA4BZ,OAAOnjB,KAAK2jB,ozBCsRLhmB,eAtwBX,SAAAA,IAAsB,IAAAya,+FAAA8V,CAAAluB,KAAArC,GAAA,QAAAuL,EAAA3D,UAAA5D,OAANwF,EAAMiC,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAANlC,EAAMkC,GAAA9D,UAAA8D,GAAA,IAAAgO,mKAAA8W,CAAAnuB,MAAAoY,EAAAza,EAAAyd,WAAA/e,OAAAgf,eAAA1d,IAAA7B,KAAA4L,MAAA0Q,EAAA,CAAApY,MAAA6I,OACT1B,KADS,OAGlBkQ,EAAK+W,eAAiB,GAHJ/W,qUArCFsV,wCAuGX7lB,GAQLA,EAAUzK,OAAOmR,OAAO,GAPL,CACf6gB,MAAO,MACPhsB,UAAW,KACXisB,SAAS,EACTC,cAAc,EACdpc,KAAM,IAE8BrL,GACxC,IAAMqC,EAASnJ,KAAKilB,uBAAuB9b,OAErCqlB,EAAgB3a,EAAY/X,KAC9BkE,KACAA,KAAKilB,uBAAuB9b,OAC5BnJ,KAAK+Q,YACLjK,EAAQynB,aAAeplB,EAAOf,IAAI,SAAAnM,GAAA,OAAKA,EAAEC,SAAQ+G,OAASjD,KAAKyV,eAC/D3O,EAAQqL,KACR,CACI8B,WAA8B,WAAlBnN,EAAQunB,MACpBra,SAAUlN,EAAQwnB,UAI1B,IAAKxnB,EAAQzE,UACT,OAAOmsB,EAxBG,IA2BNnsB,EAAcyE,EAAdzE,UACAkJ,EAAuBijB,EAAvBjjB,KAAMY,EAAiBqiB,EAAjBriB,OAAQgI,EAASqa,EAATra,KAChBsa,EAAatiB,EAAO/D,IAAK,SAAA/E,GAAA,OAAKA,EAAEnH,OAEhCwyB,EADgBryB,OAAO4J,KAAK5D,GACAqR,OAAO,SAACC,EAAKvF,GAC3C,IAAMwF,EAAM6a,EAAWroB,QAAQgI,GAI/B,OAHa,IAATwF,GACAD,EAAItN,KAAK,CAACuN,EAAKvR,EAAU+L,KAEtBuF,GACR,IAgCH,MA9BsB,WAAlB7M,EAAQunB,MACRK,EAAYplB,QAAQ,SAACqlB,GACjB,IAAMC,EAAOD,EAAK,GACZE,EAAQF,EAAK,GAEnBpjB,EAAKqjB,GAAMtlB,QAAQ,SAAC2J,EAAO6b,GACvBvjB,EAAKqjB,GAAME,GAAYD,EAAM/yB,UACzBoE,EACA+S,EACAkB,EAAK2a,GACL3iB,EAAOyiB,QAKnBrjB,EAAKjC,QAAQ,SAAC2J,EAAO6b,GACjBJ,EAAYplB,QAAQ,SAACqlB,GACjB,IAAMC,EAAOD,EAAK,GACZE,EAAQF,EAAK,GAEnB1b,EAAM2b,GAAQC,EAAM/yB,UAChBoE,EACA+S,EAAM2b,GACNza,EAAK2a,GACL3iB,EAAOyiB,QAMhBJ,oCASP,IAAM1hB,EAAa9M,KAAK+Q,YAClBge,EAAM,GAERjiB,EAAWnL,QACMmL,EAAWE,MAAM,KAEzB1D,QAAQ,SAAC8J,GAAQ,IAAA4b,EACH5b,EAAIpG,MAAM,KAAK5E,IAAIO,QADhBsmB,EAAAC,GAAAF,EAAA,GACjB7hB,EADiB8hB,EAAA,GACV7hB,EADU6hB,EAAA,GAGtB7hB,OAAclN,IAARkN,EAAoBA,EAAMD,EAChC4hB,EAAI1oB,KAAJqB,MAAAqnB,EAAAI,GAAY/lB,MAAMgE,EAAMD,EAAQ,GAAGiiB,OAAOhnB,IAAI,SAACoR,EAAG5F,GAAJ,OAAYzG,EAAQyG,QAI1E,OAAOmb,kCA0BFM,GAAwD,IAA7CrX,EAA6CzS,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAlC,GAAIgI,EAA8BhI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAArB,CAAEmhB,WAAW,GAC/CgD,KAAmB2F,EAAUpsB,OAC/B6jB,EAAS,CAAC9mB,KAAMqvB,EAAWrX,GACzBmB,EAAerB,gBAAWgP,GAgBhC,OAdAjE,GACI7iB,KACAmZ,EACAxK,EAAeG,QACf,CAAEugB,YAAW3F,gBAAejR,eAAgBZ,GAAaY,kBACzDT,GAGAzK,EAAOmZ,UACPvN,EAAauU,UAAU1tB,MAEvBmZ,EAAauU,UAAU,MAGpBvU,+BAsDLpF,GAA+C,IAA/BxG,EAA+BhI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAtB,CAAEmhB,WAAW,GAClC4I,EAAUtvB,KAAKgmB,QAAQ,CACzBqI,MAAO,MACPlc,KAAM4B,IAGJwb,EAAe,CADND,EAAQnjB,OAAO/D,IAAI,SAAA2D,GAAA,OAASA,EAAM7P,QACnB2M,OAAOymB,EAAQ/jB,MAEvCikB,EAAW,IAAIxvB,KAAKysB,YAAY8C,EAAcD,EAAQnjB,OAAQ,CAAE2R,WAAY,WAgBlF,OAdA+E,GACI7iB,KACAwvB,EACA7gB,EAAeO,KACf3B,EACAwG,GAGAxG,EAAOmZ,UACP8I,EAAS9B,UAAU1tB,MAEnBwvB,EAAS9B,UAAU,MAGhB8B,oCAwBApjB,EAAMtF,GACbsF,EAAOA,GAAQpM,KAAKmpB,YACpBriB,EAAUzK,OAAOmR,OAAO,GAAI,CAAE0T,eAAgB,KAAOpa,GAErD,IAAMqC,EAASnJ,KAAKwQ,gBAAgBrH,OAC9BsmB,EAAUtmB,EAAOf,IAAI,SAAA2M,GAAA,OAAKA,EAAE2T,kBAC5BgH,EAAYD,EAAQ,GAAG9tB,OACzBguB,SACAC,SACAC,SAEJ,GAAIzjB,IAAStO,EAAWC,UAEpB,IADA4xB,EAAiB,GACZC,EAAS,EAAGA,EAASF,EAAWE,IAAU,CAC3C,IAAMjW,EAAM,GACZ,IAAKkW,EAAS,EAAGA,EAAS1mB,EAAOxH,OAAQkuB,IACrClW,EAAIxQ,EAAO0mB,GAAQ3zB,QAAUuzB,EAAQI,GAAQD,GAEjDD,EAAetpB,KAAKsT,QAErB,GAAIvN,IAAStO,EAAWE,QAAS,CAEpC,IADA2xB,EAAiB,CAACxmB,EAAOf,IAAI,SAAA2M,GAAA,OAAKA,EAAE7Y,SAAQ+G,KAAK6D,EAAQoa,iBACpD0O,EAAS,EAAGA,EAASF,EAAWE,IAAU,CAC3C,IAAMjW,EAAM,GACZ,IAAKkW,EAAS,EAAGA,EAAS1mB,EAAOxH,OAAQkuB,IACrClW,EAAItT,KAAKopB,EAAQI,GAAQD,IAE7BD,EAAetpB,KAAKsT,EAAI1W,KAAK6D,EAAQoa,iBAEzCyO,EAAiBA,EAAe1sB,KAAK,UAClC,IAAImJ,IAAStO,EAAWG,QAU3B,MAAM,IAAI4S,MAAJ,aAAuBzE,EAAvB,qBARN,IADAujB,EAAiB,CAACxmB,EAAOf,IAAI,SAAA2M,GAAA,OAAKA,EAAE7Y,UAC/B0zB,EAAS,EAAGA,EAASF,EAAWE,IAAU,CAC3C,IAAMjW,EAAM,GACZ,IAAKkW,EAAS,EAAGA,EAAS1mB,EAAOxH,OAAQkuB,IACrClW,EAAItT,KAAKopB,EAAQI,GAAQD,IAE7BD,EAAetpB,KAAKsT,IAM5B,OAAOgW,mCAGD5jB,GACN,IAAM0I,EAAY1I,EAAM7P,OACxB8D,KAAKyV,gBAAL,IAA2BhB,EAC3B,IAAM2N,EAAoBpiB,KAAKgpB,mBACzB8G,EAAqB1N,EAAkB8G,oBAE7C,GAAK9G,EAAkBvW,YAAYE,EAAM7P,QAKlC,CACH,IAAMqN,EAAa6Y,EAAkBjZ,OAAO4kB,UAAU,SAAAgC,GAAA,OAAaA,EAAU7zB,SAAWuY,IACxFlL,GAAc,IAAM6Y,EAAkBjZ,OAAOI,GAAcwC,QAN3DqW,EAAkBjZ,OAAO9C,KAAK0F,GAC9B+jB,EAAmBxmB,QAAQ,SAACjB,EAAK1M,GAC7B0M,EAAI0D,EAAM7P,QAAU,IAAIsQ,EAAMT,EAAMsF,aAAa9F,KAAK5P,GAAIoQ,KAalE,OALAqW,EAAkBtW,iBAAmB,KACrCsW,EAAkB7V,iBAAmB,KACrC6V,EAAkBlW,eAAiB,KAEnClM,KAAK4Z,wBAAwB8L,wBACtB1lB,+CAuCQmM,EAAQ6jB,EAAYziB,GAAQ,IAAAmK,EAAA1X,KAC3CmM,EAAS0b,GAAmB1b,GAC5BoB,EAASlR,OAAOmR,OAAO,GAAI,CAAEkZ,WAAW,EAAMuJ,YAAY,GAAS1iB,GAEnE,IAAM0Y,EAAejmB,KAAK6lB,kBACpBqK,EAAUF,EAAWlb,MAAM,EAAGkb,EAAWruB,OAAS,GAClDwuB,EAAaH,EAAWA,EAAWruB,OAAS,GAElD,GAAIskB,EAAa9Z,EAAOjQ,QAAUqR,EAAO0iB,WACrC,MAAM,IAAIpf,MAAS1E,EAAOjQ,KAApB,sCAGV,IAAMk0B,EAAkBF,EAAQ9nB,IAAI,SAAC2D,GACjC,IAAMskB,EAAYpK,EAAala,GAC/B,IAAKskB,EAED,MAAM,IAAIxf,MAAS9E,EAAb,gCAEV,OAAOskB,EAAUnuB,QAGfujB,EAAQzlB,KAAKylB,MAAMlY,EAAOmZ,WAE1B4J,EAAK7K,EAAMjV,gBAAgBrH,OAC3BonB,EAAiBH,EAAgBhoB,IAAI,SAAAwL,GAAA,OAAO0c,EAAG1c,KAEjD6F,EAAc,GACdC,EAAgB,kBAAMhC,EAAKjG,gBAEzB+e,EAAiB,GACvB3jB,EAAmB4Y,EAAM1U,YAAa,SAACpV,GACnC,IAAM80B,EAAaF,EAAenoB,IAAI,SAAA2D,GAAA,OAASA,EAAMsF,aAAa9F,KAAK5P,KACvE60B,EAAe70B,GAAKw0B,kBAAcM,GAAd5nB,OAAA,CAA0BlN,EAAG+d,EAAeD,OAhCzB,IAAAiX,EAkC3BnT,GAAa,CAACiT,GAAiB,CAACrkB,GAAS,CAACA,EAAOjQ,OAA1D6P,EAlCoCmjB,GAAAwB,EAAA,MA6C3C,OAVAjL,EAAMkL,SAAS5kB,GAEf8W,GACI7iB,KACAylB,EACA9W,EAAeK,QACf,CAAEzB,OAAQpB,EAAQhD,OAAQ+mB,GAC1BC,GAGG1K,oCAWA8E,GAA2D,IAA9Chd,EAA8ChI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAArC,GAAIqrB,EAAiCrrB,UAAA,GAAjBsmB,EAAiBtmB,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAJ,GACxDsrB,EAAkBtjB,EAAOsjB,gBACzBjG,EAAsBrd,EAAOsd,SAC7BiG,EAAUvjB,EAAOujB,QACjBlF,EFXkB,SAAC7I,GAC7B,KAAOA,EAAMsH,SACTtH,EAAQA,EAAMsH,QAElB,OAAOtH,EEOegO,CAAiB/wB,MAC7B0qB,EAAuBkB,EAAUmB,sBAEjCvC,EAAa,CACfwB,aFtBuB,SAACjJ,GAChC,KAAOA,EAAMsH,SAAWtH,EAAMI,YAAY6N,KAAK,SAAA/0B,GAAA,OAAKA,EAAEonB,KAAO1U,EAAeG,WACxEiU,EAAQA,EAAMsH,QAElB,OAAOtH,EEgBsBkO,CAAoBjxB,MAGzC+iB,MAAO6I,GAgBX,OAbAgF,GFqG0B,SAAClG,GAA6C,IAAvBnd,EAAuBhI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAd,GAAIwd,EAAUxd,UAAA,GACxE2rB,SACEL,EAAkBtjB,EAAOsjB,gBACzBtN,EAAWhW,EAAOgW,SAClBrmB,EAASqQ,EAAO+d,OAAhB,IAA0B/d,EAAOsd,SAGnCqG,EADAL,EACkBnG,EAAqBS,eAErBT,EAAqBsC,iBAG1B,OAAbzJ,SACO2N,EAAgBh0B,GAEvBg0B,EAAgBh0B,GAAO,CACnB6lB,QACAxV,UEtHc4jB,CAAmBzG,EAAsBnd,EAAQvN,MACnEsqB,GAAyBC,EAAaC,EAAY,CAAEE,uBAAsBG,SAAUD,GAChFvuB,OAAOmR,OAAO,CACVsjB,WACDvjB,IAEHsjB,GF2E6B,SAACnG,EAAsBF,EAAYC,GACxE,IAAMuC,EAAmBtC,EAAqBsC,iBAE9C,IAAK,IAAM1B,KAAU0B,EAAkB,CACnC,IACMvB,EADYuB,EAAiB1B,GACN/d,OACvBqd,EAAsBH,EAAeld,OAAOsd,SAC5CuG,GAAwB3G,EAAeoB,WAAWuF,uBACpD3G,EAAeoB,WAAWuF,sBAAsB3F,EAAYhB,EAAeld,QAC/E,GAAIke,EAAWZ,WAAaD,GAAuBwG,EAAuB,CACtE,IAAMC,EAAgB5F,EAAWlI,SACjC+G,GAAyB+G,EAAe7G,EAAY,CAChDE,uBACAC,mBAAmB,EACnBE,SAAUD,GACXa,KEzFH6F,CAA0B5G,EAAsBF,EAAY,CACxDjd,SACAse,eAID7rB,gCAUPuxB,EAAWxkB,GACX,OAAQwkB,GACR,IrClkBmB,cqCmkBfvxB,KAAKouB,eAAe/nB,KAAK0G,GAG7B,OAAO/M,yCASEuxB,GACT,OAAQA,GACR,IrCjlBmB,cqCklBfvxB,KAAKouB,eAAiB,GAI1B,OAAOpuB,+CAUQ8lB,EAAWgL,GAAS,IAAAhV,EAAA9b,KACfA,KAAKouB,eACX9kB,QAAQ,SAAA6b,GAAA,OAAMA,EAAGrpB,KAAKggB,EAAMgK,EAAWgL,iCA8CpDU,EAAkBjkB,GACnB,IAAM0Y,EAAejmB,KAAK6lB,kBAE1B,IAAKI,EAAauL,GACd,MAAM,IAAI3gB,MAAJ,SAAmB2gB,EAAnB,kBAGV,IAAMC,EAAelkB,EAAOrR,MAAWs1B,EAAlB,UAErB,GAAIvL,EAAawL,GACb,MAAM,IAAI5gB,MAAJ,SAAmB4gB,EAAnB,mBAGV,IAb2BC,EtCrmB5B,SAAgCC,EAAc7kB,EAAYS,GAAQ,IAC/DY,EAA4CZ,EAA5CY,QAASyjB,EAAmCrkB,EAAnCqkB,UAAW1jB,EAAwBX,EAAxBW,QAASf,EAAeI,EAAfJ,MAAOC,EAAQG,EAARH,IAD2BykB,EAEhDF,EAAa5W,SAFmC+W,EAAAC,EAAAF,EAAA,GAE9DG,EAF8DF,EAAA,GAExDG,EAFwDH,EAAA,GAIhE3jB,IACDhB,EAAmB,IAAVA,KAAiBA,GAASA,EAAQ6kB,GAASA,EAAO7kB,EAC3DC,EAAe,IAARA,KAAeA,GAAOA,EAAM6kB,GAAUA,EAAO,EAAK7kB,EAErDwkB,IACA1jB,EAAUlK,KAAKkuB,KAAKluB,KAAKmuB,IAAI/kB,EAAMD,GAASykB,IAGhDzjB,EAAUF,EAAgBC,EAASf,EAAOC,IAG1Ce,EAAQ,GAAK6jB,GACb7jB,EAAQvG,QAAQoqB,GAEhB7jB,EAAQA,EAAQxM,OAAS,IAAMswB,GAC/B9jB,EAAQ9H,KAAK4rB,EAAO,GAIxB,IADA,IAAM3jB,EAAe,GACZ3S,EAAI,EAAGA,EAAIwS,EAAQxM,OAAS,EAAGhG,IACpC2S,EAAajI,KAAK,CACd8G,MAAOgB,EAAQxS,GACfyR,IAAKe,EAAQxS,EAAI,KAIzB,IAAMy2B,EAAa,GAYnB,OAXAvlB,EAAmBC,EAAY,SAACnR,GAC5B,IAAMsX,EAAQ0e,EAAatgB,aAAa9F,KAAK5P,GAC7C,GAAIsX,aAAiB5F,EACjB+kB,EAAW/rB,KAAK4M,OADpB,CAKA,IAAMzR,EAAQ6M,EAAgBC,EAAc2E,GAC5Cmf,EAAW/rB,KAAQ7E,EAAM2L,MAAzB,IAAkC3L,EAAM4L,QAGrC,CAAEglB,aAAYnW,KAAM9N,GsCykBMkkB,CADRryB,KAAKwQ,gBAAgB3E,YAAY2lB,GACWxxB,KAAK+Q,YAAaxD,GAA3E6kB,EAdmBV,EAcnBU,WAAYnW,EAdOyV,EAcPzV,KAEdqW,EAAW/U,GAAa,CAAC6U,GAAa,CACxC,CACIl2B,KAAMu1B,EACNrlB,KAAM1N,EAAUE,UAChB2b,QAASpc,EAAiBI,OAC1B0d,SACA,CAACwV,IAAe,GAElBhM,EAAQzlB,KAAKylB,MAAMlY,EAAOmZ,WAWhC,OAVAjB,EAAMkL,SAAS2B,GAEfzP,GACI7iB,KACAylB,EACA9W,EAAeM,IACd,CAAEuiB,mBAAkBjkB,SAAQkkB,gBAC5B,MAGEhM,yCA8BP,OAAO,IAAI9nB,EAHEqC,KAAKuyB,UAAUz0B,EAAWC,WACxBiC,KAAKwyB,gDA+CZvZ,EAAcL,EAAWrL,GACjC,IAAM0Y,EAAejmB,KAAK6lB,kBAE1B5M,EAAa3P,QAAQ,SAACmL,GAClB,IAAKwR,EAAaxR,GACd,MAAM,IAAI5D,MAAJ,SAAmB4D,EAAnB,kCAId,IAAM4Y,EAAY,CACdvwB,KAAM+B,EAAcC,OACpB4nB,WAAW,GAKf,OAFAnZ,EAASlR,OAAOmR,OAAO,GAAI6f,EAAW9f,GAE/BqZ,GAAgB5mB,KAAMiZ,EAAcL,EAAWrL,2CAuCG,IAA9CklB,EAA8CltB,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAA/B,GAAImtB,EAA2BntB,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAZ,GAAIgI,EAAQhI,UAAA,GACnD8nB,EAAY,CACdvwB,KAAM+B,EAAcC,OACpB4nB,WAAW,GAET6F,EAAcvsB,KAAK6lB,kBACnB6B,EAAYrrB,OAAO4J,KAAKsmB,GACxBoG,EAA0B,CAAC,CAACD,IAalC,OAXAnlB,EAASlR,OAAOmR,OAAO,GAAI6f,EAAW9f,IACtCklB,EAAeA,EAAa9wB,OAAS8wB,EAAe,CAAC,KAGxCnpB,QAAQ,SAACspB,EAAUj3B,GAC5Bg3B,EAAwBh3B,GAAK2wB,GAAsBA,aAC3CsG,GADqBzD,GACRuD,IACjBhL,EACA6E,KFpfgB,SAACzJ,EAAU+P,EAActlB,EAAQma,GAAjC,OAC5BmL,EAAazqB,IAAI,SAAA0qB,GAAA,OACbtL,GAAiB1E,EAAUgQ,EAAYvlB,EAAQma,KEqfxCqL,CAAiB/yB,KAAM2yB,EAAyBplB,EAAQma,wDAluBhCna,GAC/B,OAAOF,EAAkBK,iBAAiBH,oCAf1C,OAAOsK,YC3FA5B,GAAoDM,GAApDN,IAAKG,GAA+CG,GAA/CH,IAAKO,GAA0CJ,GAA1CI,IAAKE,GAAqCN,GAArCM,IAAKmc,GAAgCzc,GAAhCyc,MAAOC,GAAyB1c,GAAzB0c,KAAMC,GAAmB3c,GAAnB2c,MAAYC,GAAO5c,GAAZ6c,ICsBjDC,GAAY,CACdC,QtC8LmB,mBAAAC,EAAAhuB,UAAA5D,OAAI6xB,EAAJpqB,MAAAmqB,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAID,EAAJC,GAAAluB,UAAAkuB,GAAA,OACnB,SAAC9d,GAAqC,IAAjCpI,EAAiChI,UAAA5D,OAAA,QAAAzB,IAAAqF,UAAA,GAAAA,UAAA,GAAxB,CAAEmhB,WAAW,GACnBgN,EAAY/d,EACZge,SACEtK,EAAc,GA8BpB,OA5BAmK,EAAWlqB,QAAQ,SAAC0Z,GAChB0Q,EAAY1Q,EAAU0Q,GACtBrK,EAAYhjB,KAAZqB,MAAA2hB,wHAAAuK,CAAoBF,EAAUvQ,cACzBwQ,IACDA,EAAaD,KAIjBC,GAAcA,IAAeD,GAC7BC,EAAWE,UAIfH,EAAU/P,oBAAsB,GAChCd,GACIlN,EACA+d,EACA/kB,EAAeI,QACf,KACAsa,GAGA9b,EAAOmZ,UACPgN,EAAUhG,UAAU/X,GAEpB+d,EAAUhG,UAAU,MAGjBgG,IsC/NXI,ItC4He,mBAAAC,EAAAxuB,UAAA5D,OAAIwF,EAAJiC,MAAA2qB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAI7sB,EAAJ6sB,GAAAzuB,UAAAyuB,GAAA,OAAa,SAAAre,GAAA,OAAMA,EAAGme,IAAHpsB,MAAAiO,EAAUxO,KsC3H5Csf,OtCgCkB,mBAAAvd,EAAA3D,UAAA5D,OAAIwF,EAAJiC,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAIlC,EAAJkC,GAAA9D,UAAA8D,GAAA,OAAa,SAAAsM,GAAA,OAAMA,EAAG8Q,OAAH/e,MAAAiO,EAAaxO,KsC/BlD8sB,QtC+DmB,mBAAAC,EAAA3uB,UAAA5D,OAAIwF,EAAJiC,MAAA8qB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAIhtB,EAAJgtB,GAAA5uB,UAAA4uB,GAAA,OAAa,SAAAxe,GAAA,OAAMA,EAAGse,QAAHvsB,MAAAiO,EAAcxO,KsC9DpD2Q,QtCsJmB,mBAAAsc,EAAA7uB,UAAA5D,OAAIwF,EAAJiC,MAAAgrB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAIltB,EAAJktB,GAAA9uB,UAAA8uB,GAAA,OAAa,SAAA1e,GAAA,OAAMA,EAAGmC,QAAHpQ,MAAAiO,EAAcxO,KsCrJpDmtB,kBCvB6B,mBAAAprB,EAAA3D,UAAA5D,OAAIwF,EAAJiC,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAIlC,EAAJkC,GAAA9D,UAAA8D,GAAA,OAAa,SAAAsM,GAAA,OAAMA,EAAG2e,kBAAH5sB,MAAAiO,EAAwBxO,KDwBxEgL,KCfgB,mBAAA+hB,EAAA3uB,UAAA5D,OAAIwF,EAAJiC,MAAA8qB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAIhtB,EAAJgtB,GAAA5uB,UAAA4uB,GAAA,OAAa,SAAAxe,GAAA,OAAMA,EAAGxD,KAAHzK,MAAAiO,EAAWxO,KDgB9C6I,eACAoF,aACAmf,YE/BG,SAAsBra,EAAYC,GACrC,OAAOnK,EAAakK,EAAYC,EAAYN,GAAkBK,EAAYC,IAAa,IF+BvFF,iBACAG,kBACAoa,c3BxBG,SAAwBta,EAAYC,EAAYhK,GACnD,OAAO6J,GAAMC,GAAcC,EAAYC,EAAYhK,GAAWiK,GAAeF,EAAYC,EAAYhK,K2BwBrG6J,UAGEya,QAAcA,QACpBp4B,OAAOmR,OAAO7P,GAAW,CACrB01B,aACAqB,QACA/lB,iBACA7O,oBACAhC,aACAe,gBACAwO,oBACAonB,YACDE,GAEYh3B","file":"datamodel.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"DataModel\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"DataModel\"] = factory();\n\telse\n\t\troot[\"DataModel\"] = factory();\n})(window, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 1);\n","const DataModel = require('./export');\n\nmodule.exports = DataModel.default ? DataModel.default : DataModel;\n","/**\n * DataFormat Enum defines the format of the input data.\n * Based on the format of the data the respective adapter is loaded.\n *\n * @readonly\n * @enum {string}\n */\nconst DataFormat = {\n    FLAT_JSON: 'FlatJSON',\n    DSV_STR: 'DSVStr',\n    DSV_ARR: 'DSVArr',\n    AUTO: 'Auto'\n};\n\nexport default DataFormat;\n","/**\n * DimensionSubtype enum defines the sub types of the Dimensional Field.\n *\n * @readonly\n * @enum {string}\n */\nconst DimensionSubtype = {\n    CATEGORICAL: 'categorical',\n    TEMPORAL: 'temporal',\n    GEO: 'geo',\n    BINNED: 'binned'\n};\n\nexport default DimensionSubtype;\n","/**\n * MeasureSubtype enum defines the sub types of the Measure Field.\n *\n * @readonly\n * @enum {string}\n */\nconst MeasureSubtype = {\n    CONTINUOUS: 'continuous'\n};\n\nexport default MeasureSubtype;\n","/**\n * FieldType enum defines the high level field based on which visuals are controlled.\n * Measure in a high level is numeric field and Dimension in a high level is string field.\n *\n * @readonly\n * @enum {string}\n */\nconst FieldType = {\n    MEASURE: 'measure',\n    DIMENSION: 'dimension'\n};\n\nexport default FieldType;\n","/**\n * Filtering mode enum defines the filering modes of DataModel.\n *\n * @readonly\n * @enum {string}\n */\nconst FilteringMode = {\n    NORMAL: 'normal',\n    INVERSE: 'inverse',\n    ALL: 'all'\n};\n\nexport default FilteringMode;\n","/**\n * Group by function names\n *\n * @readonly\n * @enum {string}\n */\nconst GROUP_BY_FUNCTIONS = {\n    SUM: 'sum',\n    AVG: 'avg',\n    MIN: 'min',\n    MAX: 'max',\n    FIRST: 'first',\n    LAST: 'last',\n    COUNT: 'count',\n    STD: 'std'\n};\n\nexport default GROUP_BY_FUNCTIONS;\n","/**\n * Creates a JS native date object from input\n *\n * @param {string | number | Date} date Input using which date object to be created\n * @return {Date} : JS native date object\n */\nfunction convertToNativeDate (date) {\n    if (date instanceof Date) {\n        return date;\n    }\n\n    return new Date(date);\n}\n/**\n * Apply padding before a number if its less than 1o. This is used when constant digit's number to be returned\n * between 0 - 99\n *\n * @param {number} n Input to be padded\n * @return {string} Padded number\n */\nfunction pad (n) {\n    return (n < 10) ? (`0${n}`) : n;\n}\n/*\n * DateFormatter utility to convert any date format to any other date format\n * DateFormatter parse a date time stamp specified by a user abiding by rules which are defined\n * by user in terms of token. It creates JS native date object from the user specified format.\n * That native date can also be displayed\n * in any specified format.\n * This utility class only takes care of format conversion only\n */\n\n/*\n * Escapes all the special character that are used in regular expression.\n * Like\n * RegExp.escape('sgfd-$') // Output: sgfd\\-\\$\n *\n * @param text {String} : text which is to be escaped\n */\nRegExp.escape = function (text) {\n    return text.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&');\n};\n\n/**\n * DateTimeFormatter class to convert any user format of date time stamp to any other format\n * of date time stamp.\n *\n * @param {string} format Format of the date given. For the above date,\n * 'year: %Y, month: %b, day: %d'.\n * @class\n */\n/* istanbul ignore next */ function DateTimeFormatter (format) {\n    this.format = format;\n    this.dtParams = undefined;\n    this.nativeDate = undefined;\n}\n\n// The identifier of the tokens\nDateTimeFormatter.TOKEN_PREFIX = '%';\n\n// JS native Date constructor takes the date params (year, month, etc) in a certail sequence.\n// This defines the sequence of the date parameters in the constructor.\nDateTimeFormatter.DATETIME_PARAM_SEQUENCE = {\n    YEAR: 0,\n    MONTH: 1,\n    DAY: 2,\n    HOUR: 3,\n    MINUTE: 4,\n    SECOND: 5,\n    MILLISECOND: 6\n};\n\n/*\n * This is a default number parsing utility. It tries to parse a number in integer, if parsing is unsuccessful, it\n * gives back a default value.\n *\n * @param: defVal {Number} : Default no if the parsing to integer is not successful\n * @return {Function} : An closure function which is to be called by passing an the value which needs to be parsed.\n */\nDateTimeFormatter.defaultNumberParser = function (defVal) {\n    return function (val) {\n        let parsedVal;\n        if (isFinite(parsedVal = parseInt(val, 10))) {\n            return parsedVal;\n        }\n\n        return defVal;\n    };\n};\n\n/*\n * This is a default number range utility. It tries to find an element in the range. If not found it returns a\n * default no as an index.\n *\n * @param: range {Array} : The list which is to be serached\n * @param: defVal {Number} : Default no if the serach and find does not return anything\n * @return {Function} : An closure function which is to be called by passing an the value which needs to be found\n */\nDateTimeFormatter.defaultRangeParser = function (range, defVal) {\n    return (val) => {\n        let i;\n        let l;\n\n        if (!val) { return defVal; }\n\n        const nVal = val.toLowerCase();\n\n        for (i = 0, l = range.length; i < l; i++) {\n            if (range[i].toLowerCase() === nVal) {\n                return i;\n            }\n        }\n\n        if (i === undefined) {\n            return defVal;\n        }\n        return null;\n    };\n};\n\n/*\n * Defines the tokens which are supporter by the dateformatter. Using this definitation a value gets extracted from\n * the user specifed date string. This also formats the value for display purpose from native JS date.\n * The definition of each token contains the following named properties\n * {\n *     %token_name% : {\n *         name: name of the token, this is used in reverse lookup,\n *         extract: a function that returns the regular expression to extract that piece of information. All the\n *                  regex should be gouped by using ()\n *         parser: a function which receives value extracted by the above regex and parse it to get the date params\n *         formatter: a formatter function that takes milliseconds or JS Date object and format the param\n *                  represented by the token only.\n *     }\n * }\n *\n * @return {Object} : Definition of the all the supported tokens.\n */\nDateTimeFormatter.getTokenDefinitions = function () {\n    const daysDef = {\n        short: [\n            'Sun',\n            'Mon',\n            'Tue',\n            'Wed',\n            'Thu',\n            'Fri',\n            'Sat'\n        ],\n        long: [\n            'Sunday',\n            'Monday',\n            'Tuesday',\n            'Wednesday',\n            'Thursday',\n            'Friday',\n            'Saturday'\n        ]\n    };\n    const monthsDef = {\n        short: [\n            'Jan',\n            'Feb',\n            'Mar',\n            'Apr',\n            'May',\n            'Jun',\n            'Jul',\n            'Aug',\n            'Sep',\n            'Oct',\n            'Nov',\n            'Dec'\n        ],\n        long: [\n            'January',\n            'February',\n            'March',\n            'April',\n            'May',\n            'June',\n            'July',\n            'August',\n            'September',\n            'October',\n            'November',\n            'December'\n        ]\n    };\n\n    const definitions = {\n        H: {\n            // 24 hours format\n            name: 'H',\n            index: 3,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n\n                return d.getHours().toString();\n            }\n        },\n        l: {\n            // 12 hours format\n            name: 'l',\n            index: 3,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const hours = d.getHours() % 12;\n\n                return (hours === 0 ? 12 : hours).toString();\n            }\n        },\n        p: {\n            // AM or PM\n            name: 'p',\n            index: 3,\n            extract () { return '(AM|PM)'; },\n            parser: (val) => {\n                if (val) {\n                    return val.toLowerCase();\n                }\n                return null;\n            },\n            formatter: (val) => {\n                const d = convertToNativeDate(val);\n                const hours = d.getHours();\n\n                return (hours < 12 ? 'AM' : 'PM');\n            }\n        },\n        P: {\n            // am or pm\n            name: 'P',\n            index: 3,\n            extract () { return '(am|pm)'; },\n            parser: (val) => {\n                if (val) {\n                    return val.toLowerCase();\n                }\n                return null;\n            },\n            formatter: (val) => {\n                const d = convertToNativeDate(val);\n                const hours = d.getHours();\n\n                return (hours < 12 ? 'am' : 'pm');\n            }\n        },\n        M: {\n            // Two digit minutes 00 - 59\n            name: 'M',\n            index: 4,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const mins = d.getMinutes();\n\n                return pad(mins);\n            }\n        },\n        S: {\n            // Two digit seconds 00 - 59\n            name: 'S',\n            index: 5,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const seconds = d.getSeconds();\n\n                return pad(seconds);\n            }\n        },\n        K: {\n            // Milliseconds\n            name: 'K',\n            index: 6,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const ms = d.getMilliseconds();\n\n                return ms.toString();\n            }\n        },\n        a: {\n            // Short name of day, like Mon\n            name: 'a',\n            index: 2,\n            extract () { return `(${daysDef.short.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(daysDef.short),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDay();\n\n                return (daysDef.short[day]).toString();\n            }\n        },\n        A: {\n            // Long name of day, like Monday\n            name: 'A',\n            index: 2,\n            extract () { return `(${daysDef.long.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(daysDef.long),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDay();\n\n                return (daysDef.long[day]).toString();\n            }\n        },\n        e: {\n            // 8 of March, 11 of November\n            name: 'e',\n            index: 2,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDate();\n\n                return day.toString();\n            }\n        },\n        d: {\n            // 08 of March, 11 of November\n            name: 'd',\n            index: 2,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDate();\n\n                return pad(day);\n            }\n        },\n        b: {\n            // Short month, like Jan\n            name: 'b',\n            index: 1,\n            extract () { return `(${monthsDef.short.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(monthsDef.short),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const month = d.getMonth();\n\n                return (monthsDef.short[month]).toString();\n            }\n        },\n        B: {\n            // Long month, like January\n            name: 'B',\n            index: 1,\n            extract () { return `(${monthsDef.long.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(monthsDef.long),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const month = d.getMonth();\n\n                return (monthsDef.long[month]).toString();\n            }\n        },\n        m: {\n            // Two digit month of year like 01 for January\n            name: 'm',\n            index: 1,\n            extract () { return '(\\\\d+)'; },\n            parser (val) { return DateTimeFormatter.defaultNumberParser()(val) - 1; },\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const month = d.getMonth();\n\n                return pad(month + 1);\n            }\n        },\n        y: {\n            // Short year like 90 for 1990\n            name: 'y',\n            index: 0,\n            extract () { return '(\\\\d{2})'; },\n            parser (val) {\n                let result;\n                if (val) {\n                    const l = val.length;\n                    val = val.substring(l - 2, l);\n                }\n                let parsedVal = DateTimeFormatter.defaultNumberParser()(val);\n                let presentDate = new Date();\n                let presentYear = Math.trunc((presentDate.getFullYear()) / 100);\n\n                result = `${presentYear}${parsedVal}`;\n\n                if (convertToNativeDate(result).getFullYear() > presentDate.getFullYear()) {\n                    result = `${presentYear - 1}${parsedVal}`;\n                }\n                return convertToNativeDate(result).getFullYear();\n            },\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                let year = d.getFullYear().toString();\n                let l;\n\n                if (year) {\n                    l = year.length;\n                    year = year.substring(l - 2, l);\n                }\n\n                return year;\n            }\n        },\n        Y: {\n            // Long year like 1990\n            name: 'Y',\n            index: 0,\n            extract () { return '(\\\\d{4})'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const year = d.getFullYear().toString();\n\n                return year;\n            }\n        }\n    };\n\n    return definitions;\n};\n\n/*\n * The tokens which works internally is not user friendly in terms of memorizing the names. This gives a formal\n * definition to the informal notations.\n *\n * @return {Object} : Formal definition of the tokens\n */\nDateTimeFormatter.getTokenFormalNames = function () {\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n\n    return {\n        HOUR: definitions.H,\n        HOUR_12: definitions.l,\n        AMPM_UPPERCASE: definitions.p,\n        AMPM_LOWERCASE: definitions.P,\n        MINUTE: definitions.M,\n        SECOND: definitions.S,\n        SHORT_DAY: definitions.a,\n        LONG_DAY: definitions.A,\n        DAY_OF_MONTH: definitions.e,\n        DAY_OF_MONTH_CONSTANT_WIDTH: definitions.d,\n        SHORT_MONTH: definitions.b,\n        LONG_MONTH: definitions.B,\n        MONTH_OF_YEAR: definitions.m,\n        SHORT_YEAR: definitions.y,\n        LONG_YEAR: definitions.Y\n    };\n};\n\n/*\n * This defines the rules and declares dependencies that resolves a date parameter (year, month etc) from\n * the date time parameter array.\n *\n * @return {Object} : An object that contains dependencies and a resolver function. The dependencies values are fed\n *                  to the resolver function in that particular sequence only.\n */\nDateTimeFormatter.tokenResolver = function () {\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    const defaultResolver = (...args) => { // eslint-disable-line require-jsdoc\n        let i = 0;\n        let arg;\n        let targetParam;\n        const l = args.length;\n\n        for (; i < l; i++) {\n            arg = args[i];\n            if (args[i]) {\n                targetParam = arg;\n            }\n        }\n\n        if (!targetParam) { return null; }\n\n        return targetParam[0].parser(targetParam[1]);\n    };\n\n    return {\n        YEAR: [definitions.y, definitions.Y,\n            defaultResolver\n        ],\n        MONTH: [definitions.b, definitions.B, definitions.m,\n            defaultResolver\n        ],\n        DAY: [definitions.a, definitions.A, definitions.e, definitions.d,\n            defaultResolver\n        ],\n        HOUR: [definitions.H, definitions.l, definitions.p, definitions.P,\n            function (hourFormat24, hourFormat12, ampmLower, ampmUpper) {\n                let targetParam;\n                let amOrpm;\n                let isPM;\n                let val;\n\n                if (hourFormat12 && (amOrpm = (ampmLower || ampmUpper))) {\n                    if (amOrpm[0].parser(amOrpm[1]) === 'pm') {\n                        isPM = true;\n                    }\n\n                    targetParam = hourFormat12;\n                } else if (hourFormat12) {\n                    targetParam = hourFormat12;\n                } else {\n                    targetParam = hourFormat24;\n                }\n\n                if (!targetParam) { return null; }\n\n                val = targetParam[0].parser(targetParam[1]);\n                if (isPM) {\n                    val += 12;\n                }\n                return val;\n            }\n        ],\n        MINUTE: [definitions.M,\n            defaultResolver\n        ],\n        SECOND: [definitions.S,\n            defaultResolver\n        ]\n    };\n};\n\n/*\n * Finds token from the format rule specified by a user.\n * @param format {String} : The format of the input date specified by the user\n * @return {Array} : An array of objects which contains the available token and their occurence index in the format\n */\nDateTimeFormatter.findTokens = function (format) {\n    const tokenPrefix = DateTimeFormatter.TOKEN_PREFIX;\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    const tokenLiterals = Object.keys(definitions);\n    const occurrence = [];\n    let i;\n    let forwardChar;\n\n    while ((i = format.indexOf(tokenPrefix, i + 1)) >= 0) {\n        forwardChar = format[i + 1];\n        if (tokenLiterals.indexOf(forwardChar) === -1) { continue; }\n\n        occurrence.push({\n            index: i,\n            token: forwardChar\n        });\n    }\n\n    return occurrence;\n};\n\n/*\n * Format any JS date to a specified date given by user.\n *\n * @param date {Number | Date} : The date object which is to be formatted\n * @param format {String} : The format using which the date will be formatted for display\n */\nDateTimeFormatter.formatAs = function (date, format) {\n    const nDate = convertToNativeDate(date);\n    const occurrence = DateTimeFormatter.findTokens(format);\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    let formattedStr = String(format);\n    const tokenPrefix = DateTimeFormatter.TOKEN_PREFIX;\n    let token;\n    let formattedVal;\n    let i;\n    let l;\n\n    for (i = 0, l = occurrence.length; i < l; i++) {\n        token = occurrence[i].token;\n        formattedVal = definitions[token].formatter(nDate);\n        formattedStr = formattedStr.replace(new RegExp(tokenPrefix + token, 'g'), formattedVal);\n    }\n\n    return formattedStr;\n};\n\n/*\n * Parses the user specified date string to extract the date time params.\n *\n * @return {Array} : Value of date time params in an array [year, month, day, hour, minutes, seconds, milli]\n */\nDateTimeFormatter.prototype.parse = function (dateTimeStamp, options) {\n    const tokenResolver = DateTimeFormatter.tokenResolver();\n    const dtParams = this.extractTokenValue(dateTimeStamp);\n    const dtParamSeq = DateTimeFormatter.DATETIME_PARAM_SEQUENCE;\n    const noBreak = options && options.noBreak;\n    const dtParamArr = [];\n    const args = [];\n    let resolverKey;\n    let resolverParams;\n    let resolverFn;\n    let val;\n    let i;\n    let param;\n    let resolvedVal;\n    let l;\n    let result = [];\n\n    for (resolverKey in tokenResolver) {\n        if (!{}.hasOwnProperty.call(tokenResolver, resolverKey)) { continue; }\n\n        args.length = 0;\n        resolverParams = tokenResolver[resolverKey];\n        resolverFn = resolverParams.splice(resolverParams.length - 1, 1)[0];\n\n        for (i = 0, l = resolverParams.length; i < l; i++) {\n            param = resolverParams[i];\n            val = dtParams[param.name];\n\n            if (val === undefined) {\n                args.push(null);\n            } else {\n                args.push([param, val]);\n            }\n        }\n\n        resolvedVal = resolverFn.apply(this, args);\n\n        if ((resolvedVal === undefined || resolvedVal === null) && !noBreak) {\n            break;\n        }\n\n        dtParamArr[dtParamSeq[resolverKey]] = resolvedVal;\n    }\n\n    if (dtParamArr.length && this.checkIfOnlyYear(dtParamArr.length))\n     {\n        result.unshift(dtParamArr[0], 0, 1); }\n    else {\n        result.unshift(...dtParamArr);\n    }\n\n    return result;\n};\n\n/*\n * Extract the value of the token from user specified date time string.\n *\n * @return {Object} : An key value pair which contains the tokens as key and value as pair\n */\nDateTimeFormatter.prototype.extractTokenValue = function (dateTimeStamp) {\n    const format = this.format;\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    const tokenPrefix = DateTimeFormatter.TOKEN_PREFIX;\n    const occurrence = DateTimeFormatter.findTokens(format);\n    const tokenObj = {};\n\n    let lastOccurrenceIndex;\n    let occObj;\n    let occIndex;\n    let targetText;\n    let regexFormat;\n\n    let l;\n    let i;\n\n    regexFormat = String(format);\n\n    const tokenArr = occurrence.map(obj => obj.token);\n    const occurrenceLength = occurrence.length;\n    for (i = occurrenceLength - 1; i >= 0; i--) {\n        occIndex = occurrence[i].index;\n\n        if (occIndex + 1 === regexFormat.length - 1) {\n            lastOccurrenceIndex = occIndex;\n            continue;\n        }\n\n        if (lastOccurrenceIndex === undefined) {\n            lastOccurrenceIndex = regexFormat.length;\n        }\n\n        targetText = regexFormat.substring(occIndex + 2, lastOccurrenceIndex);\n        regexFormat = regexFormat.substring(0, occIndex + 2) +\n            RegExp.escape(targetText) +\n            regexFormat.substring(lastOccurrenceIndex, regexFormat.length);\n\n        lastOccurrenceIndex = occIndex;\n    }\n\n    for (i = 0; i < occurrenceLength; i++) {\n        occObj = occurrence[i];\n        regexFormat = regexFormat.replace(tokenPrefix + occObj.token, definitions[occObj.token].extract());\n    }\n\n    const extractValues = dateTimeStamp.match(new RegExp(regexFormat)) || [];\n    extractValues.shift();\n\n    for (i = 0, l = tokenArr.length; i < l; i++) {\n        tokenObj[tokenArr[i]] = extractValues[i];\n    }\n    return tokenObj;\n};\n\n/*\n * Give back the JS native date formed from  user specified date string\n *\n * @return {Date} : Native JS Date\n */\nDateTimeFormatter.prototype.getNativeDate = function (dateTimeStamp) {\n    let date = null;\n    if (Number.isFinite(dateTimeStamp)) {\n        date = new Date(dateTimeStamp);\n    } else if (!this.format && Date.parse(dateTimeStamp)) {\n        date = new Date(dateTimeStamp);\n    }\n    else {\n        const dtParams = this.dtParams = this.parse(dateTimeStamp);\n        if (dtParams.length) {\n            this.nativeDate = new Date(...dtParams);\n            date = this.nativeDate;\n        }\n    }\n    return date;\n};\n\nDateTimeFormatter.prototype.checkIfOnlyYear = function(len) {\n    return len === 1 && this.format.match(/y|Y/g).length;\n};\n\n/*\n * Represents JS native date to a user specified format.\n *\n * @param format {String} : The format according to which the date is to be represented\n * @return {String} : The formatted date string\n */\nDateTimeFormatter.prototype.formatAs = function (format, dateTimeStamp) {\n    let nativeDate;\n\n    if (dateTimeStamp) {\n        nativeDate = this.nativeDate = this.getNativeDate(dateTimeStamp);\n    } else if (!(nativeDate = this.nativeDate)) {\n        nativeDate = this.getNativeDate(dateTimeStamp);\n    }\n\n    return DateTimeFormatter.formatAs(nativeDate, format);\n};\n\nexport { DateTimeFormatter as default };\n","/**\n * The utility function to calculate major column.\n *\n * @param {Object} store - The store object.\n * @return {Function} Returns the push function.\n */\nexport default (store) => {\n    let i = 0;\n    return (...fields) => {\n        fields.forEach((val, fieldIndex) => {\n            if (!(store[fieldIndex] instanceof Array)) {\n                store[fieldIndex] = Array.from({ length: i });\n            }\n            store[fieldIndex].push(val);\n        });\n        i++;\n    };\n};\n","/* eslint-disable */\nconst OBJECTSTRING = 'object';\nconst objectToStrFn = Object.prototype.toString;\nconst objectToStr = '[object Object]';\nconst arrayToStr = '[object Array]';\n\nfunction checkCyclicRef(obj, parentArr) {\n    let i = parentArr.length;\n    let bIndex = -1;\n\n    while (i) {\n        if (obj === parentArr[i]) {\n            bIndex = i;\n            return bIndex;\n        }\n        i -= 1;\n    }\n\n    return bIndex;\n}\n\nfunction merge(obj1, obj2, skipUndef, tgtArr, srcArr) {\n    var item,\n        srcVal,\n        tgtVal,\n        str,\n        cRef;\n    // check whether obj2 is an array\n    // if array then iterate through it's index\n    // **** MOOTOOLS precution\n\n    if (!srcArr) {\n        tgtArr = [obj1];\n        srcArr = [obj2];\n    }\n    else {\n        tgtArr.push(obj1);\n        srcArr.push(obj2);\n    }\n\n    if (obj2 instanceof Array) {\n        for (item = 0; item < obj2.length; item += 1) {\n            try {\n                srcVal = obj1[item];\n                tgtVal = obj2[item];\n            }\n            catch (e) {\n                continue;\n            }\n\n            if (typeof tgtVal !== OBJECTSTRING) {\n                if (!(skipUndef && tgtVal === undefined)) {\n                    obj1[item] = tgtVal;\n                }\n            }\n            else {\n                if (srcVal === null || typeof srcVal !== OBJECTSTRING) {\n                    srcVal = obj1[item] = tgtVal instanceof Array ? [] : {};\n                }\n                cRef = checkCyclicRef(tgtVal, srcArr);\n                if (cRef !== -1) {\n                    srcVal = obj1[item] = tgtArr[cRef];\n                }\n                else {\n                    merge(srcVal, tgtVal, skipUndef, tgtArr, srcArr);\n                }\n            }\n        }\n    }\n    else {\n        for (item in obj2) {\n            try {\n                srcVal = obj1[item];\n                tgtVal = obj2[item];\n            }\n            catch (e) {\n                continue;\n            }\n\n            if (tgtVal !== null && typeof tgtVal === OBJECTSTRING) {\n                // Fix for issue BUG: FWXT-602\n                // IE < 9 Object.prototype.toString.call(null) gives\n                // '[object Object]' instead of '[object Null]'\n                // that's why null value becomes Object in IE < 9\n                str = objectToStrFn.call(tgtVal);\n                if (str === objectToStr) {\n                    if (srcVal === null || typeof srcVal !== OBJECTSTRING) {\n                        srcVal = obj1[item] = {};\n                    }\n                    cRef = checkCyclicRef(tgtVal, srcArr);\n                    if (cRef !== -1) {\n                        srcVal = obj1[item] = tgtArr[cRef];\n                    }\n                    else {\n                        merge(srcVal, tgtVal, skipUndef, tgtArr, srcArr);\n                    }\n                }\n                else if (str === arrayToStr) {\n                    if (srcVal === null || !(srcVal instanceof Array)) {\n                        srcVal = obj1[item] = [];\n                    }\n                    cRef = checkCyclicRef(tgtVal, srcArr);\n                    if (cRef !== -1) {\n                        srcVal = obj1[item] = tgtArr[cRef];\n                    }\n                    else {\n                        merge(srcVal, tgtVal, skipUndef, tgtArr, srcArr);\n                    }\n                }\n                else {\n                    obj1[item] = tgtVal;\n                }\n            }\n            else {\n                if (skipUndef && tgtVal === undefined) {\n                    continue;\n                }\n                obj1[item] = tgtVal;\n            }\n        }\n    }\n    return obj1;\n}\n\n\nfunction extend2 (obj1, obj2, skipUndef) {\n    //if none of the arguments are object then return back\n    if (typeof obj1 !== OBJECTSTRING && typeof obj2 !== OBJECTSTRING) {\n        return null;\n    }\n\n    if (typeof obj2 !== OBJECTSTRING || obj2 === null) {\n        return obj1;\n    }\n\n    if (typeof obj1 !== OBJECTSTRING) {\n        obj1 = obj2 instanceof Array ? [] : {};\n    }\n    merge(obj1, obj2, skipUndef);\n    return obj1;\n}\n\nexport { extend2 as default };\n","import { DataFormat } from '../enums';\n\n/**\n * Checks whether the value is an array.\n *\n * @param  {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is an array otherwise returns false.\n */\nexport function isArray (val) {\n    return Array.isArray(val);\n}\n\n/**\n * Checks whether the value is an object.\n *\n * @param  {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is an object otherwise returns false.\n */\nexport function isObject (val) {\n    return val === Object(val);\n}\n\n/**\n * Checks whether the value is a string value.\n *\n * @param  {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is a string value otherwise returns false.\n */\nexport function isString (val) {\n    return typeof val === 'string';\n}\n\n/**\n * Checks whether the value is callable.\n *\n * @param {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is callable otherwise returns false.\n */\nexport function isCallable (val) {\n    return typeof val === 'function';\n}\n\n/**\n * Returns the unique values from the input array.\n *\n * @param {Array} data - The input array.\n * @return {Array} Returns a new array of unique values.\n */\nexport function uniqueValues (data) {\n    return [...new Set(data)];\n}\n\nexport const getUniqueId = () => `id-${new Date().getTime()}${Math.round(Math.random() * 10000)}`;\n\n/**\n * Checks Whether two arrays have same content.\n *\n * @param {Array} arr1 - The first array.\n * @param {Array} arr2 - The 2nd array.\n * @return {boolean} Returns whether two array have same content.\n */\nexport function isArrEqual(arr1, arr2) {\n    if (!isArray(arr1) || !isArray(arr2)) {\n        return arr1 === arr2;\n    }\n\n    if (arr1.length !== arr2.length) {\n        return false;\n    }\n\n    for (let i = 0; i < arr1.length; i++) {\n        if (arr1[i] !== arr2[i]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n\n/**\n * It is the default number format function for the measure field type.\n *\n * @param {any} val - The input value.\n * @return {number} Returns a number value.\n */\nexport function formatNumber(val) {\n    return val;\n}\n\n/**\n * Returns the detected data format.\n *\n * @param {any} data - The input data to be tested.\n * @return {string} Returns the data format name.\n */\nexport const detectDataFormat = (data) => {\n    if (isString(data)) {\n        return DataFormat.DSV_STR;\n    } else if (isArray(data) && isArray(data[0])) {\n        return DataFormat.DSV_ARR;\n    } else if (isArray(data) && (data.length === 0 || isObject(data[0]))) {\n        return DataFormat.FLAT_JSON;\n    }\n    return null;\n};\n","import { FieldType } from './enums';\nimport { getUniqueId } from './utils';\n\nconst fieldStore = {\n    data: {},\n\n    createNamespace (fieldArr, name) {\n        const dataId = name || getUniqueId();\n\n        this.data[dataId] = {\n            name: dataId,\n            fields: fieldArr,\n\n            fieldsObj () {\n                let fieldsObj = this._cachedFieldsObj;\n\n                if (!fieldsObj) {\n                    fieldsObj = this._cachedFieldsObj = {};\n                    this.fields.forEach((field) => {\n                        fieldsObj[field.name()] = field;\n                    });\n                }\n                return fieldsObj;\n            },\n            getMeasure () {\n                let measureFields = this._cachedMeasure;\n\n                if (!measureFields) {\n                    measureFields = this._cachedMeasure = {};\n                    this.fields.forEach((field) => {\n                        if (field.schema().type === FieldType.MEASURE) {\n                            measureFields[field.name()] = field;\n                        }\n                    });\n                }\n                return measureFields;\n            },\n            getDimension () {\n                let dimensionFields = this._cachedDimension;\n\n                if (!this._cachedDimension) {\n                    dimensionFields = this._cachedDimension = {};\n                    this.fields.forEach((field) => {\n                        if (field.schema().type === FieldType.DIMENSION) {\n                            dimensionFields[field.name()] = field;\n                        }\n                    });\n                }\n                return dimensionFields;\n            },\n        };\n        return this.data[dataId];\n    },\n};\n\nexport default fieldStore;\n","/**\n * The wrapper class on top of the primitive value of a field.\n *\n * @todo Need to have support for StringValue, NumberValue, DateTimeValue\n * and GeoValue. These types should expose predicate API mostly.\n */\nclass Value {\n\n  /**\n   * Creates new Value instance.\n   *\n   * @param {*} val - the primitive value from the field cell.\n   * @param {string | Field} field - The field from which the value belongs.\n   */\n    constructor (val, field) {\n        Object.defineProperty(this, '_value', {\n            enumerable: false,\n            configurable: false,\n            writable: false,\n            value: val\n        });\n\n        this.field = field;\n    }\n\n  /**\n   * Returns the field value.\n   *\n   * @return {*} Returns the current value.\n   */\n    get value () {\n        return this._value;\n    }\n\n  /**\n   * Converts to human readable string.\n   *\n   * @override\n   * @return {string} Returns a human readable string of the field value.\n   *\n   */\n    toString () {\n        return String(this.value);\n    }\n\n  /**\n   * Returns the value of the field.\n   *\n   * @override\n   * @return {*} Returns the field value.\n   */\n    valueOf () {\n        return this.value;\n    }\n}\n\nexport default Value;\n","/**\n * Iterates through the diffSet array and call the callback with the current\n * index.\n *\n * @param {string} rowDiffset - The row diffset string e.g. '0-4,6,10-13'.\n * @param {Function} callback - The callback function to be called with every index.\n */\nexport function rowDiffsetIterator (rowDiffset, callback) {\n    if (rowDiffset.length > 0) {\n        const rowDiffArr = rowDiffset.split(',');\n        rowDiffArr.forEach((diffStr) => {\n            const diffStsArr = diffStr.split('-');\n            const start = +(diffStsArr[0]);\n            const end = +(diffStsArr[1] || diffStsArr[0]);\n            if (end >= start) {\n                for (let i = start; i <= end; i += 1) {\n                    callback(i);\n                }\n            }\n        });\n    }\n}\n","/**\n * A parser to parser null, undefined, invalid and NIL values.\n *\n * @public\n * @class\n */\nclass InvalidAwareTypes {\n    /**\n     * Static method which gets/sets the invalid value registry.\n     *\n     * @public\n     * @param {Object} config - The custom configuration supplied by user.\n     * @return {Object} Returns the invalid values registry.\n     */\n    static invalidAwareVals (config) {\n        if (!config) {\n            return InvalidAwareTypes._invalidAwareValsMap;\n        }\n        return Object.assign(InvalidAwareTypes._invalidAwareValsMap, config);\n    }\n\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {string} value - The value of the invalid data type.\n     */\n    constructor (value) {\n        this._value = value;\n    }\n\n    /**\n     * Returns the current value of the instance.\n     *\n     * @public\n     * @return {string} Returns the value of the invalid data type.\n     */\n    value () {\n        return this._value;\n    }\n\n    /**\n     * Returns the current value of the instance in string format.\n     *\n     * @public\n     * @return {string} Returns the value of the invalid data type.\n     */\n    toString () {\n        return String(this._value);\n    }\n\n    static isInvalid(val) {\n        return (val instanceof InvalidAwareTypes) || !!InvalidAwareTypes.invalidAwareVals()[val];\n    }\n\n    static getInvalidType(val) {\n        return val instanceof InvalidAwareTypes ? val : InvalidAwareTypes.invalidAwareVals()[val];\n    }\n}\n\n/**\n * Enums for Invalid types.\n */\nInvalidAwareTypes.NULL = new InvalidAwareTypes('null');\nInvalidAwareTypes.NA = new InvalidAwareTypes('na');\nInvalidAwareTypes.NIL = new InvalidAwareTypes('nil');\n\n/**\n * Default Registry for mapping the invalid values.\n *\n * @private\n */\nInvalidAwareTypes._invalidAwareValsMap = {\n    invalid: InvalidAwareTypes.NA,\n    nil: InvalidAwareTypes.NIL,\n    null: InvalidAwareTypes.NULL,\n    undefined: InvalidAwareTypes.NA\n};\n\nexport default InvalidAwareTypes;\n","import { rowDiffsetIterator } from './row-diffset-iterator';\nimport InvalidAwareTypes from '../invalid-aware-types';\n\nconst generateBuckets = (binSize, start, end) => {\n    const buckets = [];\n    let next = start;\n\n    while (next < end) {\n        buckets.push(next);\n        next += binSize;\n    }\n    buckets.push(next);\n\n    return buckets;\n};\n\nconst findBucketRange = (bucketRanges, value) => {\n    let leftIdx = 0;\n    let rightIdx = bucketRanges.length - 1;\n    let midIdx;\n    let range;\n\n    // Here use binary search as the bucketRanges is a sorted array\n    while (leftIdx <= rightIdx) {\n        midIdx = leftIdx + Math.floor((rightIdx - leftIdx) / 2);\n        range = bucketRanges[midIdx];\n\n        if (value >= range.start && value < range.end) {\n            return range;\n        } else if (value >= range.end) {\n            leftIdx = midIdx + 1;\n        } else if (value < range.start) {\n            rightIdx = midIdx - 1;\n        }\n    }\n\n    return null;\n};\n\n /**\n  * Creates the bin data from input measure field and supplied configs.\n  *\n  * @param {Measure} measureField - The Measure field instance.\n  * @param {string} rowDiffset - The datamodel rowDiffset values.\n  * @param {Object} config - The config object.\n  * @return {Object} Returns the binned data and the corresponding bins.\n  */\nexport function createBinnedFieldData (measureField, rowDiffset, config) {\n    let { buckets, binsCount, binSize, start, end } = config;\n    const [dMin, dMax] = measureField.domain();\n\n    if (!buckets) {\n        start = (start !== 0 && (!start || start > dMin)) ? dMin : start;\n        end = (end !== 0 && (!end || end < dMax)) ? (dMax + 1) : end;\n\n        if (binsCount) {\n            binSize = Math.ceil(Math.abs(end - start) / binsCount);\n        }\n\n        buckets = generateBuckets(binSize, start, end);\n    }\n\n    if (buckets[0] > dMin) {\n        buckets.unshift(dMin);\n    }\n    if (buckets[buckets.length - 1] <= dMax) {\n        buckets.push(dMax + 1);\n    }\n\n    const bucketRanges = [];\n    for (let i = 0; i < buckets.length - 1; i++) {\n        bucketRanges.push({\n            start: buckets[i],\n            end: buckets[i + 1]\n        });\n    }\n\n    const binnedData = [];\n    rowDiffsetIterator(rowDiffset, (i) => {\n        const datum = measureField.partialField.data[i];\n        if (datum instanceof InvalidAwareTypes) {\n            binnedData.push(datum);\n            return;\n        }\n\n        const range = findBucketRange(bucketRanges, datum);\n        binnedData.push(`${range.start}-${range.end}`);\n    });\n\n    return { binnedData, bins: buckets };\n}\n","export { DataFormat, FilteringMode } from '../enums';\n/**\n * The event name for data propagation.\n */\nexport const PROPAGATION = 'propagation';\n\n/**\n * The name of the unique row id column in DataModel.\n */\nexport const ROW_ID = '__id__';\n\n/**\n * The enums for operation names performed on DataModel.\n */\nexport const DM_DERIVATIVES = {\n    SELECT: 'select',\n    PROJECT: 'project',\n    GROUPBY: 'group',\n    COMPOSE: 'compose',\n    CAL_VAR: 'calculatedVariable',\n    BIN: 'bin',\n    SORT: 'sort'\n};\n\nexport const JOINS = {\n    CROSS: 'cross',\n    LEFTOUTER: 'leftOuter',\n    RIGHTOUTER: 'rightOuter',\n    NATURAL: 'natural',\n    FULLOUTER: 'fullOuter'\n};\n\nexport const LOGICAL_OPERATORS = {\n    AND: 'and',\n    OR: 'or'\n};\n","import { persistDerivations } from '../helper';\nimport { DM_DERIVATIVES } from '../constants';\n\n/**\n * DataModel's opearators are exposed as composable functional operators as well as chainable operators. Chainable\n * operators are called on the instances of {@link Datamodel} and {@link Relation} class.\n *\n * Those same operators can be used as composable operators from `DataModel.Operators` namespace.\n *\n * All these operators have similar behaviour. All these operators when called with the argument returns a function\n * which expects a DataModel instance.\n *\n * @public\n * @module Operators\n * @namespace DataModel\n */\n\n/**\n * This is functional version of selection operator. {@link link_to_selection | Selection} is a row filtering operation.\n * It takes {@link SelectionPredicate | predicate} for filtering criteria and returns a function.\n * The returned function is called with the DataModel instance on which the action needs to be performed.\n *\n * {@link SelectionPredicate} is a function which returns a boolean value. For selection opearation the selection\n * function is called for each row of DataModel instance with the current row passed as argument.\n *\n * After executing {@link SelectionPredicate} the rows are labeled as either an entry of selection set or an entry\n * of rejection set.\n *\n * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n * resulatant datamodel.\n *\n * @warning\n * [Warn] Selection and rejection set is only a logical idea for concept explanation purpose.\n *\n * @error\n * [Error] `FilteringMode.ALL` is not a valid working mode for functional version of `select`. Its only avialable on the\n * chained version.\n *\n * @example\n * const select = DataModel.Operators.select;\n * usaCarsFn = select(fields => fields.Origin.value === 'USA');\n * usaCarsDm = usaCarsFn(dm);\n * console.log(usaCarsDm);\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {SelectionPredicate} selectFn - Predicate funciton which is called for each row with the current row\n *      ```\n *          function (row, i)  { ... }\n *      ```\n * @param {Object} [config] - The configuration object to control the inclusion exclusion of a row in resultant\n *      DataModel instance\n * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - The mode of the selection\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const select = (...args) => dm => dm.select(...args);\n\n/**\n * This is functional version of projection operator. {@link link_to_projection | Projection} is a column filtering\n * operation.It expects list of fields name and either include those or exclude those based on {@link FilteringMode} on\n * the  resultant variable.It returns a function which is called with the DataModel instance on which the action needs\n * to be performed.\n *\n * Projection expects array of fields name based on which it creates the selection and rejection set. All the field\n * whose name is present in array goes in selection set and rest of the fields goes in rejection set.\n *\n * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n * resulatant datamodel.\n *\n * @warning\n * Selection and rejection set is only a logical idea for concept explanation purpose.\n *\n * @error\n * `FilteringMode.ALL` is not a valid working mode for functional version of `select`. Its only avialable on the\n * chained version.\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {Array.<string | Regexp>} projField - An array of column names in string or regular expression.\n * @param {Object} [config] - An optional config to control the creation of new DataModel\n * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - Mode of the projection\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const project = (...args) => dm => dm.project(...args);\n\n/**\n * This is functional version of binnig operator. Binning happens on a measure field based on a binning configuration.\n * Binning in DataModel does not aggregate the number of rows present in DataModel instance after binning, it just adds\n * a new field with the binned value. Refer binning {@link example_of_binning | example} to have a intuition of what\n * binning is and the use case.\n *\n * Binning can be configured by\n * - providing custom bin configuration with non uniform buckets\n * - providing bin count\n * - providing each bin size\n *\n * When custom buckets are provided as part of binning configuration\n * @example\n *  // DataModel already prepared and assigned to dm vairable\n *  const buckets = {\n *      start: 30\n *      stops: [80, 100, 110]\n *  };\n *  const config = { buckets, name: 'binnedHP' }\n *  const binFn = bin('horsepower', config);\n *  const binnedDm = binFn(dm);\n *\n * @text\n * When `binCount` is defined as part of binning configuration\n * @example\n *  // DataModel already prepared and assigned to dm vairable\n *  const config = { binCount: 5, name: 'binnedHP' }\n *  const binFn = bin('horsepower', config);\n *  const binnedDm = binFn(Dm);\n *\n * @text\n * When `binSize` is defined as part of binning configuration\n * @example\n *  // DataModel already prepared and assigned to dm vairable\n *  const config = { binSize: 200, name: 'binnedHorsepower' }\n *  const binnedDm = dataModel.bin('horsepower', config);\n *  const binnedDm = binFn(Dm);\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {String} name Name of measure which will be used to create bin\n * @param {Object} config Config required for bin creation\n * @param {Array.<Number>} config.bucketObj.stops Defination of bucket ranges. Two subsequent number from arrays\n *      are picked and a range is created. The first number from range is inclusive and the second number from range\n *      is exclusive.\n * @param {Number} [config.bucketObj.startAt] Force the start of the bin from a particular number.\n *      If not mentioned, the start of the bin or the lower domain of the data if stops is not mentioned, else its\n *      the first value of the stop.\n * @param {Number} config.binSize Bucket size for each bin\n * @param {Number} config.binCount Number of bins which will be created\n * @param {String} config.name Name of the new binned field to be created\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const bin = (...args) => dm => dm.bin(...args);\n\n/**\n * This is functional version of `groupBy` operator.Groups the data using particular dimensions and by reducing\n * measures. It expects a list of dimensions using which it projects the datamodel and perform aggregations to reduce\n * the duplicate tuples. Refer this {@link link_to_one_example_with_group_by | document} to know the intuition behind\n * groupBy.\n *\n * DataModel by default provides definition of few {@link reducer | Reducers}.\n * {@link ReducerStore | User defined reducers} can also be registered.\n *\n * This is the chained implementation of `groupBy`.\n * `groupBy` also supports {@link link_to_compose_groupBy | composability}\n *\n * @example\n * const groupBy = DataModel.Operators.groupBy;\n * const groupedFn = groupBy(['Year'], { horsepower: 'max' } );\n * groupedDM = groupByFn(dm);\n *\n * @public\n *\n * @param {Array.<string>} fieldsArr - Array containing the name of dimensions\n * @param {Object} [reducers={}] - A map whose key is the variable name and value is the name of the reducer. If its\n *      not passed, or any variable is ommitted from the object, default aggregation function is used from the\n *      schema of the variable.\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const groupBy = (...args) => dm => dm.groupBy(...args);\n\n/**\n * Enables composing operators to run multiple operations and save group of operataion as named opration on a DataModel.\n * The resulting DataModel will be the result of all the operation provided. The operations provided will be executed in\n * a serial manner ie. result of one operation will be the input for the next operations (like pipe operator in unix).\n *\n * Suported operations in compose are\n * - `select`\n * - `project`\n * - `groupBy`\n * - `bin`\n * - `compose`\n *\n * @example\n * const compose = DataModel.Operators.compose;\n * const select = DataModel.Operators.select;\n * const project = DataModel.Operators.project;\n *\n * let composedFn = compose(\n *    select(fields => fields.netprofit.value <= 15),\n *    project(['netprofit', 'netsales']));\n *\n * const dataModel = new DataModel(data1, schema1);\n *\n * let composedDm = composedFn(dataModel);\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {Array.<Operators>} operators: An array of operation that will be applied on the\n * datatable.\n *\n * @returns {DataModel} Instance of resultant DataModel\n */\nexport const compose = (...operations) =>\n    (dm, config = { saveChild: true }) => {\n        let currentDM = dm;\n        let firstChild;\n        const derivations = [];\n\n        operations.forEach((operation) => {\n            currentDM = operation(currentDM);\n            derivations.push(...currentDM._derivation);\n            if (!firstChild) {\n                firstChild = currentDM;\n            }\n        });\n\n        if (firstChild && firstChild !== currentDM) {\n            firstChild.dispose();\n        }\n\n        // reset all ancestorDerivation saved in-between compose\n        currentDM._ancestorDerivation = [];\n        persistDerivations(\n            dm,\n            currentDM,\n            DM_DERIVATIVES.COMPOSE,\n            null,\n            derivations\n        );\n\n        if (config.saveChild) {\n            currentDM.setParent(dm);\n        } else {\n            currentDM.setParent(null);\n        }\n\n        return currentDM;\n    };\n","/**\n * The helper function that returns an array of common schema\n * from two fieldStore instances.\n *\n * @param {FieldStore} fs1 - The first FieldStore instance.\n * @param {FieldStore} fs2 - The second FieldStore instance.\n * @return {Array} An array containing the common schema.\n */\nexport function getCommonSchema (fs1, fs2) {\n    const retArr = [];\n    const fs1Arr = [];\n    fs1.fields.forEach((field) => {\n        fs1Arr.push(field.schema().name);\n    });\n    fs2.fields.forEach((field) => {\n        if (fs1Arr.indexOf(field.schema().name) !== -1) {\n            retArr.push(field.schema().name);\n        }\n    });\n    return retArr;\n}\n","import DataModel from '../datamodel';\nimport { extend2 } from '../utils';\nimport { getCommonSchema } from './get-common-schema';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { JOINS } from '../constants';\nimport { prepareJoinData } from '../helper';\n/**\n * Default filter function for crossProduct.\n *\n * @return {boolean} Always returns true.\n */\nfunction defaultFilterFn() { return true; }\n\n/**\n * Implementation of cross product operation between two DataModel instances.\n * It internally creates the data and schema for the new DataModel.\n *\n * @param {DataModel} dataModel1 - The left DataModel instance.\n * @param {DataModel} dataModel2 - The right DataModel instance.\n * @param {Function} filterFn - The filter function which is used to filter the tuples.\n * @param {boolean} [replaceCommonSchema=false] - The flag if the common name schema should be there.\n * @return {DataModel} Returns The newly created DataModel instance from the crossProduct operation.\n */\nexport function crossProduct (dm1, dm2, filterFn, replaceCommonSchema = false, jointype = JOINS.CROSS) {\n    const schema = [];\n    const data = [];\n    const applicableFilterFn = filterFn || defaultFilterFn;\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    const dm1FieldStoreName = dm1FieldStore.name;\n    const dm2FieldStoreName = dm2FieldStore.name;\n    const name = `${dm1FieldStore.name}.${dm2FieldStore.name}`;\n    const commonSchemaList = getCommonSchema(dm1FieldStore, dm2FieldStore);\n\n    if (dm1FieldStoreName === dm2FieldStoreName) {\n        throw new Error('DataModels must have different alias names');\n    }\n    // Here prepare the schema\n    dm1FieldStore.fields.forEach((field) => {\n        const tmpSchema = extend2({}, field.schema());\n        if (commonSchemaList.indexOf(tmpSchema.name) !== -1 && !replaceCommonSchema) {\n            tmpSchema.name = `${dm1FieldStore.name}.${tmpSchema.name}`;\n        }\n        schema.push(tmpSchema);\n    });\n    dm2FieldStore.fields.forEach((field) => {\n        const tmpSchema = extend2({}, field.schema());\n        if (commonSchemaList.indexOf(tmpSchema.name) !== -1) {\n            if (!replaceCommonSchema) {\n                tmpSchema.name = `${dm2FieldStore.name}.${tmpSchema.name}`;\n                schema.push(tmpSchema);\n            }\n        } else {\n            schema.push(tmpSchema);\n        }\n    });\n\n    // Here prepare Data\n    rowDiffsetIterator(dm1._rowDiffset, (i) => {\n        let rowAdded = false;\n        let rowPosition;\n        rowDiffsetIterator(dm2._rowDiffset, (ii) => {\n            const tuple = [];\n            const userArg = {};\n            userArg[dm1FieldStoreName] = {};\n            userArg[dm2FieldStoreName] = {};\n            dm1FieldStore.fields.forEach((field) => {\n                tuple.push(field.partialField.data[i]);\n                userArg[dm1FieldStoreName][field.name()] = field.partialField.data[i];\n            });\n            dm2FieldStore.fields.forEach((field) => {\n                if (!(commonSchemaList.indexOf(field.schema().name) !== -1 && replaceCommonSchema)) {\n                    tuple.push(field.partialField.data[ii]);\n                }\n                userArg[dm2FieldStoreName][field.name()] = field.partialField.data[ii];\n            });\n\n            let cachedStore = {};\n            let cloneProvider1 = () => dm1.detachedRoot();\n            let cloneProvider2 = () => dm2.detachedRoot();\n\n            const dm1Fields = prepareJoinData(userArg[dm1FieldStoreName]);\n            const dm2Fields = prepareJoinData(userArg[dm2FieldStoreName]);\n            if (applicableFilterFn(dm1Fields, dm2Fields, cloneProvider1, cloneProvider2, cachedStore)) {\n                const tupleObj = {};\n                tuple.forEach((cellVal, iii) => {\n                    tupleObj[schema[iii].name] = cellVal;\n                });\n                if (rowAdded && JOINS.CROSS !== jointype) {\n                    data[rowPosition] = tupleObj;\n                }\n                else {\n                    data.push(tupleObj);\n                    rowAdded = true;\n                    rowPosition = i;\n                }\n            } else if ((jointype === JOINS.LEFTOUTER || jointype === JOINS.RIGHTOUTER) && !rowAdded) {\n                const tupleObj = {};\n                let len = dm1FieldStore.fields.length - 1;\n                tuple.forEach((cellVal, iii) => {\n                    if (iii <= len) {\n                        tupleObj[schema[iii].name] = cellVal;\n                    }\n                    else {\n                        tupleObj[schema[iii].name] = null;\n                    }\n                });\n                rowAdded = true;\n                rowPosition = i;\n                data.push(tupleObj);\n            }\n        });\n    });\n\n    return new DataModel(data, schema, { name });\n}\n","/**\n * The default sort function.\n *\n * @param {*} a - The first value.\n * @param {*} b - The second value.\n * @return {number} Returns the comparison result e.g. 1 or 0 or -1.\n */\nfunction defSortFn (a, b) {\n    const a1 = `${a}`;\n    const b1 = `${b}`;\n    if (a1 < b1) {\n        return -1;\n    }\n    if (a1 > b1) {\n        return 1;\n    }\n    return 0;\n}\n\n/**\n * The helper function for merge sort which creates the sorted array\n * from the two halves of the input array.\n *\n * @param {Array} arr - The target array which needs to be merged.\n * @param {number} lo - The starting index of the first array half.\n * @param {number} mid - The ending index of the first array half.\n * @param {number} hi - The ending index of the second array half.\n * @param {Function} sortFn - The sort function.\n */\nfunction merge (arr, lo, mid, hi, sortFn) {\n    const mainArr = arr;\n    const auxArr = [];\n    for (let i = lo; i <= hi; i += 1) {\n        auxArr[i] = mainArr[i];\n    }\n    let a = lo;\n    let b = mid + 1;\n\n    for (let i = lo; i <= hi; i += 1) {\n        if (a > mid) {\n            mainArr[i] = auxArr[b];\n            b += 1;\n        } else if (b > hi) {\n            mainArr[i] = auxArr[a];\n            a += 1;\n        } else if (sortFn(auxArr[a], auxArr[b]) <= 0) {\n            mainArr[i] = auxArr[a];\n            a += 1;\n        } else {\n            mainArr[i] = auxArr[b];\n            b += 1;\n        }\n    }\n}\n\n/**\n * The helper function for merge sort which would be called\n * recursively for sorting the array halves.\n *\n * @param {Array} arr - The target array which needs to be sorted.\n * @param {number} lo - The starting index of the array half.\n * @param {number} hi - The ending index of the array half.\n * @param {Function} sortFn - The sort function.\n * @return {Array} Returns the target array itself.\n */\nfunction sort (arr, lo, hi, sortFn) {\n    if (hi === lo) { return arr; }\n\n    const mid = lo + Math.floor((hi - lo) / 2);\n    sort(arr, lo, mid, sortFn);\n    sort(arr, mid + 1, hi, sortFn);\n    merge(arr, lo, mid, hi, sortFn);\n\n    return arr;\n}\n\n/**\n * The implementation of merge sort.\n * It is used in DataModel for stable sorting as it is not sure\n * what the sorting algorithm used by browsers is stable or not.\n *\n * @param {Array} arr - The target array which needs to be sorted.\n * @param {Function} [sortFn=defSortFn] - The sort function.\n * @return {Array} Returns the input array itself in sorted order.\n */\nexport function mergeSort (arr, sortFn = defSortFn) {\n    if (arr.length > 1) {\n        sort(arr, 0, arr.length - 1, sortFn);\n    }\n    return arr;\n}\n","import { DimensionSubtype, MeasureSubtype } from '../enums';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { mergeSort } from './merge-sort';\nimport { fieldInSchema } from '../helper';\nimport { isCallable, isArray, } from '../utils';\n/**\n * Generates the sorting functions to sort the data of a DataModel instance\n * according to the input data type.\n *\n * @param {string} dataType - The data type e.g. 'measure', 'datetime' etc.\n * @param {string} sortType - The sorting order i.e. 'asc' or 'desc'.\n * @param {integer} index - The index of the data which will be sorted.\n * @return {Function} Returns the the sorting function.\n */\nfunction getSortFn (dataType, sortType, index) {\n    let retFunc;\n    switch (dataType) {\n    case MeasureSubtype.CONTINUOUS:\n    case DimensionSubtype.TEMPORAL:\n        if (sortType === 'desc') {\n            retFunc = (a, b) => b[index] - a[index];\n        } else {\n            retFunc = (a, b) => a[index] - b[index];\n        }\n        break;\n    default:\n        retFunc = (a, b) => {\n            const a1 = `${a[index]}`;\n            const b1 = `${b[index]}`;\n            if (a1 < b1) {\n                return sortType === 'desc' ? 1 : -1;\n            }\n            if (a1 > b1) {\n                return sortType === 'desc' ? -1 : 1;\n            }\n            return 0;\n        };\n    }\n    return retFunc;\n}\n\n/**\n * Groups the data according to the specified target field.\n *\n * @param {Array} data - The input data array.\n * @param {number} fieldIndex - The target field index within schema array.\n * @return {Array} Returns an array containing the grouped data.\n */\nfunction groupData(data, fieldIndex) {\n    const hashMap = new Map();\n    const groupedData = [];\n\n    data.forEach((datum) => {\n        const fieldVal = datum[fieldIndex];\n        if (hashMap.has(fieldVal)) {\n            groupedData[hashMap.get(fieldVal)][1].push(datum);\n        } else {\n            groupedData.push([fieldVal, [datum]]);\n            hashMap.set(fieldVal, groupedData.length - 1);\n        }\n    });\n\n    return groupedData;\n}\n\n/**\n * Creates the argument value used for sorting function when sort is done\n * with another fields.\n *\n * @param {Array} groupedDatum - The grouped datum for a single dimension field value.\n * @param {Array} targetFields - An array of the sorting fields.\n * @param {Array} targetFieldDetails - An array of the sorting field details in schema.\n * @return {Object} Returns an object containing the value of sorting fields and the target field name.\n */\nfunction createSortingFnArg(groupedDatum, targetFields, targetFieldDetails) {\n    const arg = {\n        label: groupedDatum[0]\n    };\n\n    targetFields.reduce((acc, next, idx) => {\n        acc[next] = groupedDatum[1].map(datum => datum[targetFieldDetails[idx].index]);\n        return acc;\n    }, arg);\n\n    return arg;\n}\n\n/**\n * Sorts the data before return in dataBuilder.\n *\n * @param {Object} dataObj - An object containing the data and schema.\n * @param {Array} sortingDetails - An array containing the sorting configs.\n */\nfunction sortData(dataObj, sortingDetails) {\n    const { data, schema } = dataObj;\n    let fieldName;\n    let sortMeta;\n    let fDetails;\n    let i = sortingDetails.length - 1;\n\n    for (; i >= 0; i--) {\n        fieldName = sortingDetails[i][0];\n        sortMeta = sortingDetails[i][1];\n        fDetails = fieldInSchema(schema, fieldName);\n\n        if (!fDetails) {\n            // eslint-disable-next-line no-continue\n            continue;\n        }\n\n        if (isCallable(sortMeta)) {\n            // eslint-disable-next-line no-loop-func\n            mergeSort(data, (a, b) => sortMeta(a[fDetails.index], b[fDetails.index]));\n        } else if (isArray(sortMeta)) {\n            const groupedData = groupData(data, fDetails.index);\n            const sortingFn = sortMeta[sortMeta.length - 1];\n            const targetFields = sortMeta.slice(0, sortMeta.length - 1);\n            const targetFieldDetails = targetFields.map(f => fieldInSchema(schema, f));\n\n            groupedData.forEach((groupedDatum) => {\n                groupedDatum.push(createSortingFnArg(groupedDatum, targetFields, targetFieldDetails));\n            });\n\n            mergeSort(groupedData, (a, b) => {\n                const m = a[2];\n                const n = b[2];\n                return sortingFn(m, n);\n            });\n\n            // Empty the array\n            data.length = 0;\n            groupedData.forEach((datum) => {\n                data.push(...datum[1]);\n            });\n        } else {\n            sortMeta = String(sortMeta).toLowerCase() === 'desc' ? 'desc' : 'asc';\n            mergeSort(data, getSortFn(fDetails.type, sortMeta, fDetails.index));\n        }\n    }\n\n    dataObj.uids = [];\n    data.forEach((value) => {\n        dataObj.uids.push(value.pop());\n    });\n}\n\n\n/**\n * Builds the actual data array.\n *\n * @param {Array} fieldStore - An array of field.\n * @param {string} rowDiffset - A string consisting of which rows to be included eg. '0-2,4,6';\n * @param {string} colIdentifier - A string consisting of the details of which column\n * to be included eg 'date,sales,profit';\n * @param {Object} sortingDetails - An object containing the sorting details of the DataModel instance.\n * @param {Object} options - The options required to create the type of the data.\n * @return {Object} Returns an object containing the multidimensional array and the relative schema.\n */\nexport function dataBuilder (fieldStore, rowDiffset, colIdentifier, sortingDetails, options) {\n    const defOptions = {\n        addUid: false,\n        columnWise: false\n    };\n    options = Object.assign({}, defOptions, options);\n\n    const retObj = {\n        schema: [],\n        data: [],\n        uids: []\n    };\n    const addUid = options.addUid;\n    const reqSorting = sortingDetails && sortingDetails.length > 0;\n    // It stores the fields according to the colIdentifier argument\n    const tmpDataArr = [];\n    // Stores the fields according to the colIdentifier argument\n    const colIArr = colIdentifier.split(',');\n\n    colIArr.forEach((colName) => {\n        for (let i = 0; i < fieldStore.length; i += 1) {\n            if (fieldStore[i].name() === colName) {\n                tmpDataArr.push(fieldStore[i]);\n                break;\n            }\n        }\n    });\n\n    // Inserts the schema to the schema object\n    tmpDataArr.forEach((field) => {\n        /** @todo Need to use extend2 here otherwise user can overwrite the schema. */\n        retObj.schema.push(field.schema());\n    });\n\n    if (addUid) {\n        retObj.schema.push({\n            name: 'uid',\n            type: 'identifier'\n        });\n    }\n\n    rowDiffsetIterator(rowDiffset, (i) => {\n        retObj.data.push([]);\n        const insertInd = retObj.data.length - 1;\n        let start = 0;\n        tmpDataArr.forEach((field, ii) => {\n            retObj.data[insertInd][ii + start] = field.partialField.data[i];\n        });\n        if (addUid) {\n            retObj.data[insertInd][tmpDataArr.length] = i;\n        }\n        // Creates an array of unique identifiers for each row\n        retObj.uids.push(i);\n\n        // If sorting needed then there is the need to expose the index\n        // mapping from the old index to its new index\n        if (reqSorting) { retObj.data[insertInd].push(i); }\n    });\n\n    // Handles the sort functionality\n    if (reqSorting) {\n        sortData(retObj, sortingDetails);\n    }\n\n    if (options.columnWise) {\n        const tmpData = Array(...Array(retObj.schema.length)).map(() => []);\n        retObj.data.forEach((tuple) => {\n            tuple.forEach((data, i) => {\n                tmpData[i].push(data);\n            });\n        });\n        retObj.data = tmpData;\n    }\n\n    return retObj;\n}\n","import DataModel from '../datamodel';\nimport { extend2 } from '../utils';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { isArrEqual } from '../utils/helper';\n\n/**\n * Performs the union operation between two dm instances.\n *\n * @todo Fix the conflicts between union and difference terminology here.\n *\n * @param {dm} dm1 - The first dm instance.\n * @param {dm} dm2 - The second dm instance.\n * @return {dm} Returns the newly created dm after union operation.\n */\nexport function difference (dm1, dm2) {\n    const hashTable = {};\n    const schema = [];\n    const schemaNameArr = [];\n    const data = [];\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    const dm1FieldStoreFieldObj = dm1FieldStore.fieldsObj();\n    const dm2FieldStoreFieldObj = dm2FieldStore.fieldsObj();\n    const name = `${dm1FieldStore.name} union ${dm2FieldStore.name}`;\n\n   // For union the columns should match otherwise return a clone of the dm1\n    if (!isArrEqual(dm1._colIdentifier.split(',').sort(), dm2._colIdentifier.split(',').sort())) {\n        return null;\n    }\n\n    // Prepare the schema\n    (dm1._colIdentifier.split(',')).forEach((fieldName) => {\n        const field = dm1FieldStoreFieldObj[fieldName];\n        schema.push(extend2({}, field.schema()));\n        schemaNameArr.push(field.schema().name);\n    });\n\n    /**\n     * The helper function to create the data.\n     *\n     * @param {dm} dm - The dm instance for which the data is inserted.\n     * @param {Object} fieldsObj - The fieldStore object format.\n     * @param {boolean} addData - If true only tuple will be added to the data.\n     */\n    function prepareDataHelper(dm, fieldsObj, addData) {\n        rowDiffsetIterator(dm._rowDiffset, (i) => {\n            const tuple = {};\n            let hashData = '';\n            schemaNameArr.forEach((schemaName) => {\n                const value = fieldsObj[schemaName].partialField.data[i];\n                hashData += `-${value}`;\n                tuple[schemaName] = value;\n            });\n            if (!hashTable[hashData]) {\n                if (addData) { data.push(tuple); }\n                hashTable[hashData] = true;\n            }\n        });\n    }\n\n    // Prepare the data\n    prepareDataHelper(dm2, dm2FieldStoreFieldObj, false);\n    prepareDataHelper(dm1, dm1FieldStoreFieldObj, true);\n\n    return new DataModel(data, schema, { name });\n}\n\n","import { isArray } from '../utils';\nimport InvalidAwareTypes from '../invalid-aware-types';\nimport { GROUP_BY_FUNCTIONS } from '../enums';\n\nconst { SUM, AVG, FIRST, LAST, COUNT, STD, MIN, MAX } = GROUP_BY_FUNCTIONS;\n\nfunction getFilteredValues(arr) {\n    return arr.filter(item => !(item instanceof InvalidAwareTypes));\n}\n/**\n * Reducer function that returns the sum of all the values.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the sum of the array.\n */\nfunction sum (arr) {\n    if (isArray(arr) && !(arr[0] instanceof Array)) {\n        const filteredNumber = getFilteredValues(arr);\n        const totalSum = filteredNumber.length ?\n                            filteredNumber.reduce((acc, curr) => acc + curr, 0)\n                            : InvalidAwareTypes.NULL;\n        return totalSum;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Reducer function that returns the average of all the values.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the mean value of the array.\n */\nfunction avg (arr) {\n    if (isArray(arr) && !(arr[0] instanceof Array)) {\n        const totalSum = sum(arr);\n        const len = arr.length || 1;\n        return (Number.isNaN(totalSum) || totalSum instanceof InvalidAwareTypes) ?\n                 InvalidAwareTypes.NULL : totalSum / len;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Reducer function that gives the min value amongst all the values.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the minimum value of the array.\n */\nfunction min (arr) {\n    if (isArray(arr) && !(arr[0] instanceof Array)) {\n        // Filter out undefined, null and NaN values\n        const filteredValues = getFilteredValues(arr);\n\n        return (filteredValues.length) ? Math.min(...filteredValues) : InvalidAwareTypes.NULL;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Reducer function that gives the max value amongst all the values.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the maximum value of the array.\n */\nfunction max (arr) {\n    if (isArray(arr) && !(arr[0] instanceof Array)) {\n        // Filter out undefined, null and NaN values\n        const filteredValues = getFilteredValues(arr);\n\n        return (filteredValues.length) ? Math.max(...filteredValues) : InvalidAwareTypes.NULL;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Reducer function that gives the first value of the array.\n *\n * @public\n * @param  {Array} arr - The input array.\n * @return {number} Returns the first value of the array.\n */\nfunction first (arr) {\n    return arr[0];\n}\n\n/**\n * Reducer function that gives the last value of the array.\n *\n * @public\n * @param  {Array} arr - The input array.\n * @return {number} Returns the last value of the array.\n */\nfunction last (arr) {\n    return arr[arr.length - 1];\n}\n\n/**\n * Reducer function that gives the count value of the array.\n *\n * @public\n * @param  {Array} arr - The input array.\n * @return {number} Returns the length of the array.\n */\nfunction count (arr) {\n    if (isArray(arr)) {\n        return arr.length;\n    }\n    return InvalidAwareTypes.NULL;\n}\n\n/**\n * Calculates the variance of the input array.\n *\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the variance of the input array.\n */\nfunction variance (arr) {\n    let mean = avg(arr);\n    return avg(arr.map(num => (num - mean) ** 2));\n}\n\n/**\n * Calculates the square root of the variance of the input array.\n *\n * @public\n * @param  {Array.<number>} arr - The input array.\n * @return {number} Returns the square root of the variance.\n */\nfunction std (arr) {\n    return Math.sqrt(variance(arr));\n}\n\n\nconst fnList = {\n    [SUM]: sum,\n    [AVG]: avg,\n    [MIN]: min,\n    [MAX]: max,\n    [FIRST]: first,\n    [LAST]: last,\n    [COUNT]: count,\n    [STD]: std\n};\n\nconst defaultReducerName = SUM;\n\nexport {\n    defaultReducerName,\n    sum as defReducer,\n    fnList,\n};\n","import { defReducer, fnList } from '../operator';\n\n/**\n * A page level storage which stores, registers, unregisters reducers for all the datamodel instances. There is only one\n * reducer store available in a page. All the datamodel instances receive same instance of reducer store. DataModel\n * out of the box provides handful of {@link reducer | reducers} which can be used as reducer funciton.\n *\n * @public\n * @namespace DataModel\n */\nclass ReducerStore {\n    constructor () {\n        this.store = new Map();\n        this.store.set('defReducer', defReducer);\n\n        Object.entries(fnList).forEach((key) => {\n            this.store.set(key[0], key[1]);\n        });\n    }\n\n    /**\n     * Changes the `defaultReducer` globally. For all the fields which does not have `defAggFn` mentioned in schema, the\n     * value of `defaultReducer` is used for aggregation.\n     *\n     * @public\n     * @param {string} [reducer='sum'] - The name of the default reducer. It picks up the definition from store by doing\n     * name lookup. If no name is found then it takes `sum` as the default reducer.\n     * @return {ReducerStore} Returns instance of the singleton store in page.\n     */\n    defaultReducer (...params) {\n        if (!params.length) {\n            return this.store.get('defReducer');\n        }\n\n        let reducer = params[0];\n\n        if (typeof reducer === 'function') {\n            this.store.set('defReducer', reducer);\n        } else {\n            reducer = String(reducer);\n            if (Object.keys(fnList).indexOf(reducer) !== -1) {\n                this.store.set('defReducer', fnList[reducer]);\n            } else {\n                throw new Error(`Reducer ${reducer} not found in registry`);\n            }\n        }\n        return this;\n    }\n\n    /**\n     *\n     * Registers a {@link reducer | reducer}.\n     * A {@link reducer | reducer} has to be registered before it is used.\n     *\n     * @example\n     *  // find the mean squared value of a given set\n     *  const reducerStore = DataModel.Reducers();\n     *\n     *  reducers.register('meanSquared', (arr) => {\n     *      const squaredVal = arr.map(item => item * item);\n     *      let sum = 0;\n     *      for (let i = 0, l = squaredVal.length; i < l; i++) {\n     *          sum += squaredVal[i++];\n     *      }\n     *\n     *      return sum;\n     *  })\n     *\n     *  // datamodel (dm) is already prepared with cars.json\n     *  const dm1 = dm.groupBy(['origin'], {\n     *      accleration: 'meanSquared'\n     *  });\n     *\n     * @public\n     *\n     * @param {string} name formal name for a reducer. If the given name already exists in store it is overridden by new\n     *      definition.\n     * @param {Function} reducer definition of {@link reducer} function.\n     *\n     * @return {Function} function for unregistering the reducer.\n     */\n    register (name, reducer) {\n        if (typeof reducer !== 'function') {\n            throw new Error('Reducer should be a function');\n        }\n\n        name = String(name);\n        this.store.set(name, reducer);\n\n        return () => { this.__unregister(name); };\n    }\n\n    __unregister (name) {\n        if (this.store.has(name)) {\n            this.store.delete(name);\n        }\n    }\n\n    resolve (name) {\n        if (name instanceof Function) {\n            return name;\n        }\n        return this.store.get(name);\n    }\n}\n\nconst reducerStore = (function () {\n    let store = null;\n\n    function getStore () {\n        if (store === null) {\n            store = new ReducerStore();\n        }\n        return store;\n    }\n    return getStore();\n}());\n\nexport default reducerStore;\n","import { extend2 } from '../utils';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport DataModel from '../export';\nimport reducerStore from '../utils/reducer-store';\nimport { defaultReducerName } from './group-by-function';\nimport { FieldType } from '../enums';\n\n/**\n * This function sanitize the user given field and return a common Array structure field\n * list\n * @param  {DataModel} dataModel the dataModel operating on\n * @param  {Array} fieldArr  user input of field Array\n * @return {Array}           arrays of field name\n */\nfunction getFieldArr (dataModel, fieldArr) {\n    const retArr = [];\n    const fieldStore = dataModel.getFieldspace();\n    const dimensions = fieldStore.getDimension();\n\n    Object.entries(dimensions).forEach(([key]) => {\n        if (fieldArr && fieldArr.length) {\n            if (fieldArr.indexOf(key) !== -1) {\n                retArr.push(key);\n            }\n        } else {\n            retArr.push(key);\n        }\n    });\n\n    return retArr;\n}\n\n/**\n * This sanitize the reducer provide by the user and create a common type of object.\n * user can give function Also\n * @param  {DataModel} dataModel     dataModel to worked on\n * @param  {Object|function} [reducers={}] reducer provided by the users\n * @return {Object}               object containing reducer function for every measure\n */\nfunction getReducerObj (dataModel, reducers = {}) {\n    const retObj = {};\n    const fieldStore = dataModel.getFieldspace();\n    const measures = fieldStore.getMeasure();\n    const defReducer = reducerStore.defaultReducer();\n\n    Object.keys(measures).forEach((measureName) => {\n        if (typeof reducers[measureName] !== 'string') {\n            reducers[measureName] = measures[measureName].defAggFn();\n        }\n        const reducerFn = reducerStore.resolve(reducers[measureName]);\n        if (reducerFn) {\n            retObj[measureName] = reducerFn;\n        } else {\n            retObj[measureName] = defReducer;\n            reducers[measureName] = defaultReducerName;\n        }\n    });\n    return retObj;\n}\n\n/**\n * main function which perform the group-by operations which reduce the measures value is the\n * fields are common according to the reducer function provided\n * @param  {DataModel} dataModel the dataModel to worked\n * @param  {Array} fieldArr  fields according to which the groupby should be worked\n * @param  {Object|Function} reducers  reducers function\n * @param {DataModel} existingDataModel Existing datamodel instance\n * @return {DataModel} new dataModel with the group by\n */\nfunction groupBy (dataModel, fieldArr, reducers, existingDataModel) {\n    const sFieldArr = getFieldArr(dataModel, fieldArr);\n    const reducerObj = getReducerObj(dataModel, reducers);\n    const fieldStore = dataModel.getFieldspace();\n    const fieldStoreObj = fieldStore.fieldsObj();\n    const dbName = fieldStore.name;\n    const dimensionArr = [];\n    const measureArr = [];\n    const schema = [];\n    const hashMap = {};\n    const data = [];\n    let newDataModel;\n\n    // Prepare the schema\n    Object.entries(fieldStoreObj).forEach(([key, value]) => {\n        if (sFieldArr.indexOf(key) !== -1 || reducerObj[key]) {\n            schema.push(extend2({}, value.schema()));\n\n            switch (value.schema().type) {\n            case FieldType.MEASURE:\n                measureArr.push(key);\n                break;\n            default:\n            case FieldType.DIMENSION:\n                dimensionArr.push(key);\n            }\n        }\n    });\n    // Prepare the data\n    let rowCount = 0;\n    rowDiffsetIterator(dataModel._rowDiffset, (i) => {\n        let hash = '';\n        dimensionArr.forEach((_) => {\n            hash = `${hash}-${fieldStoreObj[_].partialField.data[i]}`;\n        });\n        if (hashMap[hash] === undefined) {\n            hashMap[hash] = rowCount;\n            data.push({});\n            dimensionArr.forEach((_) => {\n                data[rowCount][_] = fieldStoreObj[_].partialField.data[i];\n            });\n            measureArr.forEach((_) => {\n                data[rowCount][_] = [fieldStoreObj[_].partialField.data[i]];\n            });\n            rowCount += 1;\n        } else {\n            measureArr.forEach((_) => {\n                data[hashMap[hash]][_].push(fieldStoreObj[_].partialField.data[i]);\n            });\n        }\n    });\n\n    // reduction\n    let cachedStore = {};\n    let cloneProvider = () => dataModel.detachedRoot();\n    data.forEach((row) => {\n        const tuple = row;\n        measureArr.forEach((_) => {\n            tuple[_] = reducerObj[_](row[_], cloneProvider, cachedStore);\n        });\n    });\n    if (existingDataModel) {\n        existingDataModel.__calculateFieldspace();\n        newDataModel = existingDataModel;\n    }\n    else {\n        newDataModel = new DataModel(data, schema, { name: dbName });\n    }\n    return newDataModel;\n}\n\nexport { groupBy, getFieldArr, getReducerObj };\n","import { getCommonSchema } from './get-common-schema';\n\n/**\n * The filter function used in natural join.\n * It generates a function that will have the logic to join two\n * DataModel instances by the process of natural join.\n *\n * @param {DataModel} dm1 - The left DataModel instance.\n * @param {DataModel} dm2 - The right DataModel instance.\n * @return {Function} Returns a function that is used in cross-product operation.\n */\nexport function naturalJoinFilter (dm1, dm2) {\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    // const dm1FieldStoreName = dm1FieldStore.name;\n    // const dm2FieldStoreName = dm2FieldStore.name;\n    const commonSchemaArr = getCommonSchema(dm1FieldStore, dm2FieldStore);\n\n    return (dm1Fields, dm2Fields) => {\n        let retainTuple = true;\n        commonSchemaArr.forEach((fieldName) => {\n            if (dm1Fields[fieldName].value ===\n                dm2Fields[fieldName].value && retainTuple) {\n                retainTuple = true;\n            } else {\n                retainTuple = false;\n            }\n        });\n        return retainTuple;\n    };\n}\n","import DataModel from '../export';\nimport { extend2 } from '../utils';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { isArrEqual } from '../utils/helper';\n/**\n * Performs the union operation between two dm instances.\n *\n * @param {dm} dm1 - The first dm instance.\n * @param {dm} dm2 - The second dm instance.\n * @return {dm} Returns the newly created dm after union operation.\n */\nexport function union (dm1, dm2) {\n    const hashTable = {};\n    const schema = [];\n    const schemaNameArr = [];\n    const data = [];\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    const dm1FieldStoreFieldObj = dm1FieldStore.fieldsObj();\n    const dm2FieldStoreFieldObj = dm2FieldStore.fieldsObj();\n    const name = `${dm1FieldStore.name} union ${dm2FieldStore.name}`;\n\n    // For union the columns should match otherwise return a clone of the dm1\n    if (!isArrEqual(dm1._colIdentifier.split(',').sort(), dm2._colIdentifier.split(',').sort())) {\n        return null;\n    }\n\n    // Prepare the schema\n    (dm1._colIdentifier.split(',')).forEach((fieldName) => {\n        const field = dm1FieldStoreFieldObj[fieldName];\n        schema.push(extend2({}, field.schema()));\n        schemaNameArr.push(field.schema().name);\n    });\n\n    /**\n     * The helper function to create the data.\n     *\n     * @param {dm} dm - The dm instance for which the data is inserted.\n     * @param {Object} fieldsObj - The fieldStore object format.\n     */\n    function prepareDataHelper (dm, fieldsObj) {\n        rowDiffsetIterator(dm._rowDiffset, (i) => {\n            const tuple = {};\n            let hashData = '';\n            schemaNameArr.forEach((schemaName) => {\n                const value = fieldsObj[schemaName].partialField.data[i];\n                hashData += `-${value}`;\n                tuple[schemaName] = value;\n            });\n            if (!hashTable[hashData]) {\n                data.push(tuple);\n                hashTable[hashData] = true;\n            }\n        });\n    }\n\n    // Prepare the data\n    prepareDataHelper(dm1, dm1FieldStoreFieldObj);\n    prepareDataHelper(dm2, dm2FieldStoreFieldObj);\n\n    return new DataModel(data, schema, { name });\n}\n","import { crossProduct } from './cross-product';\nimport { JOINS } from '../constants';\nimport { union } from './union';\n\n\nexport function leftOuterJoin (dataModel1, dataModel2, filterFn) {\n    return crossProduct(dataModel1, dataModel2, filterFn, false, JOINS.LEFTOUTER);\n}\n\nexport function rightOuterJoin (dataModel1, dataModel2, filterFn) {\n    return crossProduct(dataModel2, dataModel1, filterFn, false, JOINS.RIGHTOUTER);\n}\n\nexport function fullOuterJoin (dataModel1, dataModel2, filterFn) {\n    return union(leftOuterJoin(dataModel1, dataModel2, filterFn), rightOuterJoin(dataModel1, dataModel2, filterFn));\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\n\n/**\n * In {@link DataModel}, every tabular data consists of column, a column is stored as field.\n * Field contains all the data for a given column in an array.\n *\n * Each record consists of several fields; the fields of all records form the columns.\n * Examples of fields: name, gender, sex etc.\n *\n * In DataModel, each field can have multiple attributes which describes its data and behaviour.\n * A field can have two types of data: Measure and Dimension.\n *\n * A Dimension Field is the context on which a data is categorized and the measure is the numerical values that\n * quantify the data set.\n * In short a dimension is the lens through which you are looking at your measure data.\n *\n * Refer to {@link Schema} to get info about possible field attributes.\n *\n * @public\n * @class\n */\nexport default class Field {\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {PartialField} partialField - The partialField instance which holds the whole data.\n     * @param {string} rowDiffset - The data subset definition.\n     */\n    constructor (partialField, rowDiffset) {\n        this.partialField = partialField;\n        this.rowDiffset = rowDiffset;\n    }\n\n    /**\n     * Generates the field type specific domain.\n     *\n     * @public\n     * @abstract\n     */\n    domain () {\n        throw new Error('Not yet implemented');\n    }\n\n    /**\n     * Returns the the field schema.\n     *\n     * @public\n     * @return {string} Returns the field schema.\n     */\n    schema () {\n        return this.partialField.schema;\n    }\n\n    /**\n     * Returns the name of the field.\n     *\n     * @public\n     * @return {string} Returns the name of the field.\n     */\n    name () {\n        return this.partialField.name;\n    }\n\n    /**\n     * Returns the type of the field.\n     *\n     * @public\n     * @return {string} Returns the type of the field.\n     */\n    type () {\n        return this.partialField.schema.type;\n    }\n\n    /**\n     * Returns the subtype of the field.\n     *\n     * @public\n     * @return {string} Returns the subtype of the field.\n     */\n    subtype () {\n        return this.partialField.schema.subtype;\n    }\n\n    /**\n     * Returns the description of the field.\n     *\n     * @public\n     * @return {string} Returns the description of the field.\n     */\n    description () {\n        return this.partialField.schema.description;\n    }\n\n    /**\n     * Returns the display name of the field.\n     *\n     * @public\n     * @return {string} Returns the display name of the field.\n     */\n    displayName () {\n        return this.partialField.schema.displayName || this.partialField.schema.name;\n    }\n\n    /**\n     * Returns the data associated with the field.\n     *\n     * @public\n     * @return {Array} Returns the data.\n     */\n    data () {\n        const data = [];\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            data.push(this.partialField.data[i]);\n        });\n        return data;\n    }\n\n    /**\n     * Returns the formatted version of the underlying field data.\n     *\n     * @public\n     * @abstract\n     */\n    formattedData () {\n        throw new Error('Not yet implemented');\n    }\n}\n","import Field from '../field';\n\n/**\n * Represents dimension field type.\n *\n * @public\n * @class\n * @extends Field\n */\nexport default class Dimension extends Field {\n    /**\n     * Returns the domain for the dimension field.\n     *\n     * @override\n     * @public\n     * @return {any} Returns the calculated domain.\n     */\n    domain () {\n        if (!this._cachedDomain) {\n            this._cachedDomain = this.calculateDataDomain();\n        }\n        return this._cachedDomain;\n    }\n\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @abstract\n     */\n    calculateDataDomain () {\n        throw new Error('Not yet implemented');\n    }\n\n     /**\n     * Returns the formatted version of the underlying field data.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the formatted data.\n     */\n    formattedData () {\n        return this.data();\n    }\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\nimport { DimensionSubtype } from '../../enums';\nimport Dimension from '../dimension';\n/**\n * Represents categorical field subtype.\n *\n * @public\n * @class\n * @extends Dimension\n */\nexport default class Categorical extends Dimension {\n    /**\n     * Returns the subtype of the field.\n     *\n     * @public\n     * @override\n     * @return {string} Returns the subtype of the field.\n     */\n    subtype () {\n        return DimensionSubtype.CATEGORICAL;\n    }\n\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the unique values.\n     */\n    calculateDataDomain () {\n        const hash = new Set();\n        const domain = [];\n\n        // here don't use this.data() as the iteration will be occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (!hash.has(datum)) {\n                hash.add(datum);\n                domain.push(datum);\n            }\n        });\n        return domain;\n    }\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\nimport Dimension from '../dimension';\nimport { DateTimeFormatter } from '../../utils';\nimport InvalidAwareTypes from '../../invalid-aware-types';\n\n/**\n * Represents temporal field subtype.\n *\n * @public\n * @class\n * @extends Dimension\n */\nexport default class Temporal extends Dimension {\n     /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {PartialField} partialField - The partialField instance which holds the whole data.\n     * @param {string} rowDiffset - The data subset definition.\n     */\n    constructor (partialField, rowDiffset) {\n        super(partialField, rowDiffset);\n\n        this._cachedMinDiff = null;\n    }\n\n     /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the unique values.\n     */\n    calculateDataDomain () {\n        const hash = new Set();\n        const domain = [];\n\n        // here don't use this.data() as the iteration will be\n        // occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (!hash.has(datum)) {\n                hash.add(datum);\n                domain.push(datum);\n            }\n        });\n\n        return domain;\n    }\n\n\n    /**\n     * Calculates the minimum consecutive difference from the associated field data.\n     *\n     * @public\n     * @return {number} Returns the minimum consecutive diff in milliseconds.\n     */\n    minimumConsecutiveDifference () {\n        if (this._cachedMinDiff) {\n            return this._cachedMinDiff;\n        }\n\n        const sortedData = this.data().filter(item => !(item instanceof InvalidAwareTypes)).sort((a, b) => a - b);\n        const arrLn = sortedData.length;\n        let minDiff = Number.POSITIVE_INFINITY;\n        let prevDatum;\n        let nextDatum;\n        let processedCount = 0;\n\n        for (let i = 1; i < arrLn; i++) {\n            prevDatum = sortedData[i - 1];\n            nextDatum = sortedData[i];\n\n            if (nextDatum === prevDatum) {\n                continue;\n            }\n\n            minDiff = Math.min(minDiff, nextDatum - sortedData[i - 1]);\n            processedCount++;\n        }\n\n        if (!processedCount) {\n            minDiff = null;\n        }\n        this._cachedMinDiff = minDiff;\n\n        return this._cachedMinDiff;\n    }\n\n    /**\n     * Returns the format specified in the input schema while creating field.\n     *\n     * @public\n     * @return {string} Returns the datetime format.\n     */\n    format () {\n        return this.partialField.schema.format;\n    }\n\n    /**\n     * Returns the formatted version of the underlying field data.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the formatted data.\n     */\n    formattedData () {\n        const data = [];\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (datum instanceof InvalidAwareTypes) {\n                data.push(datum);\n            } else {\n                data.push(DateTimeFormatter.formatAs(datum, this.format()));\n            }\n        });\n        return data;\n    }\n}\n\n","import Dimension from '../dimension';\n\n/**\n * Represents binned field subtype.\n *\n * @public\n * @class\n * @extends Dimension\n */\nexport default class Binned extends Dimension {\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the last and first values of bins config array.\n     */\n    calculateDataDomain () {\n        const binsArr = this.partialField.schema.bins;\n        return [binsArr[0], binsArr[binsArr.length - 1]];\n    }\n\n    /**\n     * Returns the bins config provided while creating the field instance.\n     *\n     * @public\n     * @return {Array} Returns the bins array config.\n     */\n    bins () {\n        return this.partialField.schema.bins;\n    }\n}\n","import { formatNumber } from '../../utils';\nimport { defaultReducerName } from '../../operator/group-by-function';\nimport Field from '../field';\n\n/**\n * Represents measure field type.\n *\n * @public\n * @class\n * @extends Field\n */\nexport default class Measure extends Field {\n  /**\n   * Returns the domain for the measure field.\n   *\n   * @override\n   * @public\n   * @return {any} Returns the calculated domain.\n   */\n    domain () {\n        if (!this._cachedDomain) {\n            this._cachedDomain = this.calculateDataDomain();\n        }\n        return this._cachedDomain;\n    }\n\n  /**\n   * Returns the unit of the measure field.\n   *\n   * @public\n   * @return {string} Returns unit of the field.\n   */\n    unit () {\n        return this.partialField.schema.unit;\n    }\n\n  /**\n   * Returns the aggregation function name of the measure field.\n   *\n   * @public\n   * @return {string} Returns aggregation function name of the field.\n   */\n    defAggFn () {\n        return this.partialField.schema.defAggFn || defaultReducerName;\n    }\n\n  /**\n   * Returns the number format of the measure field.\n   *\n   * @public\n   * @return {Function} Returns number format of the field.\n   */\n    numberFormat () {\n        const { numberFormat } = this.partialField.schema;\n        return numberFormat instanceof Function ? numberFormat : formatNumber;\n    }\n\n  /**\n   * Calculates the corresponding field domain.\n   *\n   * @public\n   * @abstract\n   */\n    calculateDataDomain () {\n        throw new Error('Not yet implemented');\n    }\n\n    /**\n     * Returns the formatted version of the underlying field data.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the formatted data.\n     */\n    formattedData () {\n        return this.data();\n    }\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\nimport { MeasureSubtype } from '../../enums';\nimport Measure from '../measure';\nimport InvalidAwareTypes from '../../invalid-aware-types';\n\n/**\n * Represents continuous field subtype.\n *\n * @public\n * @class\n * @extends Measure\n */\nexport default class Continuous extends Measure {\n    /**\n     * Returns the subtype of the field.\n     *\n     * @public\n     * @override\n     * @return {string} Returns the subtype of the field.\n     */\n    subtype () {\n        return MeasureSubtype.CONTINUOUS;\n    }\n\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the min and max values.\n     */\n    calculateDataDomain () {\n        let min = Number.POSITIVE_INFINITY;\n        let max = Number.NEGATIVE_INFINITY;\n\n        // here don't use this.data() as the iteration will be occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (datum instanceof InvalidAwareTypes) {\n                return;\n            }\n\n            if (datum < min) {\n                min = datum;\n            }\n            if (datum > max) {\n                max = datum;\n            }\n        });\n\n        return [min, max];\n    }\n}\n","/**\n * A interface to represent a parser which is responsible to parse the field.\n *\n * @public\n * @interface\n */\nexport default class FieldParser {\n    /**\n     * Parses a single value of a field and return the sanitized form.\n     *\n     * @public\n     * @abstract\n     */\n    parse () {\n        throw new Error('Not yet implemented');\n    }\n}\n","import FieldParser from '../field-parser';\nimport InvalidAwareTypes from '../../../invalid-aware-types';\n\n/**\n * A FieldParser which parses the categorical values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class CategoricalParser extends FieldParser {\n  /**\n   * Parses a single value of a field and returns the stringified form.\n   *\n   * @public\n   * @param {string|number} val - The value of the field.\n   * @return {string} Returns the stringified value.\n   */\n    parse (val) {\n        let result;\n        // check if invalid date value\n        if (!InvalidAwareTypes.isInvalid(val)) {\n            result = String(val).trim();\n        } else {\n            result = InvalidAwareTypes.getInvalidType(val);\n        }\n        return result;\n    }\n}\n","import { DateTimeFormatter } from '../../../utils';\nimport FieldParser from '../field-parser';\nimport InvalidAwareTypes from '../../../invalid-aware-types';\n\n/**\n * A FieldParser which parses the temporal values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class TemporalParser extends FieldParser {\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {Object} schema - The schema object for the corresponding field.\n     */\n    constructor (schema) {\n        super();\n        this.schema = schema;\n        this._dtf = new DateTimeFormatter(this.schema.format);\n    }\n\n    /**\n     * Parses a single value of a field and returns the millisecond value.\n     *\n     * @public\n     * @param {string|number} val - The value of the field.\n     * @return {number} Returns the millisecond value.\n     */\n    parse (val) {\n        let result;\n        // check if invalid date value\n        if (!InvalidAwareTypes.isInvalid(val)) {\n            let nativeDate = this._dtf.getNativeDate(val);\n            result = nativeDate ? nativeDate.getTime() : InvalidAwareTypes.NA;\n        } else {\n            result = InvalidAwareTypes.getInvalidType(val);\n        }\n        return result;\n    }\n}\n","import FieldParser from '../field-parser';\nimport InvalidAwareTypes from '../../../invalid-aware-types';\n\n/**\n * A FieldParser which parses the binned values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class BinnedParser extends FieldParser {\n  /**\n   * Parses a single binned value of a field and returns the sanitized value.\n   *\n   * @public\n   * @param {string} val - The value of the field.\n   * @return {string} Returns the sanitized value.\n   */\n    parse (val) {\n        const regex = /^\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*-\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*$/;\n        val = String(val);\n        let result;\n        // check if invalid date value\n        if (!InvalidAwareTypes.isInvalid(val)) {\n            let matched = val.match(regex);\n            result = matched ? `${Number.parseFloat(matched[1])}-${Number.parseFloat(matched[2])}`\n                             : InvalidAwareTypes.NA;\n        } else {\n            result = InvalidAwareTypes.getInvalidType(val);\n        }\n        return result;\n    }\n}\n","import FieldParser from '../field-parser';\nimport InvalidAwareTypes from '../../../invalid-aware-types';\n\n/**\n * A FieldParser which parses the continuous values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class ContinuousParser extends FieldParser {\n  /**\n   * Parses a single value of a field and returns the number form.\n   *\n   * @public\n   * @param {string|number} val - The value of the field.\n   * @return {string} Returns the number value.\n   */\n    parse (val) {\n        let result;\n        // check if invalid date value\n        if (!InvalidAwareTypes.isInvalid(val)) {\n            let parsedVal = parseFloat(val, 10);\n            result = Number.isNaN(parsedVal) ? InvalidAwareTypes.NA : parsedVal;\n        } else {\n            result = InvalidAwareTypes.getInvalidType(val);\n        }\n        return result;\n    }\n}\n","/**\n * Stores the full data and the metadata of a field. It provides\n * a single source of data from which the future Field\n * instance can get a subset of it with a rowDiffset config.\n *\n * @class\n * @public\n */\nexport default class PartialField {\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {string} name - The name of the field.\n     * @param {Array} data - The data array.\n     * @param {Object} schema - The schema object of the corresponding field.\n     * @param {FieldParser} parser - The parser instance corresponding to that field.\n     */\n    constructor (name, data, schema, parser) {\n        this.name = name;\n        this.schema = schema;\n        this.parser = parser;\n        this.data = this._sanitize(data);\n    }\n\n    /**\n     * Sanitizes the field data.\n     *\n     * @private\n     * @param {Array} data - The actual input data.\n     * @return {Array} Returns the sanitized data.\n     */\n    _sanitize (data) {\n        return data.map(datum => this.parser.parse(datum));\n    }\n}\n","import { FieldType, DimensionSubtype, MeasureSubtype } from './enums';\nimport {\n    Categorical,\n    Temporal,\n    Binned,\n    Continuous,\n    CategoricalParser,\n    TemporalParser,\n    BinnedParser,\n    ContinuousParser,\n    PartialField\n} from './fields';\n\n/**\n * Creates a field instance according to the provided data and schema.\n *\n * @param {Array} data - The field data array.\n * @param {Object} schema - The field schema object.\n * @return {Field} Returns the newly created field instance.\n */\nfunction createUnitField(data, schema) {\n    data = data || [];\n    let partialField;\n\n    switch (schema.type) {\n    case FieldType.MEASURE:\n        switch (schema.subtype) {\n        case MeasureSubtype.CONTINUOUS:\n            partialField = new PartialField(schema.name, data, schema, new ContinuousParser());\n            return new Continuous(partialField, `0-${data.length - 1}`);\n        default:\n            partialField = new PartialField(schema.name, data, schema, new ContinuousParser());\n            return new Continuous(partialField, `0-${data.length - 1}`);\n        }\n    case FieldType.DIMENSION:\n        switch (schema.subtype) {\n        case DimensionSubtype.CATEGORICAL:\n            partialField = new PartialField(schema.name, data, schema, new CategoricalParser());\n            return new Categorical(partialField, `0-${data.length - 1}`);\n        case DimensionSubtype.TEMPORAL:\n            partialField = new PartialField(schema.name, data, schema, new TemporalParser(schema));\n            return new Temporal(partialField, `0-${data.length - 1}`);\n        case DimensionSubtype.BINNED:\n            partialField = new PartialField(schema.name, data, schema, new BinnedParser());\n            return new Binned(partialField, `0-${data.length - 1}`);\n        default:\n            partialField = new PartialField(schema.name, data, schema, new CategoricalParser());\n            return new Categorical(partialField, `0-${data.length - 1}`);\n        }\n    default:\n        partialField = new PartialField(schema.name, data, schema, new CategoricalParser());\n        return new Categorical(partialField, `0-${data.length - 1}`);\n    }\n}\n\n\n/**\n * Creates a field instance from partialField and rowDiffset.\n *\n * @param {PartialField} partialField - The corresponding partial field.\n * @param {string} rowDiffset - The data subset config.\n * @return {Field} Returns the newly created field instance.\n */\nexport function createUnitFieldFromPartial(partialField, rowDiffset) {\n    const { schema } = partialField;\n\n    switch (schema.type) {\n    case FieldType.MEASURE:\n        switch (schema.subtype) {\n        case MeasureSubtype.CONTINUOUS:\n            return new Continuous(partialField, rowDiffset);\n        default:\n            return new Continuous(partialField, rowDiffset);\n        }\n    case FieldType.DIMENSION:\n        switch (schema.subtype) {\n        case DimensionSubtype.CATEGORICAL:\n            return new Categorical(partialField, rowDiffset);\n        case DimensionSubtype.TEMPORAL:\n            return new Temporal(partialField, rowDiffset);\n        case DimensionSubtype.BINNED:\n            return new Binned(partialField, rowDiffset);\n        default:\n            return new Categorical(partialField, rowDiffset);\n        }\n    default:\n        return new Categorical(partialField, rowDiffset);\n    }\n}\n\n/**\n * Creates the field instances with input data and schema.\n *\n * @param {Array} dataColumn - The data array for fields.\n * @param {Array} schema - The schema array for fields.\n * @param {Array} headers - The array of header names.\n * @return {Array.<Field>} Returns an array of newly created field instances.\n */\nexport function createFields(dataColumn, schema, headers) {\n    const headersObj = {};\n\n    if (!(headers && headers.length)) {\n        headers = schema.map(item => item.name);\n    }\n\n    headers.forEach((header, i) => {\n        headersObj[header] = i;\n    });\n\n    return schema.map(item => createUnitField(dataColumn[headersObj[item.name]], item));\n}\n","import { DataFormat } from './enums';\n\nexport default {\n    dataFormat: DataFormat.AUTO\n};\n","import { columnMajor } from '../utils';\n\n/**\n * Parses and converts data formatted in DSV array to a manageable internal format.\n *\n * @param {Array.<Array>} arr - A 2D array containing of the DSV data.\n * @param {Object} options - Option to control the behaviour of the parsing.\n * @param {boolean} [options.firstRowHeader=true] - Whether the first row of the dsv data is header or not.\n * @return {Array} Returns an array of headers and column major data.\n * @example\n *\n * // Sample input data:\n * const data = [\n *    [\"a\", \"b\", \"c\"],\n *    [1, 2, 3],\n *    [4, 5, 6],\n *    [7, 8, 9]\n * ];\n */\nfunction DSVArr (arr, options) {\n    const defaultOption = {\n        firstRowHeader: true,\n    };\n    options = Object.assign({}, defaultOption, options);\n\n    let header;\n    const columns = [];\n    const push = columnMajor(columns);\n\n    if (options.firstRowHeader) {\n        // If header present then mutate the array.\n        // Do in-place mutation to save space.\n        header = arr.splice(0, 1)[0];\n    } else {\n        header = [];\n    }\n\n    arr.forEach(field => push(...field));\n\n    return [header, columns];\n}\n\nexport default DSVArr;\n","var EOL = {},\n    EOF = {},\n    QUOTE = 34,\n    NEWLINE = 10,\n    RETURN = 13;\n\nfunction objectConverter(columns) {\n  return new Function(\"d\", \"return {\" + columns.map(function(name, i) {\n    return JSON.stringify(name) + \": d[\" + i + \"]\";\n  }).join(\",\") + \"}\");\n}\n\nfunction customConverter(columns, f) {\n  var object = objectConverter(columns);\n  return function(row, i) {\n    return f(object(row), i, columns);\n  };\n}\n\n// Compute unique columns in order of discovery.\nfunction inferColumns(rows) {\n  var columnSet = Object.create(null),\n      columns = [];\n\n  rows.forEach(function(row) {\n    for (var column in row) {\n      if (!(column in columnSet)) {\n        columns.push(columnSet[column] = column);\n      }\n    }\n  });\n\n  return columns;\n}\n\nfunction pad(value, width) {\n  var s = value + \"\", length = s.length;\n  return length < width ? new Array(width - length + 1).join(0) + s : s;\n}\n\nfunction formatYear(year) {\n  return year < 0 ? \"-\" + pad(-year, 6)\n    : year > 9999 ? \"+\" + pad(year, 6)\n    : pad(year, 4);\n}\n\nfunction formatDate(date) {\n  var hours = date.getUTCHours(),\n      minutes = date.getUTCMinutes(),\n      seconds = date.getUTCSeconds(),\n      milliseconds = date.getUTCMilliseconds();\n  return isNaN(date) ? \"Invalid Date\"\n      : formatYear(date.getUTCFullYear(), 4) + \"-\" + pad(date.getUTCMonth() + 1, 2) + \"-\" + pad(date.getUTCDate(), 2)\n      + (milliseconds ? \"T\" + pad(hours, 2) + \":\" + pad(minutes, 2) + \":\" + pad(seconds, 2) + \".\" + pad(milliseconds, 3) + \"Z\"\n      : seconds ? \"T\" + pad(hours, 2) + \":\" + pad(minutes, 2) + \":\" + pad(seconds, 2) + \"Z\"\n      : minutes || hours ? \"T\" + pad(hours, 2) + \":\" + pad(minutes, 2) + \"Z\"\n      : \"\");\n}\n\nexport default function(delimiter) {\n  var reFormat = new RegExp(\"[\\\"\" + delimiter + \"\\n\\r]\"),\n      DELIMITER = delimiter.charCodeAt(0);\n\n  function parse(text, f) {\n    var convert, columns, rows = parseRows(text, function(row, i) {\n      if (convert) return convert(row, i - 1);\n      columns = row, convert = f ? customConverter(row, f) : objectConverter(row);\n    });\n    rows.columns = columns || [];\n    return rows;\n  }\n\n  function parseRows(text, f) {\n    var rows = [], // output rows\n        N = text.length,\n        I = 0, // current character index\n        n = 0, // current line number\n        t, // current token\n        eof = N <= 0, // current token followed by EOF?\n        eol = false; // current token followed by EOL?\n\n    // Strip the trailing newline.\n    if (text.charCodeAt(N - 1) === NEWLINE) --N;\n    if (text.charCodeAt(N - 1) === RETURN) --N;\n\n    function token() {\n      if (eof) return EOF;\n      if (eol) return eol = false, EOL;\n\n      // Unescape quotes.\n      var i, j = I, c;\n      if (text.charCodeAt(j) === QUOTE) {\n        while (I++ < N && text.charCodeAt(I) !== QUOTE || text.charCodeAt(++I) === QUOTE);\n        if ((i = I) >= N) eof = true;\n        else if ((c = text.charCodeAt(I++)) === NEWLINE) eol = true;\n        else if (c === RETURN) { eol = true; if (text.charCodeAt(I) === NEWLINE) ++I; }\n        return text.slice(j + 1, i - 1).replace(/\"\"/g, \"\\\"\");\n      }\n\n      // Find next delimiter or newline.\n      while (I < N) {\n        if ((c = text.charCodeAt(i = I++)) === NEWLINE) eol = true;\n        else if (c === RETURN) { eol = true; if (text.charCodeAt(I) === NEWLINE) ++I; }\n        else if (c !== DELIMITER) continue;\n        return text.slice(j, i);\n      }\n\n      // Return last token before EOF.\n      return eof = true, text.slice(j, N);\n    }\n\n    while ((t = token()) !== EOF) {\n      var row = [];\n      while (t !== EOL && t !== EOF) row.push(t), t = token();\n      if (f && (row = f(row, n++)) == null) continue;\n      rows.push(row);\n    }\n\n    return rows;\n  }\n\n  function preformatBody(rows, columns) {\n    return rows.map(function(row) {\n      return columns.map(function(column) {\n        return formatValue(row[column]);\n      }).join(delimiter);\n    });\n  }\n\n  function format(rows, columns) {\n    if (columns == null) columns = inferColumns(rows);\n    return [columns.map(formatValue).join(delimiter)].concat(preformatBody(rows, columns)).join(\"\\n\");\n  }\n\n  function formatBody(rows, columns) {\n    if (columns == null) columns = inferColumns(rows);\n    return preformatBody(rows, columns).join(\"\\n\");\n  }\n\n  function formatRows(rows) {\n    return rows.map(formatRow).join(\"\\n\");\n  }\n\n  function formatRow(row) {\n    return row.map(formatValue).join(delimiter);\n  }\n\n  function formatValue(value) {\n    return value == null ? \"\"\n        : value instanceof Date ? formatDate(value)\n        : reFormat.test(value += \"\") ? \"\\\"\" + value.replace(/\"/g, \"\\\"\\\"\") + \"\\\"\"\n        : value;\n  }\n\n  return {\n    parse: parse,\n    parseRows: parseRows,\n    format: format,\n    formatBody: formatBody,\n    formatRows: formatRows\n  };\n}\n","import dsv from \"./dsv\";\n\nvar csv = dsv(\",\");\n\nexport var csvParse = csv.parse;\nexport var csvParseRows = csv.parseRows;\nexport var csvFormat = csv.format;\nexport var csvFormatBody = csv.formatBody;\nexport var csvFormatRows = csv.formatRows;\n","import dsv from \"./dsv\";\n\nvar tsv = dsv(\"\\t\");\n\nexport var tsvParse = tsv.parse;\nexport var tsvParseRows = tsv.parseRows;\nexport var tsvFormat = tsv.format;\nexport var tsvFormatBody = tsv.formatBody;\nexport var tsvFormatRows = tsv.formatRows;\n","import { dsvFormat as d3Dsv } from 'd3-dsv';\nimport DSVArr from './dsv-arr';\n\n/**\n * Parses and converts data formatted in DSV string to a manageable internal format.\n *\n * @todo Support to be given for https://tools.ietf.org/html/rfc4180.\n * @todo Sample implementation https://github.com/knrz/CSV.js/.\n *\n * @param {string} str - The input DSV string.\n * @param {Object} options - Option to control the behaviour of the parsing.\n * @param {boolean} [options.firstRowHeader=true] - Whether the first row of the dsv string data is header or not.\n * @param {string} [options.fieldSeparator=\",\"] - The separator of two consecutive field.\n * @return {Array} Returns an array of headers and column major data.\n * @example\n *\n * // Sample input data:\n * const data = `\n * a,b,c\n * 1,2,3\n * 4,5,6\n * 7,8,9\n * `\n */\nfunction DSVStr (str, options) {\n    const defaultOption = {\n        firstRowHeader: true,\n        fieldSeparator: ','\n    };\n    options = Object.assign({}, defaultOption, options);\n\n    const dsv = d3Dsv(options.fieldSeparator);\n    return DSVArr(dsv.parseRows(str), options);\n}\n\nexport default DSVStr;\n","import { columnMajor } from '../utils';\n\n/**\n * Parses and converts data formatted in JSON to a manageable internal format.\n *\n * @param {Array.<Object>} arr - The input data formatted in JSON.\n * @return {Array.<Object>} Returns an array of headers and column major data.\n * @example\n *\n * // Sample input data:\n * const data = [\n *    {\n *      \"a\": 1,\n *      \"b\": 2,\n *      \"c\": 3\n *    },\n *    {\n *      \"a\": 4,\n *      \"b\": 5,\n *      \"c\": 6\n *    },\n *    {\n *      \"a\": 7,\n *      \"b\": 8,\n *      \"c\": 9\n *    }\n * ];\n */\nfunction FlatJSON (arr) {\n    const header = {};\n    let i = 0;\n    let insertionIndex;\n    const columns = [];\n    const push = columnMajor(columns);\n\n    arr.forEach((item) => {\n        const fields = [];\n        for (let key in item) {\n            if (key in header) {\n                insertionIndex = header[key];\n            } else {\n                header[key] = i++;\n                insertionIndex = i - 1;\n            }\n            fields[insertionIndex] = item[key];\n        }\n        push(...fields);\n    });\n\n    return [Object.keys(header), columns];\n}\n\nexport default FlatJSON;\n","import FlatJSON from './flat-json';\nimport DSVArr from './dsv-arr';\nimport DSVStr from './dsv-str';\nimport { detectDataFormat } from '../utils';\n\n/**\n * Parses the input data and detect the format automatically.\n *\n * @param {string|Array} data - The input data.\n * @param {Object} options - An optional config specific to data format.\n * @return {Array.<Object>} Returns an array of headers and column major data.\n */\nfunction Auto (data, options) {\n    const converters = { FlatJSON, DSVStr, DSVArr };\n    const dataFormat = detectDataFormat(data);\n\n    if (!dataFormat) {\n        throw new Error('Couldn\\'t detect the data format');\n    }\n\n    return converters[dataFormat](data, options);\n}\n\nexport default Auto;\n","import { FieldType, FilteringMode, DimensionSubtype, MeasureSubtype, DataFormat } from './enums';\nimport fieldStore from './field-store';\nimport Value from './value';\nimport {\n    rowDiffsetIterator\n} from './operator';\nimport { DM_DERIVATIVES, LOGICAL_OPERATORS } from './constants';\nimport { createFields, createUnitFieldFromPartial } from './field-creator';\nimport defaultConfig from './default-config';\nimport * as converter from './converter';\nimport { extend2, detectDataFormat } from './utils';\n\n/**\n * Prepares the selection data.\n */\nfunction prepareSelectionData (fields, i) {\n    const resp = {};\n    for (let field of fields) {\n        resp[field.name()] = new Value(field.partialField.data[i], field);\n    }\n    return resp;\n}\n\nexport function prepareJoinData (fields) {\n    const resp = {};\n    Object.keys(fields).forEach((key) => { resp[key] = new Value(fields[key], key); });\n    return resp;\n}\n\nexport const updateFields = ([rowDiffset, colIdentifier], partialFieldspace, fieldStoreName) => {\n    let collID = colIdentifier.length ? colIdentifier.split(',') : [];\n    let partialFieldMap = partialFieldspace.fieldsObj();\n    let newFields = collID.map(coll => createUnitFieldFromPartial(partialFieldMap[coll].partialField, rowDiffset));\n    return fieldStore.createNamespace(newFields, fieldStoreName);\n};\n\nexport const persistCurrentDerivation = (model, operation, config = {}, criteriaFn) => {\n    if (operation === DM_DERIVATIVES.COMPOSE) {\n        model._derivation.length = 0;\n        model._derivation.push(...criteriaFn);\n    } else {\n        model._derivation.push({\n            op: operation,\n            meta: config,\n            criteria: criteriaFn\n        });\n    }\n};\nexport const persistAncestorDerivation = (sourceDm, newDm) => {\n    newDm._ancestorDerivation.push(...sourceDm._ancestorDerivation, ...sourceDm._derivation);\n};\n\nexport const persistDerivations = (sourceDm, model, operation, config = {}, criteriaFn) => {\n    persistCurrentDerivation(model, operation, config, criteriaFn);\n    persistAncestorDerivation(sourceDm, model);\n};\n\nconst selectModeMap = {\n    [FilteringMode.NORMAL]: {\n        diffIndex: ['rowDiffset'],\n        calcDiff: [true, false]\n    },\n    [FilteringMode.INVERSE]: {\n        diffIndex: ['rejectRowDiffset'],\n        calcDiff: [false, true]\n    },\n    [FilteringMode.ALL]: {\n        diffIndex: ['rowDiffset', 'rejectRowDiffset'],\n        calcDiff: [true, true]\n    }\n};\n\nconst generateRowDiffset = (rowDiffset, i, lastInsertedValue) => {\n    if (lastInsertedValue !== -1 && i === (lastInsertedValue + 1)) {\n        const li = rowDiffset.length - 1;\n\n        rowDiffset[li] = `${rowDiffset[li].split('-')[0]}-${i}`;\n    } else {\n        rowDiffset.push(`${i}`);\n    }\n};\n\nexport const selectRowDiffsetIterator = (rowDiffset, checker, mode) => {\n    let lastInsertedValueSel = -1;\n    let lastInsertedValueRej = -1;\n    const newRowDiffSet = [];\n    const rejRowDiffSet = [];\n\n    const [shouldSelect, shouldReject] = selectModeMap[mode].calcDiff;\n\n    rowDiffsetIterator(rowDiffset, (i) => {\n        const checkerResult = checker(i);\n        checkerResult && shouldSelect && generateRowDiffset(newRowDiffSet, i, lastInsertedValueSel);\n        !checkerResult && shouldReject && generateRowDiffset(rejRowDiffSet, i, lastInsertedValueRej);\n    });\n    return {\n        rowDiffset: newRowDiffSet.join(','),\n        rejectRowDiffset: rejRowDiffSet.join(',')\n    };\n};\n\n\nexport const rowSplitDiffsetIterator = (rowDiffset, checker, mode, dimensionArr, fieldStoreObj) => {\n    let lastInsertedValue = {};\n    const splitRowDiffset = {};\n    const dimensionMap = {};\n\n    rowDiffsetIterator(rowDiffset, (i) => {\n        if (checker(i)) {\n            let hash = '';\n\n            let dimensionSet = { keys: {} };\n\n            dimensionArr.forEach((_) => {\n                const data = fieldStoreObj[_].partialField.data[i];\n                hash = `${hash}-${data}`;\n                dimensionSet.keys[_] = data;\n            });\n\n            if (splitRowDiffset[hash] === undefined) {\n                splitRowDiffset[hash] = [];\n                lastInsertedValue[hash] = -1;\n                dimensionMap[hash] = dimensionSet;\n            }\n\n            generateRowDiffset(splitRowDiffset[hash], i, lastInsertedValue[hash]);\n            lastInsertedValue[hash] = i;\n        }\n    });\n\n    return {\n        splitRowDiffset,\n        dimensionMap\n    };\n};\n\n\nexport const selectHelper = (clonedDm, selectFn, config, sourceDm, iterator) => {\n    let cachedStore = {};\n    let cloneProvider = () => sourceDm.detachedRoot();\n    const { mode } = config;\n    const rowDiffset = clonedDm._rowDiffset;\n    const fields = clonedDm.getPartialFieldspace().fields;\n    const selectorHelperFn = index => selectFn(\n        prepareSelectionData(fields, index),\n        index,\n        cloneProvider,\n        cachedStore\n    );\n\n    return iterator(rowDiffset, selectorHelperFn, mode);\n};\n\nexport const cloneWithAllFields = (model) => {\n    const clonedDm = model.clone(false);\n    const partialFieldspace = model.getPartialFieldspace();\n    clonedDm._colIdentifier = partialFieldspace.fields.map(f => f.name()).join(',');\n\n    // flush out cached namespace values on addition of new fields\n    partialFieldspace._cachedFieldsObj = null;\n    partialFieldspace._cachedDimension = null;\n    partialFieldspace._cachedMeasure = null;\n    clonedDm.__calculateFieldspace().calculateFieldsConfig();\n\n    return clonedDm;\n};\n\nconst getKey = (arr, data, fn) => {\n    let key = fn(arr, data, 0);\n\n    for (let i = 1, len = arr.length; i < len; i++) {\n        key = `${key},${fn(arr, data, i)}`;\n    }\n    return key;\n};\n\nexport const filterPropagationModel = (model, propModels, config = {}) => {\n    let fns = [];\n    const operation = config.operation || LOGICAL_OPERATORS.AND;\n    const filterByMeasure = config.filterByMeasure || false;\n    const clonedModel = cloneWithAllFields(model);\n    const modelFieldsConfig = clonedModel.getFieldsConfig();\n\n    if (!propModels.length) {\n        fns = [() => false];\n    } else {\n        fns = propModels.map(propModel => ((dataModel) => {\n            let keyFn;\n            const dataObj = dataModel.getData();\n            const fieldsConfig = dataModel.getFieldsConfig();\n            const dimensions = Object.keys(dataModel.getFieldspace().getDimension())\n                .filter(d => d in modelFieldsConfig);\n            const dLen = dimensions.length;\n            const indices = dimensions.map(d =>\n                fieldsConfig[d].index);\n            const measures = Object.keys(dataModel.getFieldspace().getMeasure())\n                .filter(d => d in modelFieldsConfig);\n            const fieldsSpace = dataModel.getFieldspace().fieldsObj();\n            const data = dataObj.data;\n            const domain = measures.reduce((acc, v) => {\n                acc[v] = fieldsSpace[v].domain();\n                return acc;\n            }, {});\n            const valuesMap = {};\n\n            keyFn = (arr, row, idx) => row[arr[idx]];\n            if (dLen) {\n                data.forEach((row) => {\n                    const key = getKey(indices, row, keyFn);\n                    valuesMap[key] = 1;\n                });\n            }\n\n            keyFn = (arr, fields, idx) => fields[arr[idx]].value;\n            return data.length ? (fields) => {\n                const present = dLen ? valuesMap[getKey(dimensions, fields, keyFn)] : true;\n\n                if (filterByMeasure) {\n                    return measures.every(field => fields[field].value >= domain[field][0] &&\n                        fields[field].value <= domain[field][1]) && present;\n                }\n                return present;\n            } : () => false;\n        })(propModel));\n    }\n\n    let filteredModel;\n    if (operation === LOGICAL_OPERATORS.AND) {\n        filteredModel = clonedModel.select(fields => fns.every(fn => fn(fields)), {\n            saveChild: false\n        });\n    } else {\n        filteredModel = clonedModel.select(fields => fns.some(fn => fn(fields)), {\n            saveChild: false\n        });\n    }\n\n    return filteredModel;\n};\n\n\nexport const splitWithSelect = (sourceDm, dimensionArr, reducerFn = val => val, config) => {\n    const {\n        saveChild,\n    } = config;\n    const fieldStoreObj = sourceDm.getFieldspace().fieldsObj();\n\n    const {\n        splitRowDiffset,\n        dimensionMap\n    } = selectHelper(\n        sourceDm.clone(saveChild),\n        reducerFn,\n        config,\n        sourceDm,\n        (...params) => rowSplitDiffsetIterator(...params, dimensionArr, fieldStoreObj)\n        );\n\n    const clonedDMs = [];\n    Object.keys(splitRowDiffset).sort().forEach((e) => {\n        if (splitRowDiffset[e]) {\n            const cloned = sourceDm.clone(saveChild);\n            const derivation = dimensionMap[e];\n            cloned._rowDiffset = splitRowDiffset[e].join(',');\n            cloned.__calculateFieldspace().calculateFieldsConfig();\n\n            const derivationFormula = fields => dimensionArr.every(_ => fields[_].value === derivation.keys[_]);\n            // Store reference to child model and selector function\n            if (saveChild) {\n                persistDerivations(sourceDm, cloned, DM_DERIVATIVES.SELECT, config, derivationFormula);\n            }\n            cloned._derivation[cloned._derivation.length - 1].meta = dimensionMap[e];\n\n            clonedDMs.push(cloned);\n        }\n    });\n\n\n    return clonedDMs;\n};\nexport const addDiffsetToClonedDm = (clonedDm, rowDiffset, sourceDm, selectConfig, selectFn) => {\n    clonedDm._rowDiffset = rowDiffset;\n    clonedDm.__calculateFieldspace().calculateFieldsConfig();\n    persistDerivations(\n        sourceDm,\n        clonedDm,\n        DM_DERIVATIVES.SELECT,\n         { config: selectConfig },\n          selectFn\n    );\n};\n\n\nexport const cloneWithSelect = (sourceDm, selectFn, selectConfig, cloneConfig) => {\n    let extraCloneDm = {};\n\n    let { mode } = selectConfig;\n\n    const cloned = sourceDm.clone(cloneConfig.saveChild);\n    const setOfRowDiffsets = selectHelper(\n        cloned,\n        selectFn,\n        selectConfig,\n        sourceDm,\n        selectRowDiffsetIterator\n    );\n    const diffIndex = selectModeMap[mode].diffIndex;\n\n    addDiffsetToClonedDm(cloned, setOfRowDiffsets[diffIndex[0]], sourceDm, selectConfig, selectFn);\n\n    if (diffIndex.length > 1) {\n        extraCloneDm = sourceDm.clone(cloneConfig.saveChild);\n        addDiffsetToClonedDm(extraCloneDm, setOfRowDiffsets[diffIndex[1]], sourceDm, selectConfig, selectFn);\n        return [cloned, extraCloneDm];\n    }\n\n    return cloned;\n};\n\nexport const cloneWithProject = (sourceDm, projField, config, allFields) => {\n    const cloned = sourceDm.clone(config.saveChild);\n    let projectionSet = projField;\n    if (config.mode === FilteringMode.INVERSE) {\n        projectionSet = allFields.filter(fieldName => projField.indexOf(fieldName) === -1);\n    }\n    // cloned._colIdentifier = sourceDm._colIdentifier.split(',')\n    //                         .filter(coll => projectionSet.indexOf(coll) !== -1).join();\n    cloned._colIdentifier = projectionSet.join(',');\n    cloned.__calculateFieldspace().calculateFieldsConfig();\n\n    persistDerivations(\n        sourceDm,\n        cloned,\n        DM_DERIVATIVES.PROJECT,\n        { projField, config, actualProjField: projectionSet },\n        null\n    );\n\n    return cloned;\n};\n\n\nexport const splitWithProject = (sourceDm, projFieldSet, config, allFields) =>\n    projFieldSet.map(projFields =>\n        cloneWithProject(sourceDm, projFields, config, allFields));\n\nexport const sanitizeUnitSchema = (unitSchema) => {\n    // Do deep clone of the unit schema as the user might change it later.\n    unitSchema = extend2({}, unitSchema);\n    if (!unitSchema.type) {\n        unitSchema.type = FieldType.DIMENSION;\n    }\n\n    if (!unitSchema.subtype) {\n        switch (unitSchema.type) {\n        case FieldType.MEASURE:\n            unitSchema.subtype = MeasureSubtype.CONTINUOUS;\n            break;\n        default:\n        case FieldType.DIMENSION:\n            unitSchema.subtype = DimensionSubtype.CATEGORICAL;\n            break;\n        }\n    }\n\n    return unitSchema;\n};\n\nexport const validateUnitSchema = (unitSchema) => {\n    const supportedMeasureSubTypes = [MeasureSubtype.CONTINUOUS];\n    const supportedDimSubTypes = [\n        DimensionSubtype.CATEGORICAL,\n        DimensionSubtype.BINNED,\n        DimensionSubtype.TEMPORAL,\n        DimensionSubtype.GEO\n    ];\n    const { type, subtype, name } = unitSchema;\n\n    switch (type) {\n    case FieldType.DIMENSION:\n        if (supportedDimSubTypes.indexOf(subtype) === -1) {\n            throw new Error(`DataModel doesn't support dimension field subtype ${subtype} used for ${name} field`);\n        }\n        break;\n    case FieldType.MEASURE:\n        if (supportedMeasureSubTypes.indexOf(subtype) === -1) {\n            throw new Error(`DataModel doesn't support measure field subtype ${subtype} used for ${name} field`);\n        }\n        break;\n    default:\n        throw new Error(`DataModel doesn't support field type ${type} used for ${name} field`);\n    }\n};\n\nexport const sanitizeAndValidateSchema = schema => schema.map((unitSchema) => {\n    unitSchema = sanitizeUnitSchema(unitSchema);\n    validateUnitSchema(unitSchema);\n    return unitSchema;\n});\n\nexport const resolveFieldName = (schema, dataHeader) => {\n    schema.forEach((unitSchema) => {\n        const fieldNameAs = unitSchema.as;\n        if (!fieldNameAs) { return; }\n\n        const idx = dataHeader.indexOf(unitSchema.name);\n        dataHeader[idx] = fieldNameAs;\n        unitSchema.name = fieldNameAs;\n        delete unitSchema.as;\n    });\n};\n\nexport const updateData = (relation, data, schema, options) => {\n    schema = sanitizeAndValidateSchema(schema);\n    options = Object.assign(Object.assign({}, defaultConfig), options);\n    const converterFn = converter[options.dataFormat];\n\n    if (!(converterFn && typeof converterFn === 'function')) {\n        throw new Error(`No converter function found for ${options.dataFormat} format`);\n    }\n\n    const [header, formattedData] = converterFn(data, options);\n    resolveFieldName(schema, header);\n    const fieldArr = createFields(formattedData, schema, header);\n\n    // This will create a new fieldStore with the fields\n    const nameSpace = fieldStore.createNamespace(fieldArr, options.name);\n    relation._partialFieldspace = nameSpace;\n\n    // If data is provided create the default colIdentifier and rowDiffset\n    relation._rowDiffset = formattedData.length && formattedData[0].length ? `0-${formattedData[0].length - 1}` : '';\n\n    // This stores the value objects which is passed to the filter method when selection operation is done.\n    const valueObjects = [];\n    rowDiffsetIterator(relation._rowDiffset, (i) => {\n        valueObjects[i] = prepareSelectionData(nameSpace.fields, i);\n    });\n    nameSpace._cachedValueObjects = valueObjects;\n\n    relation._colIdentifier = (schema.map(_ => _.name)).join();\n    relation._dataFormat = options.dataFormat === DataFormat.AUTO ? detectDataFormat(data) : options.dataFormat;\n    return relation;\n};\n\nexport const fieldInSchema = (schema, field) => {\n    let i = 0;\n\n    for (; i < schema.length; ++i) {\n        if (field === schema[i].name) {\n            return {\n                type: schema[i].subtype || schema[i].type,\n                index: i\n            };\n        }\n    }\n    return null;\n};\n\n\nexport const getDerivationArguments = (derivation) => {\n    let params = [];\n    let operation;\n    operation = derivation.op;\n    switch (operation) {\n    case DM_DERIVATIVES.SELECT:\n        params = [derivation.criteria];\n        break;\n    case DM_DERIVATIVES.PROJECT:\n        params = [derivation.meta.actualProjField];\n        break;\n    case DM_DERIVATIVES.GROUPBY:\n        operation = 'groupBy';\n        params = [derivation.meta.groupByString.split(','), derivation.criteria];\n        break;\n    default:\n        operation = null;\n    }\n\n    return {\n        operation,\n        params\n    };\n};\n\nconst applyExistingOperationOnModel = (propModel, dataModel) => {\n    const derivations = dataModel.getDerivations();\n    let selectionModel = propModel;\n\n    derivations.forEach((derivation) => {\n        if (!derivation) {\n            return;\n        }\n\n        const { operation, params } = getDerivationArguments(derivation);\n        if (operation) {\n            selectionModel = selectionModel[operation](...params, {\n                saveChild: false\n            });\n        }\n    });\n\n    return selectionModel;\n};\n\nconst getFilteredModel = (propModel, path) => {\n    for (let i = 0, len = path.length; i < len; i++) {\n        const model = path[i];\n        propModel = applyExistingOperationOnModel(propModel, model);\n    }\n    return propModel;\n};\n\nconst propagateIdentifiers = (dataModel, propModel, config = {}, propModelInf = {}) => {\n    const nonTraversingModel = propModelInf.nonTraversingModel;\n    const excludeModels = propModelInf.excludeModels || [];\n\n    if (dataModel === nonTraversingModel) {\n        return;\n    }\n\n    const propagate = excludeModels.length ? excludeModels.indexOf(dataModel) === -1 : true;\n\n    propagate && dataModel.handlePropagation(propModel, config);\n\n    const children = dataModel._children;\n    children.forEach((child) => {\n        const selectionModel = applyExistingOperationOnModel(propModel, child);\n        propagateIdentifiers(child, selectionModel, config, propModelInf);\n    });\n};\n\nexport const getRootGroupByModel = (model) => {\n    while (model._parent && model._derivation.find(d => d.op !== DM_DERIVATIVES.GROUPBY)) {\n        model = model._parent;\n    }\n    return model;\n};\n\nexport const getRootDataModel = (model) => {\n    while (model._parent) {\n        model = model._parent;\n    }\n    return model;\n};\n\nexport const getPathToRootModel = (model, path = []) => {\n    while (model._parent) {\n        path.push(model);\n        model = model._parent;\n    }\n    return path;\n};\n\nexport const propagateToAllDataModels = (identifiers, rootModels, propagationInf, config) => {\n    let criteria;\n    let propModel;\n    const { propagationNameSpace, propagateToSource } = propagationInf;\n    const propagationSourceId = propagationInf.sourceId;\n    const propagateInterpolatedValues = config.propagateInterpolatedValues;\n    const filterFn = (entry) => {\n        const filter = config.filterFn || (() => true);\n        return filter(entry, config);\n    };\n\n    let criterias = [];\n\n    if (identifiers === null && config.persistent !== true) {\n        criterias = [{\n            criteria: []\n        }];\n        criteria = [];\n    } else {\n        let actionCriterias = Object.values(propagationNameSpace.mutableActions);\n        if (propagateToSource !== false) {\n            actionCriterias = actionCriterias.filter(d => d.config.sourceId !== propagationSourceId);\n        }\n\n        const filteredCriteria = actionCriterias.filter(filterFn).map(action => action.config.criteria);\n\n        const excludeModels = [];\n\n        if (propagateToSource !== false) {\n            const sourceActionCriterias = Object.values(propagationNameSpace.mutableActions);\n\n            sourceActionCriterias.forEach((actionInf) => {\n                const actionConf = actionInf.config;\n                if (actionConf.applyOnSource === false && actionConf.action === config.action &&\n                        actionConf.sourceId !== propagationSourceId) {\n                    excludeModels.push(actionInf.model);\n                    criteria = sourceActionCriterias.filter(d => d !== actionInf).map(d => d.config.criteria);\n                    criteria.length && criterias.push({\n                        criteria,\n                        models: actionInf.model,\n                        path: getPathToRootModel(actionInf.model)\n                    });\n                }\n            });\n        }\n\n\n        criteria = [].concat(...[...filteredCriteria, identifiers]).filter(d => d !== null);\n        criterias.push({\n            criteria,\n            excludeModels: [...excludeModels, ...config.excludeModels || []]\n        });\n    }\n\n    const rootModel = rootModels.model;\n\n    const propConfig = Object.assign({\n        sourceIdentifiers: identifiers,\n        propagationSourceId\n    }, config);\n\n    const rootGroupByModel = rootModels.groupByModel;\n    if (propagateInterpolatedValues && rootGroupByModel) {\n        propModel = filterPropagationModel(rootGroupByModel, criteria, {\n            filterByMeasure: propagateInterpolatedValues\n        });\n        propagateIdentifiers(rootGroupByModel, propModel, propConfig);\n    }\n\n    criterias.forEach((inf) => {\n        const propagationModel = filterPropagationModel(rootModel, inf.criteria);\n        const path = inf.path;\n\n        if (path) {\n            const filteredModel = getFilteredModel(propagationModel, path.reverse());\n            inf.models.handlePropagation(filteredModel, propConfig);\n        } else {\n            propagateIdentifiers(rootModel, propagationModel, propConfig, {\n                excludeModels: inf.excludeModels,\n                nonTraversingModel: propagateInterpolatedValues && rootGroupByModel\n            });\n        }\n    });\n};\n\nexport const propagateImmutableActions = (propagationNameSpace, rootModels, propagationInf) => {\n    const immutableActions = propagationNameSpace.immutableActions;\n\n    for (const action in immutableActions) {\n        const actionInf = immutableActions[action];\n        const actionConf = actionInf.config;\n        const propagationSourceId = propagationInf.config.sourceId;\n        const filterImmutableAction = propagationInf.propConfig.filterImmutableAction ?\n            propagationInf.propConfig.filterImmutableAction(actionConf, propagationInf.config) : true;\n        if (actionConf.sourceId !== propagationSourceId && filterImmutableAction) {\n            const criteriaModel = actionConf.criteria;\n            propagateToAllDataModels(criteriaModel, rootModels, {\n                propagationNameSpace,\n                propagateToSource: false,\n                sourceId: propagationSourceId\n            }, actionConf);\n        }\n    }\n};\n\nexport const addToPropNamespace = (propagationNameSpace, config = {}, model) => {\n    let sourceNamespace;\n    const isMutableAction = config.isMutableAction;\n    const criteria = config.criteria;\n    const key = `${config.action}-${config.sourceId}`;\n\n    if (isMutableAction) {\n        sourceNamespace = propagationNameSpace.mutableActions;\n    } else {\n        sourceNamespace = propagationNameSpace.immutableActions;\n    }\n\n    if (criteria === null) {\n        delete sourceNamespace[key];\n    } else {\n        sourceNamespace[key] = {\n            model,\n            config\n        };\n    }\n\n    return this;\n};\n\n\nexport const getNormalizedProFields = (projField, allFields, fieldConfig) => {\n    const normalizedProjField = projField.reduce((acc, field) => {\n        if (field.constructor.name === 'RegExp') {\n            acc.push(...allFields.filter(fieldName => fieldName.search(field) !== -1));\n        } else if (field in fieldConfig) {\n            acc.push(field);\n        }\n        return acc;\n    }, []);\n    return Array.from(new Set(normalizedProjField)).map(field => field.trim());\n};\n","import { FilteringMode } from './enums';\nimport { getUniqueId } from './utils';\nimport {\n    updateFields,\n    cloneWithSelect,\n    cloneWithProject,\n    updateData,\n    getNormalizedProFields\n} from './helper';\nimport { crossProduct, difference, naturalJoinFilter, union } from './operator';\n\n/**\n * Relation provides the definitions of basic operators of relational algebra like *selection*, *projection*, *union*,\n * *difference* etc.\n *\n * It is extended by {@link DataModel} to inherit the functionalities of relational algebra concept.\n *\n * @class\n * @public\n * @module Relation\n * @namespace DataModel\n */\nclass Relation {\n\n    /**\n     * Creates a new Relation instance by providing underlying data and schema.\n     *\n     * @private\n     *\n     * @param {Object | string | Relation} data - The input tabular data in dsv or json format or\n     * an existing Relation instance object.\n     * @param {Array} schema - An array of data schema.\n     * @param {Object} [options] - The optional options.\n     */\n    constructor (...params) {\n        let source;\n\n        this._parent = null;\n        this._derivation = [];\n        this._ancestorDerivation = [];\n        this._children = [];\n\n        if (params.length === 1 && ((source = params[0]) instanceof Relation)) {\n            // parent datamodel was passed as part of source\n            this._colIdentifier = source._colIdentifier;\n            this._rowDiffset = source._rowDiffset;\n            this._dataFormat = source._dataFormat;\n            this._parent = source;\n            this._partialFieldspace = this._parent._partialFieldspace;\n            this._fieldStoreName = getUniqueId();\n            this.__calculateFieldspace().calculateFieldsConfig();\n        } else {\n            updateData(this, ...params);\n            this._fieldStoreName = this._partialFieldspace.name;\n            this.__calculateFieldspace().calculateFieldsConfig();\n            this._propagationNameSpace = {\n                mutableActions: {},\n                immutableActions: {}\n            };\n        }\n    }\n\n    /**\n     * Retrieves the {@link Schema | schema} details for every {@link Field | field} as an array.\n     *\n     * @public\n     *\n     * @return {Array.<Schema>} Array of fields schema.\n     *      ```\n     *      [\n     *          { name: 'Name', type: 'dimension' },\n     *          { name: 'Miles_per_Gallon', type: 'measure', numberFormat: (val) => `${val} miles / gallon` },\n     *          { name: 'Cylinder', type: 'dimension' },\n     *          { name: 'Displacement', type: 'measure', defAggFn: 'max' },\n     *          { name: 'HorsePower', type: 'measure', defAggFn: 'max' },\n     *          { name: 'Weight_in_lbs', type: 'measure', defAggFn: 'avg',  },\n     *          { name: 'Acceleration', type: 'measure', defAggFn: 'avg' },\n     *          { name: 'Year', type: 'dimension', subtype: 'datetime', format: '%Y' },\n     *          { name: 'Origin' }\n     *      ]\n     *      ```\n     */\n    getSchema () {\n        return this.getFieldspace().fields.map(d => d.schema());\n    }\n\n    /**\n     * Returns the name of the {@link DataModel} instance. If no name was specified during {@link DataModel}\n     * initialization, then it returns a auto-generated name.\n     *\n     * @public\n     *\n     * @return {string} Name of the DataModel instance.\n     */\n    getName() {\n        return this._fieldStoreName;\n    }\n\n    getFieldspace () {\n        return this._fieldspace;\n    }\n\n    __calculateFieldspace () {\n        this._fieldspace = updateFields([this._rowDiffset, this._colIdentifier],\n             this.getPartialFieldspace(), this._fieldStoreName);\n        return this;\n    }\n\n    getPartialFieldspace () {\n        return this._partialFieldspace;\n    }\n\n    /**\n     * Performs {@link link_of_cross_product | cross-product} between two {@link DataModel} instances and returns a\n     * new {@link DataModel} instance containing the results. This operation is also called theta join.\n     *\n     * Cross product takes two set and create one set where each value of one set is paired with each value of another\n     * set.\n     *\n     * This method takes an optional predicate which filters the generated result rows. If the predicate returns true\n     * the combined row is included in the resulatant table.\n     *\n     * @example\n     *  let originDM = dm.project(['Origin','Origin_Formal_Name']);\n     *  let carsDM = dm.project(['Name','Miles_per_Gallon','Origin'])\n     *\n     *  console.log(carsDM.join(originDM)));\n     *\n     *  console.log(carsDM.join(originDM,\n     *      obj => obj.[originDM.getName()].Origin === obj.[carsDM.getName()].Origin));\n     *\n     * @text\n     * This is chained version of `join` operator. `join` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} joinWith - The DataModel to be joined with the current instance DataModel.\n     * @param {SelectionPredicate} filterFn - The predicate function that will filter the result of the crossProduct.\n     *\n     * @return {DataModel} New DataModel instance created after joining.\n     */\n    join (joinWith, filterFn) {\n        return crossProduct(this, joinWith, filterFn);\n    }\n\n    /**\n     * {@link natural_join | Natural join} is a special kind of cross-product join where filtering of rows are performed\n     * internally by resolving common fields are from both table and the rows with common value are included.\n     *\n     * @example\n     *  let originDM = dm.project(['Origin','Origin_Formal_Name']);\n     *  let carsDM = dm.project(['Name','Miles_per_Gallon','Origin'])\n     *\n     *  console.log(carsDM.naturalJoin(originDM));\n     *\n     * @text\n     * This is chained version of `naturalJoin` operator. `naturalJoin` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} joinWith - The DataModel with which the current instance of DataModel on which the method is\n     *      called will be joined.\n     * @return {DataModel} New DataModel instance created after joining.\n     */\n    naturalJoin (joinWith) {\n        return crossProduct(this, joinWith, naturalJoinFilter(this, joinWith), true);\n    }\n\n    /**\n     * {@link link_to_union | Union} operation can be termed as vertical stacking of all rows from both the DataModel\n     * instances, provided that both of the {@link DataModel} instances should have same column names.\n     *\n     * @example\n     * console.log(EuropeanMakerDM.union(USAMakerDM));\n     *\n     * @text\n     * This is chained version of `naturalJoin` operator. `naturalJoin` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} unionWith - DataModel instance for which union has to be applied with the instance on which\n     *      the method is called\n     *\n     * @return {DataModel} New DataModel instance with the result of the operation\n     */\n    union (unionWith) {\n        return union(this, unionWith);\n    }\n\n    /**\n     * {@link link_to_difference | Difference } operation only include rows which are present in the datamodel on which\n     * it was called but not on the one passed as argument.\n     *\n     * @example\n     * console.log(highPowerDM.difference(highExpensiveDM));\n     *\n     * @text\n     * This is chained version of `naturalJoin` operator. `naturalJoin` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} differenceWith - DataModel instance for which difference has to be applied with the instance\n     *      on which the method is called\n     * @return {DataModel} New DataModel instance with the result of the operation\n     */\n    difference (differenceWith) {\n        return difference(this, differenceWith);\n    }\n\n    /**\n     * {@link link_to_selection | Selection} is a row filtering operation. It expects a predicate and an optional mode\n     * which control which all rows should be included in the resultant DataModel instance.\n     *\n     * {@link SelectionPredicate} is a function which returns a boolean value. For selection operation the selection\n     * function is called for each row of DataModel instance with the current row passed as argument.\n     *\n     * After executing {@link SelectionPredicate} the rows are labeled as either an entry of selection set or an entry\n     * of rejection set.\n     *\n     * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n     * resultant datamodel.\n     *\n     * @warning\n     * Selection and rejection set is only a logical idea for concept explanation purpose.\n     *\n     * @example\n     *  // with selection mode NORMAL:\n     *  const normDt = dt.select(fields => fields.Origin.value === \"USA\")\n     *  console.log(normDt));\n     *\n     * // with selection mode INVERSE:\n     * const inverDt = dt.select(fields => fields.Origin.value === \"USA\", { mode: DataModel.FilteringMode.INVERSE })\n     * console.log(inverDt);\n     *\n     * // with selection mode ALL:\n     * const dtArr = dt.select(fields => fields.Origin.value === \"USA\", { mode: DataModel.FilteringMode.ALL })\n     * // print the selected parts\n     * console.log(dtArr[0]);\n     * // print the inverted parts\n     * console.log(dtArr[1]);\n     *\n     * @text\n     * This is chained version of `select` operator. `select` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {Function} selectFn - The predicate function which is called for each row with the current row.\n     * ```\n     *  function (row, i, cloneProvider, store)  { ... }\n     * ```\n     * @param {Object} config - The configuration object to control the inclusion exclusion of a row in resultant\n     * DataModel instance.\n     * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - The mode of the selection.\n     * @return {DataModel} Returns the new DataModel instance(s) after operation.\n     */\n    select (selectFn, config) {\n        const defConfig = {\n            mode: FilteringMode.NORMAL,\n            saveChild: true\n        };\n        config = Object.assign({}, defConfig, config);\n        config.mode = config.mode || defConfig.mode;\n\n        const cloneConfig = { saveChild: config.saveChild };\n        return cloneWithSelect(\n            this,\n            selectFn,\n            config,\n            cloneConfig\n        );\n    }\n\n    /**\n     * Retrieves a boolean value if the current {@link DataModel} instance has data.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'CarName', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     * const data = [];\n     *\n     * const dt = new DataModel(data, schema);\n     * console.log(dt.isEmpty());\n     *\n     * @public\n     *\n     * @return {Boolean} True if the datamodel has no data, otherwise false.\n     */\n    isEmpty () {\n        return !this._rowDiffset.length || !this._colIdentifier.length;\n    }\n\n    /**\n     * Creates a clone from the current DataModel instance with child parent relationship.\n     *\n     * @private\n     * @param {boolean} [saveChild=true] - Whether the cloned instance would be recorded in the parent instance.\n     * @return {DataModel} - Returns the newly cloned DataModel instance.\n     */\n    clone (saveChild = true) {\n        const clonedDm = new this.constructor(this);\n        if (saveChild) {\n            clonedDm.setParent(this);\n        } else {\n            clonedDm.setParent(null);\n        }\n        return clonedDm;\n    }\n\n    /**\n     * {@link Projection} is filter column (field) operation. It expects list of fields' name and either include those\n     * or exclude those based on {@link FilteringMode} on the resultant variable.\n     *\n     * Projection expects array of fields name based on which it creates the selection and rejection set. All the field\n     * whose name is present in array goes in selection set and rest of the fields goes in rejection set.\n     *\n     * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n     * resulatant datamodel.\n     *\n     * @warning\n     * Selection and rejection set is only a logical idea for concept explanation purpose.\n     *\n     * @example\n     *  const dm = new DataModel(data, schema);\n     *\n     *  // with projection mode NORMAL:\n     *  const normDt = dt.project([\"Name\", \"HorsePower\"]);\n     *  console.log(normDt.getData());\n     *\n     *  // with projection mode INVERSE:\n     *  const inverDt = dt.project([\"Name\", \"HorsePower\"], { mode: DataModel.FilteringMode.INVERSE })\n     *  console.log(inverDt.getData());\n     *\n     *  // with selection mode ALL:\n     *  const dtArr = dt.project([\"Name\", \"HorsePower\"], { mode: DataModel.FilteringMode.ALL })\n     *  // print the normal parts\n     *  console.log(dtArr[0].getData());\n     *  // print the inverted parts\n     *  console.log(dtArr[1].getData());\n     *\n     * @text\n     * This is chained version of `select` operator. `select` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {Array.<string | Regexp>} projField - An array of column names in string or regular expression.\n     * @param {Object} [config] - An optional config to control the creation of new DataModel\n     * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - Mode of the projection\n     *\n     * @return {DataModel} Returns the new DataModel instance after operation.\n     */\n    project (projField, config) {\n        const defConfig = {\n            mode: FilteringMode.NORMAL,\n            saveChild: true\n        };\n        config = Object.assign({}, defConfig, config);\n        const fieldConfig = this.getFieldsConfig();\n        const allFields = Object.keys(fieldConfig);\n        const { mode } = config;\n        const normalizedProjField = getNormalizedProFields(projField, allFields, fieldConfig);\n\n        let dataModel;\n\n        if (mode === FilteringMode.ALL) {\n            let projectionClone = cloneWithProject(this, normalizedProjField, {\n                mode: FilteringMode.NORMAL,\n                saveChild: config.saveChild\n            }, allFields);\n            let rejectionClone = cloneWithProject(this, normalizedProjField, {\n                mode: FilteringMode.INVERSE,\n                saveChild: config.saveChild\n            }, allFields);\n            dataModel = [projectionClone, rejectionClone];\n        } else {\n            let projectionClone = cloneWithProject(this, normalizedProjField, config, allFields);\n            dataModel = projectionClone;\n        }\n\n        return dataModel;\n    }\n\n    getFieldsConfig () {\n        return this._fieldConfig;\n    }\n\n    calculateFieldsConfig () {\n        this._fieldConfig = this._fieldspace.fields.reduce((acc, fieldObj, i) => {\n            acc[fieldObj.name()] = {\n                index: i,\n                def: fieldObj.schema(),\n            };\n            return acc;\n        }, {});\n        return this;\n    }\n\n\n    /**\n     * Frees up the resources associated with the current DataModel instance and breaks all the links instance has in\n     * the DAG.\n     *\n     * @public\n     */\n    dispose () {\n        this._parent && this._parent.removeChild(this);\n        this._parent = null;\n        this._children.forEach((child) => {\n            child._parent = null;\n        });\n        this._children = [];\n    }\n\n    /**\n     * Removes the specified child {@link DataModel} from the child list of the current {@link DataModel} instance.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'Name', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *    { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *    { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *    { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *    { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     *\n     * const dt2 = dt.select(fields => fields.Origin.value === \"USA\")\n     * dt.removeChild(dt2);\n     *\n     * @private\n     *\n     * @param {DataModel} child - Delegates the parent to remove this child.\n     */\n    removeChild (child) {\n        let idx = this._children.findIndex(sibling => sibling === child);\n        idx !== -1 ? this._children.splice(idx, 1) : true;\n    }\n\n    /**\n     * Sets the specified {@link DataModel} as a parent for the current {@link DataModel} instance.\n     *\n     * @param {DataModel} parent - The datamodel instance which will act as parent.\n     */\n    setParent (parent) {\n        this._parent && this._parent.removeChild(this);\n        this._parent = parent;\n        parent && parent._children.push(this);\n    }\n\n    /**\n     * Returns the parent {@link DataModel} instance.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'Name', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *    { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *    { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *    { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *    { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     *\n     * const dt2 = dt.select(fields => fields.Origin.value === \"USA\");\n     * const parentDm = dt2.getParent();\n     *\n     * @return {DataModel} Returns the parent DataModel instance.\n     */\n    getParent () {\n        return this._parent;\n    }\n\n    /**\n     * Returns the immediate child {@link DataModel} instances.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'Name', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *    { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *    { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *    { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *    { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     *\n     * const childDm1 = dt.select(fields => fields.Origin.value === \"USA\");\n     * const childDm2 = dt.select(fields => fields.Origin.value === \"Japan\");\n     * const childDm3 = dt.groupBy([\"Origin\"]);\n     *\n     * @return {DataModel[]} Returns the immediate child DataModel instances.\n     */\n    getChildren () {\n        return this._children;\n    }\n\n    /**\n     * Returns the in-between operation meta data while creating the current {@link DataModel} instance.\n     *\n     * @example\n     * const schema = [\n     *   { name: 'Name', type: 'dimension' },\n     *   { name: 'HorsePower', type: 'measure' },\n     *   { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *   { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *   { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *   { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *   { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     * const dt2 = dt.select(fields => fields.Origin.value === \"USA\");\n     * const dt3 = dt2.groupBy([\"Origin\"]);\n     * const derivations = dt3.getDerivations();\n     *\n     * @return {Any[]} Returns the derivation meta data.\n     */\n    getDerivations () {\n        return this._derivation;\n    }\n\n    /**\n     * Returns the in-between operation meta data happened from root {@link DataModel} to current instance.\n     *\n     * @example\n     * const schema = [\n     *   { name: 'Name', type: 'dimension' },\n     *   { name: 'HorsePower', type: 'measure' },\n     *   { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *   { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *   { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *   { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *   { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(data, schema);\n     * const dt2 = dt.select(fields => fields.Origin.value === \"USA\");\n     * const dt3 = dt2.groupBy([\"Origin\"]);\n     * const ancDerivations = dt3.getAncestorDerivations();\n     *\n     * @return {Any[]} Returns the previous derivation meta data.\n     */\n    getAncestorDerivations () {\n        return this._ancestorDerivation;\n    }\n}\n\nexport default Relation;\n","/* eslint-disable default-case */\n\nimport { FieldType, DimensionSubtype, DataFormat, FilteringMode } from './enums';\nimport {\n    persistDerivations,\n    getRootGroupByModel,\n    propagateToAllDataModels,\n    getRootDataModel,\n    propagateImmutableActions,\n    addToPropNamespace,\n    sanitizeUnitSchema,\n    splitWithSelect,\n    splitWithProject,\n    getNormalizedProFields\n} from './helper';\nimport { DM_DERIVATIVES, PROPAGATION } from './constants';\nimport {\n    dataBuilder,\n    rowDiffsetIterator,\n    groupBy\n} from './operator';\nimport { createBinnedFieldData } from './operator/bucket-creator';\nimport Relation from './relation';\nimport reducerStore from './utils/reducer-store';\nimport { createFields } from './field-creator';\nimport InvalidAwareTypes from './invalid-aware-types';\nimport Value from './value';\n\n/**\n * DataModel is an in-browser representation of tabular data. It supports\n * {@link https://en.wikipedia.org/wiki/Relational_algebra | relational algebra} operators as well as generic data\n * processing opearators.\n * DataModel extends {@link Relation} class which defines all the relational algebra opreators. DataModel gives\n * definition of generic data processing operators which are not relational algebra complient.\n *\n * @public\n * @class\n * @extends Relation\n * @memberof Datamodel\n */\nclass DataModel extends Relation {\n    /**\n     * Creates a new DataModel instance by providing data and schema. Data could be in the form of\n     * - Flat JSON\n     * - DSV String\n     * - 2D Array\n     *\n     * By default DataModel finds suitable adapter to serialize the data. DataModel also expects a\n     * {@link Schema | schema} for identifying the variables present in data.\n     *\n     * @constructor\n     * @example\n     * const data = loadData('cars.csv');\n     * const schema = [\n     *      { name: 'Name', type: 'dimension' },\n     *      { name: 'Miles_per_Gallon', type: 'measure', unit : 'cm', scale: '1000', numberformat: val => `${val}G`},\n     *      { name: 'Cylinders', type: 'dimension' },\n     *      { name: 'Displacement', type: 'measure' },\n     *      { name: 'Horsepower', type: 'measure' },\n     *      { name: 'Weight_in_lbs', type: 'measure' },\n     *      { name: 'Acceleration', type: 'measure' },\n     *      { name: 'Year', type: 'dimension', subtype: 'datetime', format: '%Y' },\n     *      { name: 'Origin', type: 'dimension' }\n     * ];\n     * const dm = new DataModel(data, schema, { name: 'Cars' });\n     * table(dm);\n     *\n     * @public\n     *\n     * @param {Array.<Object> | string | Array.<Array>} data Input data in any of the mentioned formats\n     * @param {Array.<Schema>} schema Defination of the variables. Order of the variables in data and order of the\n     *      variables in schema has to be same.\n     * @param {object} [options] Optional arguments to specify more settings regarding the creation part\n     * @param {string} [options.name] Name of the datamodel instance. If no name is given an auto generated name is\n     *      assigned to the instance.\n     * @param {string} [options.fieldSeparator=','] specify field separator type if the data is of type dsv string.\n     */\n    constructor (...args) {\n        super(...args);\n\n        this._onPropagation = [];\n    }\n\n    /**\n     * Reducers are simple functions which reduces an array of numbers to a representative number of the set.\n     * Like an array of numbers `[10, 20, 5, 15]` can be reduced to `12.5` if average / mean reducer function is\n     * applied. All the measure fields in datamodel (variables in data) needs a reducer to handle aggregation.\n     *\n     * @public\n     *\n     * @return {ReducerStore} Singleton instance of {@link ReducerStore}.\n     */\n    static get Reducers () {\n        return reducerStore;\n    }\n\n    /**\n     * Configure null, undefined, invalid values in the source data\n     *\n     * @public\n     *\n     * @param {Object} [config] - Configuration to control how null, undefined and non-parsable values are\n     * represented in DataModel.\n     * @param {string} [config.undefined] - Define how an undefined value will be represented.\n     * @param {string} [config.null] - Define how a null value will be represented.\n     * @param {string} [config.invalid] - Define how a non-parsable value will be represented.\n     */\n    static configureInvalidAwareTypes (config) {\n        return InvalidAwareTypes.invalidAwareVals(config);\n    }\n\n    /**\n     * Retrieve the data attached to an instance in JSON format.\n     *\n     * @example\n     * // DataModel instance is already prepared and assigned to dm variable\n     *  const data = dm.getData({\n     *      order: 'column',\n     *      formatter: {\n     *          origin: (val) => val === 'European Union' ? 'EU' : val;\n     *      }\n     *  });\n     *  console.log(data);\n     *\n     * @public\n     *\n     * @param {Object} [options] Options to control how the raw data is to be returned.\n     * @param {string} [options.order='row'] Defines if data is retieved in row order or column order. Possible values\n     *      are `'rows'` and `'columns'`\n     * @param {Function} [options.formatter=null] Formats the output data. This expects an object, where the keys are\n     *      the name of the variable needs to be formatted. The formatter function is called for each row passing the\n     *      value of the cell for a particular row as arguments. The formatter is a function in the form of\n     *      `function (value, rowId, schema) => { ... }`\n     *      Know more about {@link Fomatter}.\n     *\n     * @return {Array} Returns a multidimensional array of the data with schema. The return format looks like\n     *      ```\n     *          {\n     *              data,\n     *              schema\n     *          }\n     *      ```\n     */\n    getData (options) {\n        const defOptions = {\n            order: 'row',\n            formatter: null,\n            withUid: false,\n            getAllFields: false,\n            sort: []\n        };\n        options = Object.assign({}, defOptions, options);\n        const fields = this.getPartialFieldspace().fields;\n\n        const dataGenerated = dataBuilder.call(\n            this,\n            this.getPartialFieldspace().fields,\n            this._rowDiffset,\n            options.getAllFields ? fields.map(d => d.name()).join() : this._colIdentifier,\n            options.sort,\n            {\n                columnWise: options.order === 'column',\n                addUid: !!options.withUid\n            }\n        );\n\n        if (!options.formatter) {\n            return dataGenerated;\n        }\n\n        const { formatter } = options;\n        const { data, schema, uids } = dataGenerated;\n        const fieldNames = schema.map((e => e.name));\n        const fmtFieldNames = Object.keys(formatter);\n        const fmtFieldIdx = fmtFieldNames.reduce((acc, next) => {\n            const idx = fieldNames.indexOf(next);\n            if (idx !== -1) {\n                acc.push([idx, formatter[next]]);\n            }\n            return acc;\n        }, []);\n\n        if (options.order === 'column') {\n            fmtFieldIdx.forEach((elem) => {\n                const fIdx = elem[0];\n                const fmtFn = elem[1];\n\n                data[fIdx].forEach((datum, datumIdx) => {\n                    data[fIdx][datumIdx] = fmtFn.call(\n                        undefined,\n                        datum,\n                        uids[datumIdx],\n                        schema[fIdx]\n                    );\n                });\n            });\n        } else {\n            data.forEach((datum, datumIdx) => {\n                fmtFieldIdx.forEach((elem) => {\n                    const fIdx = elem[0];\n                    const fmtFn = elem[1];\n\n                    datum[fIdx] = fmtFn.call(\n                        undefined,\n                        datum[fIdx],\n                        uids[datumIdx],\n                        schema[fIdx]\n                    );\n                });\n            });\n        }\n\n        return dataGenerated;\n    }\n\n    /**\n     * Returns the unique ids in an array.\n     *\n     * @return {Array} Returns an array of ids.\n     */\n    getUids () {\n        const rowDiffset = this._rowDiffset;\n        const ids = [];\n\n        if (rowDiffset.length) {\n            const diffSets = rowDiffset.split(',');\n\n            diffSets.forEach((set) => {\n                let [start, end] = set.split('-').map(Number);\n\n                end = end !== undefined ? end : start;\n                ids.push(...Array(end - start + 1).fill().map((_, idx) => start + idx));\n            });\n        }\n\n        return ids;\n    }\n    /**\n     * Groups the data using particular dimensions and by reducing measures. It expects a list of dimensions using which\n     * it projects the datamodel and perform aggregations to reduce the duplicate tuples. Refer this\n     * {@link link_to_one_example_with_group_by | document} to know the intuition behind groupBy.\n     *\n     * DataModel by default provides definition of few {@link reducer | Reducers}.\n     * {@link ReducerStore | User defined reducers} can also be registered.\n     *\n     * This is the chained implementation of `groupBy`.\n     * `groupBy` also supports {@link link_to_compose_groupBy | composability}\n     *\n     * @example\n     * const groupedDM = dm.groupBy(['Year'], { horsepower: 'max' } );\n     * console.log(groupedDm);\n     *\n     * @public\n     *\n     * @param {Array.<string>} fieldsArr - Array containing the name of dimensions\n     * @param {Object} [reducers={}] - A map whose key is the variable name and value is the name of the reducer. If its\n     *      not passed, or any variable is ommitted from the object, default aggregation function is used from the\n     *      schema of the variable.\n     *\n     * @return {DataModel} Returns a new DataModel instance after performing the groupby.\n     */\n    groupBy (fieldsArr, reducers = {}, config = { saveChild: true }) {\n        const groupByString = `${fieldsArr.join()}`;\n        let params = [this, fieldsArr, reducers];\n        const newDataModel = groupBy(...params);\n\n        persistDerivations(\n            this,\n            newDataModel,\n            DM_DERIVATIVES.GROUPBY,\n            { fieldsArr, groupByString, defaultReducer: reducerStore.defaultReducer() },\n            reducers\n        );\n\n        if (config.saveChild) {\n            newDataModel.setParent(this);\n        } else {\n            newDataModel.setParent(null);\n        }\n\n        return newDataModel;\n    }\n\n    /**\n     * Performs sorting operation on the current {@link DataModel} instance according to the specified sorting details.\n     * Like every other operator it doesn't mutate the current DataModel instance on which it was called, instead\n     * returns a new DataModel instance containing the sorted data.\n     *\n     * DataModel support multi level sorting by listing the variables using which sorting needs to be performed and\n     * the type of sorting `ASC` or `DESC`.\n     *\n     * In the following example, data is sorted by `Origin` field in `DESC` order in first level followed by another\n     * level of sorting by `Acceleration` in `ASC` order.\n     *\n     * @example\n     * // here dm is the pre-declared DataModel instance containing the data of 'cars.json' file\n     * let sortedDm = dm.sort([\n     *    [\"Origin\", \"DESC\"]\n     *    [\"Acceleration\"] // Default value is ASC\n     * ]);\n     *\n     * console.log(dm.getData());\n     * console.log(sortedDm.getData());\n     *\n     * // Sort with a custom sorting function\n     * sortedDm = dm.sort([\n     *    [\"Origin\", \"DESC\"]\n     *    [\"Acceleration\", (a, b) => a - b] // Custom sorting function\n     * ]);\n     *\n     * console.log(dm.getData());\n     * console.log(sortedDm.getData());\n     *\n     * @text\n     * DataModel also provides another sorting mechanism out of the box where sort is applied to a variable using\n     * another variable which determines the order.\n     * Like the above DataModel contains three fields `Origin`, `Name` and `Acceleration`. Now, the data in this\n     * model can be sorted by `Origin` field according to the average value of all `Acceleration` for a\n     * particular `Origin` value.\n     *\n     * @example\n     * // here dm is the pre-declared DataModel instance containing the data of 'cars.json' file\n     * const sortedDm = dm.sort([\n     *     ['Origin', ['Acceleration', (a, b) => avg(...a.Acceleration) - avg(...b.Acceleration)]]\n     * ]);\n     *\n     * console.log(dm.getData());\n     * console.log(sortedDm.getData());\n     *\n     * @public\n     *\n     * @param {Array.<Array>} sortingDetails - Sorting details based on which the sorting will be performed.\n     * @return {DataModel} Returns a new instance of DataModel with sorted data.\n     */\n    sort (sortingDetails, config = { saveChild: false }) {\n        const rawData = this.getData({\n            order: 'row',\n            sort: sortingDetails\n        });\n        const header = rawData.schema.map(field => field.name);\n        const dataInCSVArr = [header].concat(rawData.data);\n\n        const sortedDm = new this.constructor(dataInCSVArr, rawData.schema, { dataFormat: 'DSVArr' });\n\n        persistDerivations(\n            this,\n            sortedDm,\n            DM_DERIVATIVES.SORT,\n            config,\n            sortingDetails\n        );\n\n        if (config.saveChild) {\n            sortedDm.setParent(this);\n        } else {\n            sortedDm.setParent(null);\n        }\n\n        return sortedDm;\n    }\n\n    /**\n     * Performs the serialization operation on the current {@link DataModel} instance according to the specified data\n     * type. When an {@link DataModel} instance is created, it de-serializes the input data into its internal format,\n     * and during its serialization process, it converts its internal data format to the specified data type and returns\n     * that data regardless what type of data is used during the {@link DataModel} initialization.\n     *\n     * @example\n     * // here dm is the pre-declared DataModel instance.\n     * const csvData = dm.serialize(DataModel.DataFormat.DSV_STR, { fieldSeparator: \",\" });\n     * console.log(csvData); // The csv formatted data.\n     *\n     * const jsonData = dm.serialize(DataModel.DataFormat.FLAT_JSON);\n     * console.log(jsonData); // The json data.\n     *\n     * @public\n     *\n     * @param {string} type - The data type name for serialization.\n     * @param {Object} options - The optional option object.\n     * @param {string} options.fieldSeparator - The field separator character for DSV data type.\n     * @return {Array|string} Returns the serialized data.\n     */\n    serialize (type, options) {\n        type = type || this._dataFormat;\n        options = Object.assign({}, { fieldSeparator: ',' }, options);\n\n        const fields = this.getFieldspace().fields;\n        const colData = fields.map(f => f.formattedData());\n        const rowsCount = colData[0].length;\n        let serializedData;\n        let rowIdx;\n        let colIdx;\n\n        if (type === DataFormat.FLAT_JSON) {\n            serializedData = [];\n            for (rowIdx = 0; rowIdx < rowsCount; rowIdx++) {\n                const row = {};\n                for (colIdx = 0; colIdx < fields.length; colIdx++) {\n                    row[fields[colIdx].name()] = colData[colIdx][rowIdx];\n                }\n                serializedData.push(row);\n            }\n        } else if (type === DataFormat.DSV_STR) {\n            serializedData = [fields.map(f => f.name()).join(options.fieldSeparator)];\n            for (rowIdx = 0; rowIdx < rowsCount; rowIdx++) {\n                const row = [];\n                for (colIdx = 0; colIdx < fields.length; colIdx++) {\n                    row.push(colData[colIdx][rowIdx]);\n                }\n                serializedData.push(row.join(options.fieldSeparator));\n            }\n            serializedData = serializedData.join('\\n');\n        } else if (type === DataFormat.DSV_ARR) {\n            serializedData = [fields.map(f => f.name())];\n            for (rowIdx = 0; rowIdx < rowsCount; rowIdx++) {\n                const row = [];\n                for (colIdx = 0; colIdx < fields.length; colIdx++) {\n                    row.push(colData[colIdx][rowIdx]);\n                }\n                serializedData.push(row);\n            }\n        } else {\n            throw new Error(`Data type ${type} is not supported`);\n        }\n\n        return serializedData;\n    }\n\n    addField (field) {\n        const fieldName = field.name();\n        this._colIdentifier += `,${fieldName}`;\n        const partialFieldspace = this._partialFieldspace;\n        const cachedValueObjects = partialFieldspace._cachedValueObjects;\n\n        if (!partialFieldspace.fieldsObj()[field.name()]) {\n            partialFieldspace.fields.push(field);\n            cachedValueObjects.forEach((obj, i) => {\n                obj[field.name()] = new Value(field.partialField.data[i], field);\n            });\n        } else {\n            const fieldIndex = partialFieldspace.fields.findIndex(fieldinst => fieldinst.name() === fieldName);\n            fieldIndex >= 0 && (partialFieldspace.fields[fieldIndex] = field);\n        }\n\n        // flush out cached namespace values on addition of new fields\n        partialFieldspace._cachedFieldsObj = null;\n        partialFieldspace._cachedDimension = null;\n        partialFieldspace._cachedMeasure = null;\n\n        this.__calculateFieldspace().calculateFieldsConfig();\n        return this;\n    }\n\n    /**\n    * Creates a new variable calculated from existing variables. This method expects the definition of the newly created\n    * variable and a function which resolves the value of the new variable from existing variables.\n    *\n    * Can create a new measure based on existing variables:\n    * @example\n    *  // DataModel already prepared and assigned to dm variable;\n    *  const newDm = dataModel.calculateVariable({\n    *      name: 'powerToWeight',\n    *      type: 'measure'\n    *  }, ['horsepower', 'weight_in_lbs', (hp, weight) => hp / weight ]);\n    *\n    *\n    * Can create a new dimension based on existing variables:\n    * @example\n    *  // DataModel already prepared and assigned to dm variable;\n    *  const child = dataModel.calculateVariable(\n    *     {\n    *       name: 'Efficiency',\n    *       type: 'dimension'\n    *     }, ['horsepower', (hp) => {\n    *      if (hp < 80) { return 'low'; },\n    *      else if (hp < 120) { return 'moderate'; }\n    *      else { return 'high' }\n    *  }]);\n    *\n    * @public\n    *\n    * @param {Object} schema - The schema of newly defined variable.\n    * @param {Array.<string|function>} dependency - An array containing the dependency variable names and a resolver\n    * function as the last element.\n    * @param {Object} config - An optional config object.\n    * @param {boolean} [config.saveChild] - Whether the newly created DataModel will be a child.\n    * @param {boolean} [config.replaceVar] - Whether the newly created variable will replace the existing variable.\n    * @return {DataModel} Returns an instance of DataModel with the new field.\n    */\n    calculateVariable (schema, dependency, config) {\n        schema = sanitizeUnitSchema(schema);\n        config = Object.assign({}, { saveChild: true, replaceVar: false }, config);\n\n        const fieldsConfig = this.getFieldsConfig();\n        const depVars = dependency.slice(0, dependency.length - 1);\n        const retrieveFn = dependency[dependency.length - 1];\n\n        if (fieldsConfig[schema.name] && !config.replaceVar) {\n            throw new Error(`${schema.name} field already exists in datamodel`);\n        }\n\n        const depFieldIndices = depVars.map((field) => {\n            const fieldSpec = fieldsConfig[field];\n            if (!fieldSpec) {\n                // @todo dont throw error here, use warning in production mode\n                throw new Error(`${field} is not a valid column name.`);\n            }\n            return fieldSpec.index;\n        });\n\n        const clone = this.clone(config.saveChild);\n\n        const fs = clone.getFieldspace().fields;\n        const suppliedFields = depFieldIndices.map(idx => fs[idx]);\n\n        let cachedStore = {};\n        let cloneProvider = () => this.detachedRoot();\n\n        const computedValues = [];\n        rowDiffsetIterator(clone._rowDiffset, (i) => {\n            const fieldsData = suppliedFields.map(field => field.partialField.data[i]);\n            computedValues[i] = retrieveFn(...fieldsData, i, cloneProvider, cachedStore);\n        });\n        const [field] = createFields([computedValues], [schema], [schema.name]);\n        clone.addField(field);\n\n        persistDerivations(\n            this,\n            clone,\n            DM_DERIVATIVES.CAL_VAR,\n            { config: schema, fields: depVars },\n            retrieveFn\n        );\n\n        return clone;\n    }\n\n    /**\n     * Propagates changes across all the connected DataModel instances.\n     *\n     * @param {Array} identifiers - A list of identifiers that were interacted with.\n     * @param {Object} payload - The interaction specific details.\n     *\n     * @return {DataModel} DataModel instance.\n     */\n    propagate (identifiers, config = {}, addToNameSpace, propConfig = {}) {\n        const isMutableAction = config.isMutableAction;\n        const propagationSourceId = config.sourceId;\n        const payload = config.payload;\n        const rootModel = getRootDataModel(this);\n        const propagationNameSpace = rootModel._propagationNameSpace;\n        const rootGroupByModel = getRootGroupByModel(this);\n        const rootModels = {\n            groupByModel: rootGroupByModel,\n            model: rootModel\n        };\n\n        addToNameSpace && addToPropNamespace(propagationNameSpace, config, this);\n        propagateToAllDataModels(identifiers, rootModels, { propagationNameSpace, sourceId: propagationSourceId },\n            Object.assign({\n                payload\n            }, config));\n\n        if (isMutableAction) {\n            propagateImmutableActions(propagationNameSpace, rootModels, {\n                config,\n                propConfig\n            }, this);\n        }\n\n        return this;\n    }\n\n    /**\n     * Associates a callback with an event name.\n     *\n     * @param {string} eventName - The name of the event.\n     * @param {Function} callback - The callback to invoke.\n     * @return {DataModel} Returns this current DataModel instance itself.\n     */\n    on (eventName, callback) {\n        switch (eventName) {\n        case PROPAGATION:\n            this._onPropagation.push(callback);\n            break;\n        }\n        return this;\n    }\n\n    /**\n     * Unsubscribes the callbacks for the provided event name.\n     *\n     * @param {string} eventName - The name of the event to unsubscribe.\n     * @return {DataModel} Returns the current DataModel instance itself.\n     */\n    unsubscribe (eventName) {\n        switch (eventName) {\n        case PROPAGATION:\n            this._onPropagation = [];\n            break;\n\n        }\n        return this;\n    }\n\n    /**\n     * This method is used to invoke the method associated with propagation.\n     *\n     * @param {Object} payload The interaction payload.\n     * @param {DataModel} identifiers The propagated DataModel.\n     * @memberof DataModel\n     */\n    handlePropagation (propModel, payload) {\n        let propListeners = this._onPropagation;\n        propListeners.forEach(fn => fn.call(this, propModel, payload));\n    }\n\n    /**\n     * Performs the binning operation on a measure field based on the binning configuration. Binning means discretizing\n     * values of a measure. Binning configuration contains an array; subsequent values from the array marks the boundary\n     * of buckets in [inclusive, exclusive) range format. This operation does not mutate the subject measure field,\n     * instead, it creates a new field (variable) of type dimension and subtype binned.\n     *\n     * Binning can be configured by\n     * - providing custom bin configuration with non-uniform buckets,\n     * - providing bins count,\n     * - providing each bin size,\n     *\n     * When custom `buckets` are provided as part of binning configuration:\n     * @example\n     *  // DataModel already prepared and assigned to dm variable\n     *  const config = { name: 'binnedHP', buckets: [30, 80, 100, 110] }\n     *  const binnedDM = dataModel.bin('horsepower', config);\n     *\n     * @text\n     * When `binsCount` is defined as part of binning configuration:\n     * @example\n     *  // DataModel already prepared and assigned to dm variable\n     *  const config = { name: 'binnedHP', binsCount: 5, start: 0, end: 100 }\n     *  const binDM = dataModel.bin('horsepower', config);\n     *\n     * @text\n     * When `binSize` is defined as part of binning configuration:\n     * @example\n     *  // DataModel already prepared and assigned to dm variable\n     *  const config = { name: 'binnedHorsepower', binSize: 20, start: 5}\n     *  const binDM = dataModel.bin('horsepower', config);\n     *\n     * @public\n     *\n     * @param {string} measureFieldName - The name of the target measure field.\n     * @param {Object} config - The config object.\n     * @param {string} [config.name] - The name of the new field which will be created.\n     * @param {string} [config.buckets] - An array containing the bucket ranges.\n     * @param {string} [config.binSize] - The size of each bin. It is ignored when buckets are given.\n     * @param {string} [config.binsCount] - The total number of bins to generate. It is ignored when buckets are given.\n     * @param {string} [config.start] - The start value of the bucket ranges. It is ignored when buckets are given.\n     * @param {string} [config.end] - The end value of the bucket ranges. It is ignored when buckets are given.\n     * @return {DataModel} Returns a new {@link DataModel} instance with the new field.\n     */\n    bin (measureFieldName, config) {\n        const fieldsConfig = this.getFieldsConfig();\n\n        if (!fieldsConfig[measureFieldName]) {\n            throw new Error(`Field ${measureFieldName} doesn't exist`);\n        }\n\n        const binFieldName = config.name || `${measureFieldName}_binned`;\n\n        if (fieldsConfig[binFieldName]) {\n            throw new Error(`Field ${binFieldName} already exists`);\n        }\n\n        const measureField = this.getFieldspace().fieldsObj()[measureFieldName];\n        const { binnedData, bins } = createBinnedFieldData(measureField, this._rowDiffset, config);\n\n        const binField = createFields([binnedData], [\n            {\n                name: binFieldName,\n                type: FieldType.DIMENSION,\n                subtype: DimensionSubtype.BINNED,\n                bins\n            }], [binFieldName])[0];\n\n        const clone = this.clone(config.saveChild);\n        clone.addField(binField);\n\n        persistDerivations(\n            this,\n            clone,\n            DM_DERIVATIVES.BIN,\n             { measureFieldName, config, binFieldName },\n             null\n        );\n\n        return clone;\n    }\n\n    /**\n     * Creates a new {@link DataModel} instance with completely detached root from current {@link DataModel} instance,\n     * the new {@link DataModel} instance has no parent-children relationship with the current one, but has same data as\n     * the current one.\n     * This API is useful when a completely different {@link DataModel} but with same data as the current instance is\n     * needed.\n     *\n     * @example\n     *  const dm = new DataModel(data, schema);\n     *  const detachedDm = dm.detachedRoot();\n     *\n     * // has different namespace\n     * console.log(dm.getPartialFieldspace().name);\n     * console.log(detachedDm.getPartialFieldspace().name);\n     *\n     * // has same data\n     * console.log(dm.getData());\n     * console.log(detachedDm.getData());\n     *\n     * @public\n     *\n     * @return {DataModel} Returns a detached {@link DataModel} instance.\n     */\n    detachedRoot () {\n        const data = this.serialize(DataFormat.FLAT_JSON);\n        const schema = this.getSchema();\n\n        return new DataModel(data, schema);\n    }\n\n    /**\n     * Creates a set of new {@link DataModel} instances by splitting the set of rows in the source {@link DataModel}\n     * instance based on a set of dimensions.\n     *\n     * For each unique dimensional value, a new split is created which creates a unique {@link DataModel} instance for\n     *  that split\n     *\n     * If multiple dimensions are provided, it splits the source {@link DataModel} instance with all possible\n     * combinations of the dimensional values for all the dimensions provided\n     *\n     * Additionally, it also accepts a predicate function to reduce the set of rows provided. A\n     * {@link link_to_selection | Selection} is performed on all the split {@link DataModel} instances based on\n     * the predicate function\n     *\n     * @example\n     *  // without predicate function:\n     *  const splitDt = dt.splitByRow(['Origin'])\n     *  console.log(splitDt));\n     * // This should give three unique DataModel instances, one each having rows only for 'USA',\n     * // 'Europe' and 'Japan' respectively\n     *\n     * @example\n     *  // without predicate function:\n     *  const splitDtMulti = dt.splitByRow(['Origin', 'Cylinders'])\n     *  console.log(splitDtMulti));\n     * // This should give DataModel instances for all unique combinations of Origin and Cylinder values\n     *\n     * @example\n     * // with predicate function:\n     * const splitWithPredDt = dt.select(['Origin'], fields => fields.Origin.value === \"USA\")\n     * console.log(splitWithPredDt);\n     * // This should not include the DataModel for the Origin : 'USA'\n     *\n     *\n     * @public\n     *\n     * @param {Array} dimensionArr - Set of dimensions based on which the split should occur\n     * @param {Object} config - The configuration object\n     * @param {string} [config.saveChild] - Configuration to save child or not\n     * @param {string}[config.mode=FilteringMode.NORMAL] -The mode of the selection.\n     * @return {Array}  Returns the new DataModel instances after operation.\n     */\n    splitByRow (dimensionArr, reducerFn, config) {\n        const fieldsConfig = this.getFieldsConfig();\n\n        dimensionArr.forEach((fieldName) => {\n            if (!fieldsConfig[fieldName]) {\n                throw new Error(`Field ${fieldName} doesn't exist in the schema`);\n            }\n        });\n\n        const defConfig = {\n            mode: FilteringMode.NORMAL,\n            saveChild: true\n        };\n\n        config = Object.assign({}, defConfig, config);\n\n        return splitWithSelect(this, dimensionArr, reducerFn, config);\n    }\n\n    /**\n     * Creates a set of new {@link DataModel} instances by splitting the set of fields in the source {@link DataModel}\n     * instance based on a set of common and unique field names provided.\n     *\n     * Each DataModel created contains a set of fields which are common to all and a set of unique fields.\n     * It also accepts configurations such as saveChild and mode(inverse or normal) to include/exclude the respective\n     * fields\n     *\n     * @example\n     *  // without predicate function:\n     *  const splitDt = dt.splitByColumn( [['Acceleration'], ['Horsepower']], ['Origin'])\n     *  console.log(splitDt));\n     * // This should give two unique DataModel instances, both having the field 'Origin' and\n     * // one each having 'Acceleration' and 'Horsepower' fields respectively\n     *\n     * @example\n     *  // without predicate function:\n     *  const splitDtInv = dt.splitByColumn( [['Acceleration'], ['Horsepower'],['Origin', 'Cylinders'],\n     *                           {mode: 'inverse'})\n     *  console.log(splitDtInv));\n     * // This should give DataModel instances in the following way:\n     * // All DataModel Instances do not have the fields 'Origin' and 'Cylinders'\n     * // One DataModel Instance has rest of the fields except 'Acceleration' and the other DataModel instance\n     * // has rest of the fields except 'Horsepower'\n     *\n     *\n     *\n     * @public\n     *\n     * @param {Array} uniqueFields - Set of unique fields included in each datamModel instance\n     * @param {Array} commonFields - Set of common fields included in all datamModel instances\n     * @param {Object} config - The configuration object\n     * @param {string} [config.saveChild] - Configuration to save child or not\n     * @param {string}[config.mode=FilteringMode.NORMAL] -The mode of the selection.\n     * @return {Array}  Returns the new DataModel instances after operation.\n     */\n    splitByColumn (uniqueFields = [], commonFields = [], config) {\n        const defConfig = {\n            mode: FilteringMode.NORMAL,\n            saveChild: true\n        };\n        const fieldConfig = this.getFieldsConfig();\n        const allFields = Object.keys(fieldConfig);\n        const normalizedProjFieldSets = [[commonFields]];\n\n        config = Object.assign({}, defConfig, config);\n        uniqueFields = uniqueFields.length ? uniqueFields : [[]];\n\n\n        uniqueFields.forEach((fieldSet, i) => {\n            normalizedProjFieldSets[i] = getNormalizedProFields(\n                [...fieldSet, ...commonFields],\n                allFields,\n                fieldConfig);\n        });\n\n        return splitWithProject(this, normalizedProjFieldSets, config, allFields);\n    }\n\n\n}\n\nexport default DataModel;\n","import { fnList } from '../operator/group-by-function';\n\nexport const { sum, avg, min, max, first, last, count, std: sd } = fnList;\n","import DataModel from './datamodel';\nimport {\n  compose,\n  bin,\n  select,\n  project,\n  groupby as groupBy,\n  calculateVariable,\n  sort,\n  crossProduct,\n  difference,\n  naturalJoin,\n  leftOuterJoin,\n  rightOuterJoin,\n  fullOuterJoin,\n  union\n} from './operator';\nimport * as Stats from './stats';\nimport * as enums from './enums';\nimport { DateTimeFormatter } from './utils';\nimport { DataFormat, FilteringMode, DM_DERIVATIVES } from './constants';\nimport InvalidAwareTypes from './invalid-aware-types';\nimport pkg from '../package.json';\n\nconst Operators = {\n    compose,\n    bin,\n    select,\n    project,\n    groupBy,\n    calculateVariable,\n    sort,\n    crossProduct,\n    difference,\n    naturalJoin,\n    leftOuterJoin,\n    rightOuterJoin,\n    fullOuterJoin,\n    union\n};\n\nconst version = pkg.version;\nObject.assign(DataModel, {\n    Operators,\n    Stats,\n    DM_DERIVATIVES,\n    DateTimeFormatter,\n    DataFormat,\n    FilteringMode,\n    InvalidAwareTypes,\n    version\n}, enums);\n\nexport default DataModel;\n","/**\n * Wrapper on calculateVariable() method of DataModel to behave\n * the pure-function functionality.\n *\n * @param {Array} args - The argument list.\n * @return {any} Returns the returned value of calling function.\n */\nexport const calculateVariable = (...args) => dm => dm.calculateVariable(...args);\n\n/**\n * Wrapper on sort() method of DataModel to behave\n * the pure-function functionality.\n *\n * @param {Array} args - The argument list.\n * @return {any} Returns the returned value of calling function.\n */\nexport const sort = (...args) => dm => dm.sort(...args);\n","import { crossProduct } from './cross-product';\nimport { naturalJoinFilter } from './natural-join-filter-function';\n\nexport function naturalJoin (dataModel1, dataModel2) {\n    return crossProduct(dataModel1, dataModel2, naturalJoinFilter(dataModel1, dataModel2), true);\n}\n"],"sourceRoot":""}
>>>>>>> develop
